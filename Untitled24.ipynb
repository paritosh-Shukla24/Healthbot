{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6okVrAfVay2v",
        "outputId": "392ae12b-320d-4e42-9c1f-05133d32e764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.14 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.16)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.16)\n",
            "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.83)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.3)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.14)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.11.2)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.10.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.3)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2024.1.2)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.0.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.26.3)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.6.1)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.0)\n",
            "Requirement already satisfied: unstructured-client>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.14.1)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured) (2023.11.17)\n",
            "Requirement already satisfied: charset-normalizer>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured) (3.3.2)\n",
            "Requirement already satisfied: idna>=3.4 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured) (3.6)\n",
            "Requirement already satisfied: jsonpath-python>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured) (1.0.6)\n",
            "Requirement already satisfied: marshmallow>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured) (3.20.2)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured) (1.0.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured) (23.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured) (2.8.2)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured) (1.16.0)\n",
            "Requirement already satisfied: typing-inspect>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured) (0.9.0)\n",
            "Requirement already satisfied: urllib3>=1.26.18 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured) (2.0.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (4.66.1)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.26.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2023.11.17)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.9.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install pypdf\n",
        "!pip install unstructured\n",
        "!pip install sentence_transformers\n",
        "!pip install pinecone-client\n",
        "!!pip install huggingface_hub\n",
        "!pip install -q cassio datasets tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "from datasets import load_dataset\n",
        "import cassio"
      ],
      "metadata": {
        "id": "0EXww0kNfom9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader,OnlinePDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Pinecone\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "import os"
      ],
      "metadata": {
        "id": "iR_afyaWiy6p"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgTm98s_g-V6",
        "outputId": "b3b08e97-9aad-43f8-9d94-2a91a6454df8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader"
      ],
      "metadata": {
        "id": "v9OY6e4ThOX0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "Jm429Ir_hRPQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ASTRA_DB_APPLICATION_TOKEN='AstraCS:bJpLHCFjYHjbybZDiqYGdLvs:4b46b6175b8305d4efa364591d5266df045494f720a8cba172972331c9737f34'"
      ],
      "metadata": {
        "id": "dYzOZdmchU6v"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ASTRA_DB_ID='1f246906-21d0-46d1-9cb3-1f18538943e1'"
      ],
      "metadata": {
        "id": "cGrEi9orhU9q"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdfreader=PdfReader('/content/drive/MyDrive/Data/NotesOnMachineLearningForBTech-1-2.pdf')"
      ],
      "metadata": {
        "id": "U_TerzRehdR-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Concatenate\n",
        "raw_text=''\n",
        "for i,page in enumerate(pdfreader.pages):\n",
        "  content=page.extract_text()\n",
        "  if content:\n",
        "    raw_text+=content"
      ],
      "metadata": {
        "id": "Lq9kZwlfk-Mq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "LRPRCMYKlhvT",
        "outputId": "a41129aa-d133-419e-a1ba-2fe304058416"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'   \\n \\nLecture Notes  in \\nMACHINE LEARNING  \\n \\n Dr V N Krishnachandran  \\n  \\n \\nVidya Centre for Artificial Intelligence Research  \\nThis page is intentionally left blank.LECTURE NOTES IN\\nMACHINE LEARNING\\nDr V N Krishnachandran\\nVidya Centre for Artiﬁcial Intelligence Research\\nVidya Academy of Science & Technology\\nThrissur - 680501Copyright © 2018 V . N. Krishnachandran\\nPublished by\\nVidya Centre for Artiﬁcial Intelligence Research\\nVidya Academy of Science & Technology\\nThrissur - 680501, Kerala, India\\nThe book was typeset by the author using the L ATEX document preparation system.\\nCover design: Author\\nLicensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License. You may\\nnot use this ﬁle except in compliance with the License. You may obtain a copy of the License at\\nhttps://creativecommons.org/licenses/by/4.0/ .\\nPrice: Rs 0.00.\\nFirst printing: July 2018Preface\\nThe book is exactly what its title claims it to be: lecture notes; nothing more, nothing less!\\nA reader looking for elaborate descriptive expositions of the concepts and tools of machine\\nlearning will be disappointed with this book. There are plenty of books out there in the market\\nwith different styles of exposition. Some of them give a lot of emphasis on the mathematical theory\\nbehind the algorithms. In some others the emphasis is on the verbal descriptions of algorithms\\navoiding the use of mathematical notations and concepts to the maximum extent possible. There is\\none book the author of which is so afraid of introducing mathematical symbols that he introduces\\n\\x1bas “the Greek letter sigma similar to a bturned sideways\". But among these books, the author of\\nthese Notes could not spot a book that would give complete worked out examples illustrating the\\nvarious algorithms. These notes are expected to ﬁll this gap.\\nThe focus of this book is on giving a quick and fast introduction to the basic concepts and im-\\nportant algorithms in machine learning. In nearly all cases, whenever a new concept is introduced\\nit has been illustrated with “toy examples” and also with examples from real life situations. In the\\ncase of algorithms, wherever possible, the working of the algorithm has been illustrated with con-\\ncrete numerical examples. In some cases, the full algorithm may contain heavy use of mathematical\\nnotations and concepts. Practitioners of machine learning sometimes treat such algorithms as “black\\nbox algorithms”. Student readers of this book may skip these details on a ﬁrst reading.\\nThe book is written primarily for the students pursuing the B Tech programme in Computer\\nScience and Engineering of the APJ Abdul Kalam Technological University. The Curriculum for\\nthe programme offers a course on machine learning as an elective course in the Seventh Semester\\nwith code and name “CS 467 Machine Learning”. The selection of topics in the book was guided\\nby the contents of the syllabus for the course. The book will also be useful to faculty members who\\nteach the course.\\nThough the syllabus for CS 467 Machine Learning is reasonably well structured and covers most\\nof the basic concepts of machine learning, there is some lack of clarity on the depth to which the\\nvarious topics are to be covered. This ambiguity has been compounded by the lack of any mention\\nof a single textbook for the course and unfortunately the books cited as references treat machine\\nlearning at varying levels. The guiding principle the author has adopted in the selection of materials\\nin the preparation of these notes is that, at the end of the course, the student must acquire enough\\nunderstanding about the methodologies and concepts underlying the various topics mentioned in the\\nsyllabus.\\nAny study of machine learning algorithms without studying their implementations in software\\npackages is deﬁnitely incomplete. There are implementations of these algorithms available in the\\nR and Python programming languages. Two or three lines of code may be sufﬁcient to implement\\nan algorithm. Since the syllabus for CS 467 Machine Learning does not mandate the study of such\\nimplementations, this aspect of machine learning has not been included in this book. The students\\nare well advised to refer to any good book or the resources available in the internet to acquire a\\nworking knowledge of these implementations.\\nEvidently, there are no original material in this book. The readers can see shadows of everything\\npresented here in other sources which include the reference books listed in the syllabus of the course\\nreferred to earlier, other books on machine learning, published research/review papers and also\\nseveral open sources accessible through the internet. However, care has been taken to present the\\nmaterial borrowed from other sources in a format digestible to the targeted audience. There are\\niiiiv\\nmore than a hundred ﬁgures in the book. Nearly all of them were drawn using the TikZ package for\\nLATEX. A few of the ﬁgures were created using the R programming language. A small number of\\nﬁgures are reproductions of images available in various websites. There surely will be many errors\\n– conceptual, technical and printing – in these notes. The readers are earnestly requested to point\\nout such errors to the author so that an error free book can be brought up in the future.\\nThe author wishes to put on record his thankfulness to Vidya Centre for Artiﬁcial Intelligence\\nResearch (V-CAIR) for agreeing to be the publisher of this book. V-CAIR is a research centre func-\\ntioning in Vidya Academy of Science & Technology, Thrissur, Kerala, established as part of the\\n“AI and Deep Learning: Skilling and Research” project launched by Royal Academy of Engineer-\\ning, UK, in collaboration with University College, London, Brunel University, London and Bennett\\nUniversity, India.\\nV AST Campus Dr V N Krishnachandran\\nJuly 2018 Department of Computer Applications\\nVidya Academy of Science & Technology, Thrissur - 680501\\n(email: krishnachandran.vn@vidyaacademy.ac.in )Syllabus\\nCourse code Course Name L - T - P - Credits Year of introduction\\nCS467 Machine Learning 3 - 0 - 0 - 3 2016\\nCourse Objectives\\n• To introduce the prominent methods for machine learning\\n• To study the basics of supervised and unsupervised learning\\n• To study the basics of connectionist and other architectures\\nSyllabus\\nIntroduction to Machine Learning, Learning in Artiﬁcial Neural Networks, Decision trees, HMM,\\nSVM, and other Supervised and Unsupervised learning methods.\\nExpected Outcome\\nThe students will be able to\\ni) differentiate various learning approaches, and to interpret the concepts of supervised learn-\\ning\\nii) compare the different dimensionality reduction techniques\\niii) apply theoretical foundations of decision trees to identify best split and Bayesian classiﬁer\\nto label data points\\niv) illustrate the working of classiﬁer models like SVM, Neural Networks and identify classiﬁer\\nmodel for typical machine learning applications\\nv) identify the state sequence and evaluate a sequence emission probability from a given HMM\\nvi) illustrate and apply clustering algorithms and identify its applicability in real life problems\\nReferences\\n1. Christopher M. Bishop, Pattern Recognition and Machine Learning , Springer, 2006.\\n2. Ethem Alpayidin, Introduction to Machine Learning (Adaptive Computation and machine\\nLearning), MIT Press, 2004.\\n3. Margaret H. Dunham, Data Mining: Introductory and Advanced Topics , Pearson, 2006.\\nvvi\\n4. Mitchell T., Machine Learning , McGraw Hill.\\n5. Ryszard S. Michalski, Jaime G. Carbonell, and Tom M. Mitchell, Machine Learning : An\\nArtiﬁcial Intelligence Approach , Tioga Publishing Company.\\nCourse Plan\\nModule I. Introduction to Machine Learning, Examples of Machine Learning applications -\\nLearning associations, Classiﬁcation, Regression, Unsupervised Learning, Reinforce-\\nment Learning. Supervised learning- Input representation, Hypothesis class, Version\\nspace, Vapnik-Chervonenkis (VC) Dimension\\nHours: 6. Semester exam marks: 15%\\nModule II. Probably Approximately Learning (PAC), Noise, Learning Multiple classes, Model\\nSelection and Generalization, Dimensionality reduction- Subset selection, Principle\\nComponent Analysis\\nHours: 8. Semester exam marks: 15%\\nFIRST INTERNAL EXAMINATION\\nModule III. Classiﬁcation- Cross validation and re-sampling methods- Kfold cross validation,\\nBoot strapping, Measuring classiﬁer performance- Precision, recall, ROC curves.\\nBayes Theorem, Bayesian classiﬁer, Maximum Likelihood estimation, Density func-\\ntions, Regression\\nHours: 8. Semester exam marks: 20%\\nModule IV . Decision Trees- Entropy, Information Gain, Tree construction, ID3, Issues in Decision\\nTree learning- Avoiding Over-ﬁtting, Reduced Error Pruning, The problem of Missing\\nAttributes, Gain Ratio, Classiﬁcation by Regression (CART), Neural Networks- The\\nPerceptron, Activation Functions, Training Feed Forward Network by Back Propaga-\\ntion.\\nHours: 6. Semester exam marks: 15%\\nSECOND INTERNAL EXAMINATION\\nModule V . Kernel Machines - Support Vector Machine - Optimal Separating hyper plane, Soft-\\nmargin hyperplane, Kernel trick, Kernel functions. Discrete Markov Processes, Hid-\\nden Markov models, Three basic problems of HMMs - Evaluation problem, ﬁnding\\nstate sequence, Learning model parameters. Combining multiple learners, Ways to\\nachieve diversity, Model combination schemes, V oting, Bagging, Booting\\nHours: 8. Semester exam marks: 20%\\nModule VI. Unsupervised Learning - Clustering Methods - K-means, Expect-ation-Maxi-mization\\nAlgorithm, Hierarchical Clustering Methods, Density based clustering\\nHours: 6. Semester exam marks: 15%\\nEND SEMESTER EXAMINATION\\nQuestion paper pattern\\n1. There will be FOUR parts in the question paper: A, B, C, D.\\n2.Part A\\na) Total marks: 40\\nb) TEN questions, each have 4 marks, covering all the SIX modules (THREE questions\\nfrom modules I & II; THREE questions from modules III & IV; FOUR questions from\\nmodules V & VI).vii\\nc) All the TEN questions have to be answered.\\n3.Part B\\na) Total marks: 18\\nb) THREE questions, each having 9 marks. One question is from module I; one question\\nis from module II; one question uniformly covers modules I & II.\\nc) Any TWO questions have to be answered.\\nd) Each question can have maximum THREE subparts.\\n4.Part C\\na) Total marks: 18\\nb) THREE questions, each having 9 marks. One question is from module III; one question\\nis from module IV; one question uniformly covers modules III & IV .\\nc) Any TWO questions have to be answered.\\nd) Each question can have maximum THREE subparts.\\n5.Part D\\na) Total marks: 24\\nb) THREE questions, each having 12 marks. One question is from module V; one question\\nis from module VI; one question uniformly covers modules V & VI.\\nc) Any TWO questions have to be answered.\\nd) Each question can have maximum THREE subparts.\\n6. There will be AT LEAST 60% analytical/numerical questions in all possible combinations of\\nquestion choices.Contents\\nIntroduction iii\\nSyllabus v\\n1 Introduction to machine learning 1\\n1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\\n1.2 How machines learn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\\n1.3 Applications of machine learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\n1.4 Understanding data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n1.5 General classes of machine learning problems . . . . . . . . . . . . . . . . . . . . . . 6\\n1.6 Different types of learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n1.7 Sample questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\n2 Some general concepts 15\\n2.1 Input representation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\n2.2 Hypothesis space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\n2.3 Ordering of hypotheses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\\n2.4 Version space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\n2.5 Noise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\n2.6 Learning multiple classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\n2.7 Model selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n2.8 Generalisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\\n2.9 Sample questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n3 VC dimension and PAC learning 27\\n3.1 Vapnik-Chervonenkis dimension . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n3.2 Probably approximately correct learning . . . . . . . . . . . . . . . . . . . . . . . . . 31\\n3.3 Sample questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\\n4 Dimensionality reduction 35\\n4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n4.2 Why dimensionality reduction is useful . . . . . . . . . . . . . . . . . . . . . . . . . . 36\\n4.3 Subset selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\\n4.4 Principal component analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\\n4.5 Sample questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\n5 Evaluation of classiﬁers 48\\n5.1 Methods of evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\\n5.2 Cross-validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\n5.3K-fold cross-validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\n5.4 Measuring error . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\n5.5 Receiver Operating Characteristic (ROC) . . . . . . . . . . . . . . . . . . . . . . . . 54\\n5.6 Sample questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\nviiiCONTENTS ix\\n6 Bayesian classiﬁer and ML estimation 61\\n6.1 Conditional probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\\n6.2 Bayes’ theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\n6.3 Naive Bayes algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\\n6.4 Using numeric features with naive Bayes algorithm . . . . . . . . . . . . . . . . . . . 67\\n6.5 Maximum likelihood estimation (ML estimation) . . . . . . . . . . . . . . . . . . . . 68\\n6.6 Sample questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\\n7 Regression 72\\n7.1 Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\n7.2 Criterion for minimisation of error . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\n7.3 Simple linear regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\\n7.4 Polynomial regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\n7.5 Multiple linear regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\\n7.6 Sample questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80\\n8 Decision trees 83\\n8.1 Decision tree: Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\\n8.2 Two types of decision trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\\n8.3 Classiﬁcation trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\\n8.4 Feature selection measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\\n8.5 Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\\n8.6 Information gain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92\\n8.7 Gini indices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\\n8.8 Gain ratio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\\n8.9 Decision tree algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\\n8.10 The ID3 algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\\n8.11 Regression trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\n8.12 CART algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105\\n8.13 Other decision tree algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105\\n8.14 Issues in decision tree learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106\\n8.15 Avoiding overﬁtting of data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106\\n8.16 Problem of missing attributes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\\n8.17 Sample questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108\\n9 Neural networks 111\\n9.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\\n9.2 Biological motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\\n9.3 Artiﬁcial neurons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112\\n9.4 Activation function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113\\n9.5 Perceptron . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\\n9.6 Artiﬁcial neural networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119\\n9.7 Characteristics of an ANN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119\\n9.8 Backpropagation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\\n9.9 Introduction to deep learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129\\n9.10 Sample questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\\n10 Support vector machines 133\\n10.1 An example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133\\n10.2 Finite dimensional vector spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\\n10.3 Hyperplanes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\\n10.4 Two-class data sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\n10.5 Linearly separable data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\n10.6 Maximal margin hyperplanes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145\\n10.7 Mathematical formulation of the SVM problem . . . . . . . . . . . . . . . . . . . . . 147CONTENTS x\\n10.8 Solution of the SVM problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\\n10.9 Soft margin hyperlanes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154\\n10.10 Kernel functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155\\n10.11 The kernel method (kernel trick) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157\\n10.12 Multiclass SVM’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158\\n10.13 Sample questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159\\n11 Hidden Markov models 161\\n11.1 Discrete Markov processes: Examples . . . . . . . . . . . . . . . . . . . . . . . . . . 161\\n11.2 Discrete Markov processes: General case . . . . . . . . . . . . . . . . . . . . . . . . 163\\n11.3 Hidden Markov models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167\\n11.4 Three basic problems of HMMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169\\n11.5 HMM application: Isolated word recognition . . . . . . . . . . . . . . . . . . . . . . 170\\n11.6 Sample questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171\\n12 Combining multiple learners 173\\n12.1 Why combine many learners . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\\n12.2 Ways to achieve diversity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\\n12.3 Model combination schemes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\\n12.4 Ensemble learning/uni22C6. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176\\n12.5 Random forest/uni22C6. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176\\n12.6 Sample questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178\\n13 Clustering methods 179\\n13.1 Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179\\n13.2k-means clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179\\n13.3 Multi-modal distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\n13.4 Mixture of normal distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\n13.5 Mixtures in terms of latent variables . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\\n13.6 Expectation-maximisation algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\\n13.7 The EM algorithm for Gaussian mixtures . . . . . . . . . . . . . . . . . . . . . . . . 190\\n13.8 Hierarchical clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191\\n13.9 Measures of dissimilarity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\\n13.10 Algorithm for agglomerative hierarchical clustering . . . . . . . . . . . . . . . . . . 196\\n13.11 Algorithm for divisive hierarchical clustering . . . . . . . . . . . . . . . . . . . . . . 200\\n13.12 Density-based clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203\\n13.13 Sample questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204\\nBibliography 206\\nIndex 207List of Figures\\n1.1 Components of learning process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\\n1.2 Example for “examples” and “features” collected in a matrix format (data relates\\nto automobiles and their features) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n1.3 Graphical representation of data in Table 1.1. Solid dots represent data in “Pass”\\nclass and hollow dots data in “Fail” class. The class label of the square dot is to be\\ndetermined. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n1.4 Supervised learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n2.1 Data in Table 2.1 with hollow dots representing positive examples and solid dots\\nrepresenting negative examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n2.2 An example hypothesis deﬁned by Eq. (2.5) . . . . . . . . . . . . . . . . . . . . . . . 17\\n2.3 Hypothesis h′is more general than hypothesis h′′if and only if S′′⊆S′. . . . . . . 18\\n2.4 Values of mwhich deﬁne the version space with data in Table 2.1 and hypothesis\\nspace deﬁned by Eq.(2.4) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\n2.5 Scatter plot of price-power data (hollow circles indicate positive examples and\\nsolid dots indicate negative examples) . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n2.6 The version space consists of hypotheses corresponding to axis-aligned rectangles\\ncontained in the shaded region . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n2.7 Examples for overﬁtting and overﬁtting models . . . . . . . . . . . . . . . . . . . . . 24\\n2.8 Fitting a classiﬁcation boundary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n3.1 Different forms of the set {x∈S∶h(x)=1}forD={a;b;c}. . . . . . . . . . . . . 28\\n3.2 Geometrical representation of the hypothesis ha;b;c . . . . . . . . . . . . . . . . . . . 30\\n3.3 A hypothesis ha;b;c consistent with the dichotomy deﬁned by the subset {A;C}of\\n{A;B;C }. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\\n3.4 There is no hypothesis ha;b;c consistent with the dichotomy deﬁned by the subset\\n{A;C}of{A;B;C;D }. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\\n3.5 An axis-aligned rectangle in the Euclidean plane . . . . . . . . . . . . . . . . . . . . 32\\n3.6 Axis-aligned rectangle which gives the tightest ﬁt to the positive examples . . . . . 33\\n4.1 Principal components . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\\n4.2 Scatter plot of data in Table 4.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\\n4.3 Coordinate system for principal components . . . . . . . . . . . . . . . . . . . . . . . 45\\n4.4 Projections of data points on the axis of the ﬁrst principal component . . . . . . . . 46\\n4.5 Geometrical representation of one-dimensional approximation to the data in Table\\n4.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\n5.1 One iteration in a 5-fold cross-validation . . . . . . . . . . . . . . . . . . . . . . . . . 50\\n5.2 The ROC space and some special points in the space . . . . . . . . . . . . . . . . . . 56\\n5.3 ROC curves of three different classiﬁers A, B, C . . . . . . . . . . . . . . . . . . . . 57\\n5.4 ROC curve of data in Table 5.3 showing the points closest to the perfect prediction\\npoint(0;1). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\n6.1 Events A;B;C which are not mutually independent: Eqs.(6.1)–(6.3) are satisﬁed,\\nbut Eq.(6.4) is not satisﬁed. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nxiLIST OF FIGURES xii\\n6.2 Events A;B;C which are not mutually independent: Eq.(6.4) is satisﬁed but Eqs.(6.1)–\\n(6.2) are not satisﬁed. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\n6.3 Discretization of numeric data: Example . . . . . . . . . . . . . . . . . . . . . . . . . 68\\n7.1 Errors in observed values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\\n7.2 Regression model for Table 7.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\\n7.3 Plot of quadratic polynomial model . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\\n7.4 The regression plane for the data in Table 7.4 . . . . . . . . . . . . . . . . . . . . . . 80\\n8.1 Example for a decision tree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\\n8.2 The graph-theoretical representation of the decision tree in Figure 8.6 . . . . . . . . 84\\n8.3 Classiﬁcation tree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\\n8.4 Classiﬁcation tree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\\n8.5 Classiﬁcation tree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\\n8.6 Plot of pvs. Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\\n8.7 Root node of the decision tree for data in Table 8.9 . . . . . . . . . . . . . . . . . . . 97\\n8.8 Decision tree for data in Table 8.9, after selecting the branching feature at root node 99\\n8.9 Decision tree for data in Table 8.9, after selecting the branching feature at Node 1 . 100\\n8.10 Decision tree for data in Table 8.9 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\n8.11 Part of a regression tree for Table 8.11 . . . . . . . . . . . . . . . . . . . . . . . . . . 102\\n8.12 Part of regression tree for Table 8.11 . . . . . . . . . . . . . . . . . . . . . . . . . . . 102\\n8.13 A regression tree for Table 8.11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\\n8.14 Impact of overﬁtting in decision tree learning . . . . . . . . . . . . . . . . . . . . . . 107\\n9.1 Anatomy of a neuron . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\\n9.2 Flow of signals in a biological neuron . . . . . . . . . . . . . . . . . . . . . . . . . . 112\\n9.3 Schematic representation of an artiﬁcial neuron . . . . . . . . . . . . . . . . . . . . . 112\\n9.4 Simpliﬁed representation of an artiﬁcial neuron . . . . . . . . . . . . . . . . . . . . . 113\\n9.5 Threshold activation function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\\n9.6 Unit step activation function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\\n9.7 The sigmoid activation function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\\n9.8 Linear activation function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\\n9.9 Piecewise linear activation function . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\\n9.10 Gaussian activation function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\\n9.11 Hyperbolic tangent activation function . . . . . . . . . . . . . . . . . . . . . . . . . . 116\\n9.12 Schematic representation of a perceptrn . . . . . . . . . . . . . . . . . . . . . . . . . 116\\n9.13 Representation of x1ANDx2by a perceptron . . . . . . . . . . . . . . . . . . . . . . 117\\n9.14 An ANN with only one layer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120\\n9.15 An ANN with two layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121\\n9.16 Examples of different topologies of networks . . . . . . . . . . . . . . . . . . . . . . 122\\n9.17 A simpliﬁed model of the error surface showing the direction of gradient . . . . . . 123\\n9.18 ANN for illustrating backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . 124\\n9.19 ANN for illustrating backpropagation algorithm with initial values for weights . . . 124\\n9.20 Notations of backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . . . 128\\n9.21 Notations of backpropagation algorithm: The i-th node in layer j. . . . . . . . . . . 128\\n9.22 A shallow neural network . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\n9.23 A deep neural network with three hidden layers . . . . . . . . . . . . . . . . . . . . . 130\\n10.1 Scatter plot of data in Table 10.1 (ﬁlled circles represent “yes” and unﬁlled circles\\n“no”) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134\\n10.2 Scatter plot of data in Table 10.1 with a separating line . . . . . . . . . . . . . . . . . 135\\n10.3 Two separating lines for the data in Table 10.1 . . . . . . . . . . . . . . . . . . . . . . 135\\n10.4 Shortest perpendicular distance of a separating line from data points . . . . . . . . . 136\\n10.5 Maximum margin line for data in Table 10.1 . . . . . . . . . . . . . . . . . . . . . . . 136\\n10.6 Support vectors for data in Table 10.1 . . . . . . . . . . . . . . . . . . . . . . . . . . 137LIST OF FIGURES xiii\\n10.7 Boundaries of “street” of maximum width separating “yes” points and “no” points\\nin Table 10.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137\\n10.8 Plot of the maximum margin line of data in Table 10.1 produced by the R program-\\nming language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\\n10.9 Half planes deﬁned by a line . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142\\n10.10 Perpendicular distance of a point from a plane . . . . . . . . . . . . . . . . . . . . . . 143\\n10.11 Scatterplot of data in Table 10.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145\\n10.12 Maximal separating hyperplane, margin and support vectors . . . . . . . . . . . . . . 146\\n10.13 Maximal margin hyperplane of a 2-sample set in 2-dimensional space . . . . . . . . 147\\n10.14 Maximal margin hyperplane of a 3-sample set in 2-dimensional space . . . . . . . . 147\\n10.15 Soft margin hyperplanes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155\\n10.16 One-against all . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158\\n10.17 One-against-one . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159\\n11.1 A state diagram showing state transition probabilities . . . . . . . . . . . . . . . . . . 162\\n11.2 A two-coin model of an HMM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167\\n11.3 AnN-state urn and ball model which illustrates the general case of a discrete\\nsymbol HMM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168\\n11.4 Block diagram of an isolated word HMM recogniser . . . . . . . . . . . . . . . . . . 171\\n12.1 Example of random forest with majority voting . . . . . . . . . . . . . . . . . . . . . 177\\n13.1 Scatter diagram of data in Table 13.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . 180\\n13.2 Initial choice of cluster centres and the resulting clusters . . . . . . . . . . . . . . . . 181\\n13.3 Cluster centres after ﬁrst iteration and the corresponding clusters . . . . . . . . . . . 182\\n13.4 New cluster centres and the corresponding clusters . . . . . . . . . . . . . . . . . . . 183\\n13.5 Probability distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\n13.6 Graph of pdf deﬁned by Eq.(13.9) superimposed on the histogram of the data in\\nTable 13.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\\n13.7 A dendrogram of the dataset {a;b;c;d;e }. . . . . . . . . . . . . . . . . . . . . . . . 192\\n13.8 Different ways of drawing dendrogram . . . . . . . . . . . . . . . . . . . . . . . . . . 192\\n13.9 A dendrogram of the dataset {a;b;c;d;e }showing the distances (heights) of the\\nclusters at different levels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192\\n13.10 Hierarchical clustering using agglomerative method . . . . . . . . . . . . . . . . . . 193\\n13.11 Hierarchical clustering using divisive method . . . . . . . . . . . . . . . . . . . . . . 195\\n13.12 Length of the solid line “ ae” ismax{d(x;y)∶x∈A;y∈B}. . . . . . . . . . . . . . 196\\n13.13 Length of the solid line “ bc” ismin{d(x;y)∶x∈A;y∈B}. . . . . . . . . . . . . . 196\\n13.14 Dendrogram for the data given in Table 13.4 (complete linkage clustering) . . . . . 199\\n13.15 Dendrogram for the data given in Table 13.4 (single linkage clustering) . . . . . . . 200\\n13.16Dx= (average of dashed lines) −(average of solid lines) . . . . . . . . . . . . . . . . 201\\n13.17 Clusters of points and noise points not belonging to any of those clusters . . . . . . 203\\n13.18 With m0=4: (a)pa point of high density (b) pa core point (c) pa border point\\n(d)ra noise point . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203\\n13.19 With m0=4: (a)qis directly density-reachable from p(b)qis indirectly density-\\nreachable from p. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204Chapter 1\\nIntroduction to machine learning\\nIn this chapter, we consider different deﬁnitions of the term “machine learning” and explain what\\nis meant by “learning” in the context of machine learning. We also discuss the various components\\nof the machine learning process. There are also brief discussions about different types learning like\\nsupervised learning, unsupervised learning and reinforcement learning.\\n1.1 Introduction\\n1.1.1 Deﬁnition of machine learning\\nArthur Samuel, an early American leader in the ﬁeld of computer gaming and artiﬁcial intelligence,\\ncoined the term “Machine Learning” in 1959 while at IBM. He deﬁned machine learning as “the ﬁeld\\nof study that gives computers the ability to learn without being explicitly programmed.” However,\\nthere is no universally accepted deﬁnition for machine learning. Different authors deﬁne the term\\ndifferently. We give below two more deﬁnitions.\\n1. Machine learning is programming computers to optimize a performance criterion using exam-\\nple data or past experience. We have a model deﬁned up to some parameters, and learning is\\nthe execution of a computer program to optimize the parameters of the model using the train-\\ning data or past experience. The model may be predictive to make predictions in the future, or\\ndescriptive to gain knowledge from data, or both (see [2] p.3).\\n2. The ﬁeld of study known as machine learning is concerned with the question of how to con-\\nstruct computer programs that automatically improve with experience (see [4], Preface.).\\nRemarks\\nIn the above deﬁnitions we have used the term “model” and we will be using this term at several\\ncontexts later in this book. It appears that there is no universally accepted one sentence deﬁnition\\nof this term. Loosely, it may be understood as some mathematical expression or equation, or some\\nmathematical structures such as graphs and trees, or a division of sets into disjoint subsets, or a set\\nof logical “if :::then:::else:::” rules, or some such thing. It may be noted that this is not an\\nexhaustive list.\\n1.1.2 Deﬁnition of learning\\nDeﬁnition\\nA computer program is said to learn from experience Ewith respect to some class of tasks Tand\\nperformance measure P, if its performance at tasks T, as measured by P, improves with experience\\nE.\\n1CHAPTER 1. INTRODUCTION TO MACHINE LEARNING 2\\nExamples\\ni) Handwriting recognition learning problem\\n• TaskT: Recognising and classifying handwritten words within images\\n• Performance P: Percent of words correctly classiﬁed\\n• Training experience E: A dataset of handwritten words with given classiﬁcations\\nii) A robot driving learning problem\\n• TaskT: Driving on highways using vision sensors\\n• Performance measure P: Average distance traveled before an error\\n• training experience: A sequence of images and steering commands recorded while\\nobserving a human driver\\niii) A chess learning problem\\n• TaskT: Playing chess\\n• Performance measure P: Percent of games won against opponents\\n• Training experience E: Playing practice games against itself\\nDeﬁnition\\nA computer program which learns from experience is called a machine learning program or simply\\nalearning program . Such a program is sometimes also referred to as a learner .\\n1.2 How machines learn\\n1.2.1 Basic components of learning process\\nThe learning process, whether by a human or a machine, can be divided into four components,\\nnamely, data storage, abstraction, generalization and evaluation. Figure 1.1 illustrates the various\\ncomponents and the steps involved in the learning process.\\nData Concepts InferencesData storage Abstraction Generalization Evaluation\\nFigure 1.1: Components of learning process\\n1.Data storage\\nFacilities for storing and retrieving huge amounts of data are an important component of\\nthe learning process. Humans and computers alike utilize data storage as a foundation for\\nadvanced reasoning.\\n• In a human being, the data is stored in the brain and data is retrieved using electrochem-\\nical signals.\\n• Computers use hard disk drives, ﬂash memory, random access memory and similar de-\\nvices to store data and use cables and other technology to retrieve data.CHAPTER 1. INTRODUCTION TO MACHINE LEARNING 3\\n2.Abstraction\\nThe second component of the learning process is known as abstraction .\\nAbstraction is the process of extracting knowledge about stored data. This involves creating\\ngeneral concepts about the data as a whole. The creation of knowledge involves application\\nof known models and creation of new models.\\nThe process of ﬁtting a model to a dataset is known as training . When the model has been\\ntrained, the data is transformed into an abstract form that summarizes the original information.\\n3.Generalization\\nThe third component of the learning process is known as generalisation.\\nThe term generalization describes the process of turning the knowledge about stored data into\\na form that can be utilized for future action. These actions are to be carried out on tasks that\\nare similar, but not identical, to those what have been seen before. In generalization, the goal\\nis to discover those properties of the data that will be most relevant to future tasks.\\n4.Evaluation\\nEvaluation is the last component of the learning process.\\nIt is the process of giving feedback to the user to measure the utility of the learned knowledge.\\nThis feedback is then utilised to effect improvements in the whole learning process.\\n1.3 Applications of machine learning\\nApplication of machine learning methods to large databases is called data mining. In data mining, a\\nlarge volume of data is processed to construct a simple model with valuable use, for example, having\\nhigh predictive accuracy.\\nThe following is a list of some of the typical applications of machine learning.\\n1. In retail business, machine learning is used to study consumer behaviour.\\n2. In ﬁnance, banks analyze their past data to build models to use in credit applications, fraud\\ndetection, and the stock market.\\n3. In manufacturing, learning models are used for optimization, control, and troubleshooting.\\n4. In medicine, learning programs are used for medical diagnosis.\\n5. In telecommunications, call patterns are analyzed for network optimization and maximizing\\nthe quality of service.\\n6. In science, large amounts of data in physics, astronomy, and biology can only be analyzed fast\\nenough by computers. The World Wide Web is huge; it is constantly growing and searching\\nfor relevant information cannot be done manually.\\n7. In artiﬁcial intelligence, it is used to teach a system to learn and adapt to changes so that the\\nsystem designer need not foresee and provide solutions for all possible situations.\\n8. It is used to ﬁnd solutions to many problems in vision, speech recognition, and robotics.\\n9. Machine learning methods are applied in the design of computer-controlled vehicles to steer\\ncorrectly when driving on a variety of roads.\\n10. Machine learning methods have been used to develop programmes for playing games such as\\nchess, backgammon and Go.CHAPTER 1. INTRODUCTION TO MACHINE LEARNING 4\\n1.4 Understanding data\\nSince an important component of the machine learning process is data storage, we brieﬂy consider\\nin this section the different types and forms of data that are encountered in the machine learning\\nprocess.\\n1.4.1 Unit of observation\\nBy a unit of observation we mean the smallest entity with measured properties of interest for a study.\\nExamples\\n• A person, an object or a thing\\n• A time point\\n• A geographic region\\n• A measurement\\nSometimes, units of observation are combined to form units such as person-years.\\n1.4.2 Examples and features\\nDatasets that store the units of observation and their properties can be imagined as collections of\\ndata consisting of the following:\\n•Examples\\nAn “example” is an instance of the unit of observation for which properties have been recorded.\\nAn “example” is also referred to as an “instance”, or “case” or “record.” (It may be noted that\\nthe word “example” has been used here in a technical sense.)\\n•Features\\nA “feature” is a recorded property or a characteristic of examples. It is also referred to as\\n“attribute”, or “variable” or “feature.”\\nExamples for “examples” and “features”\\n1.Cancer detection\\nConsider the problem of developing an algorithm for detecting cancer. In this study we note\\nthe following.\\n(a) The units of observation are the patients.\\n(b) The examples are members of a sample of cancer patients.\\n(c) The following attributes of the patients may be chosen as the features:\\n• gender\\n• age\\n• blood pressure\\n• the ﬁndings of the pathology report after a biopsy\\n2.Pet selection\\nSuppose we want to predict the type of pet a person will choose.\\n(a) The units are the persons.\\n(b) The examples are members of a sample of persons who own pets.CHAPTER 1. INTRODUCTION TO MACHINE LEARNING 5\\nFigure 1.2: Example for “examples” and “features” collected in a matrix format (data relates to\\nautomobiles and their features)\\n(c) The features might include age, home region, family income, etc. of persons who own\\npets.\\n3.Spam e-mail\\nLet it be required to build a learning algorithm to identify spam e-mail.\\n(a) The unit of observation could be an e-mail messages.\\n(b) The examples would be speciﬁc messages.\\n(c) The features might consist of the words used in the messages.\\nExamples and features are generally collected in a “matrix format”. Fig. 1.2 shows such a data\\nset.\\n1.4.3 Different forms of data\\n1.Numeric data\\nIf a feature represents a characteristic measured in numbers, it is called a numeric feature.\\n2.Categorical or nominal\\nA categorical feature is an attribute that can take on one of a limited, and usually ﬁxed, number\\nof possible values on the basis of some qualitative property. A categorical feature is also called\\na nominal feature.\\n3.Ordinal data\\nThis denotes a nominal variable with categories falling in an ordered list. Examples include\\nclothing sizes such as small, medium, and large, or a measurement of customer satisfaction\\non a scale from “not at all happy” to “very happy.”\\nExamples\\nIn the data given in Fig.1.2, the features “year”, “price” and “mileage” are numeric and the features\\n“model”, “color” and “transmission” are categorical.CHAPTER 1. INTRODUCTION TO MACHINE LEARNING 6\\n1.5 General classes of machine learning problems\\n1.5.1 Learning associations\\n1. Association rule learning\\nAssociation rule learning is a machine learning method for discovering interesting relations, called\\n“association rules”, between variables in large databases using some measures of “interestingness”.\\n2. Example\\nConsider a supermarket chain. The management of the chain is interested in knowing whether\\nthere are any patterns in the purchases of products by customers like the following:\\n“If a customer buys onions and potatoes together, then he/she is likely to also buy\\nhamburger.”\\nFrom the standpoint of customer behaviour, this deﬁnes an association between the set of\\nproducts {onion, potato} and the set {burger}. This association is represented in the form of\\na rule as follows:\\n{onion, potato }⇒{burger}\\nThe measure of how likely a customer, who has bought onion and potato, to buy burger also\\nis given by the conditional probability\\nP({onion, potato }/divides.alt0{burger}):\\nIf this conditional probability is 0.8, then the rule may be stated more precisely as follows:\\n“80% of customers who buy onion and potato also buy burger.”\\n3. How association rules are made use of\\nConsider an association rule of the form\\nX⇒Y;\\nthat is, if people buy Xthen they are also likely to buy Y.\\nSuppose there is a customer who buys Xand does not buy Y. Then that customer is a potential\\nYcustomer. Once we ﬁnd such customers, we can target them for cross-selling. A knowledge of\\nsuch rules can be used for promotional pricing or product placements.\\n4. General case\\nIn ﬁnding an association rule X⇒Y, we are interested in learning a conditional probability of\\nthe formP(Y/divides.alt0X)whereYis the product the customer may buy and Xis the product or the set of\\nproducts the customer has already purchased.\\nIf we may want to make a distinction among customers, we may estimate P(Y/divides.alt0X;D)where\\nDis a set of customer attributes, like gender, age, marital status, and so on, assuming that we have\\naccess to this information.\\n5. Algorithms\\nThere are several algorithms for generating association rules. Some of the well-known algorithms\\nare listed below:\\na) Apriori algorithm\\nb) Eclat algorithm\\nc) FP-Growth Algorithm (FP stands for Frequency Pattern)CHAPTER 1. INTRODUCTION TO MACHINE LEARNING 7\\n1.5.2 Classiﬁcation\\n1. Deﬁnition\\nIn machine learning, classiﬁcation is the problem of identifying to which of a set of categories a\\nnew observation belongs, on the basis of a training set of data containing observations (or instances)\\nwhose category membership is known.\\n2. Example\\nConsider the following data:\\nScore1 29 22 10 31 17 33 32 20\\nScore2 43 29 47 55 18 54 40 41\\nResult Pass Fail Fail Pass Fail Pass Pass Pass\\nTable 1.1: Example data for a classiﬁcation problem\\nData in Table 1.1 is the training set of data. There are two attributes “Score1” and “Score2”. The\\nclass label is called “Result”. The class label has two possible values “Pass” and “Fail”. The data\\ncan be divided into two categories or classes: The set of data for which the class label is “Pass” and\\nthe set of data for which the class label is“Fail”.\\nLet us assume that we have no knowledge about the data other than what is given in the table.\\nNow, the problem can be posed as follows: If we have some new data, say “Score1 = 25” and\\n“Score2 = 36”, what value should be assigned to “Result” corresponding to the new data; in other\\nwords, to which of the two categories or classes the new observation should be assigned? See Figure\\n1.3 for a graphical representation of the problem.\\nScore1Score2\\n?\\n0 10 20 30 40102030405060\\nFigure 1.3: Graphical representation of data in Table 1.1. Solid dots represent data in “Pass” class\\nand hollow dots data in “Fail” class. The class label of the square dot is to be determined.\\nTo answer this question, using the given data alone we need to ﬁnd the rule, or the formula, or\\nthe method that has been used in assigning the values to the class label “Result”. The problem of\\nﬁnding this rule or formula or the method is the classiﬁcation problem. In general, even the general\\nform of the rule or function or method will not be known. So several different rules, etc. may have\\nto be tested to obtain the correct rule or function or method.CHAPTER 1. INTRODUCTION TO MACHINE LEARNING 8\\n3. Real life examples\\ni)Optical character recognition\\nOptical character recognition problem, which is the problem of recognizing character codes\\nfrom their images, is an example of classiﬁcation problem. This is an example where there\\nare multiple classes, as many as there are characters we would like to recognize. Especially\\ninteresting is the case when the characters are handwritten. People have different handwrit-\\ning styles; characters may be written small or large, slanted, with a pen or pencil, and there\\nare many possible images corresponding to the same character.\\nii)Face recognition\\nIn the case of face recognition , the input is an image, the classes are people to be recognized,\\nand the learning program should learn to associate the face images to identities. This prob-\\nlem is more difﬁcult than optical character recognition because there are more classes, input\\nimage is larger, and a face is three-dimensional and differences in pose and lighting cause\\nsigniﬁcant changes in the image.\\niii) Speech recognition\\nInspeech recognition , the input is acoustic and the classes are words that can be uttered.\\niv)Medical diagnosis\\nInmedical diagnosis , the inputs are the relevant information we have about the patient and\\nthe classes are the illnesses. The inputs contain the patient’s age, gender, past medical\\nhistory, and current symptoms. Some tests may not have been applied to the patient, and\\nthus these inputs would be missing.\\nv)Knowledge extraction\\nClassiﬁcation rules can also be used for knowledge extraction . The rule is a simple model\\nthat explains the data, and looking at this model we have an explanation about the process\\nunderlying the data.\\nvi)Compression\\nClassiﬁcation rules can be used for compression . By ﬁtting a rule to the data, we get an\\nexplanation that is simpler than the data, requiring less memory to store and less computation\\nto process.\\nvii) More examples\\nHere are some further examples of classiﬁcation problems.\\n(a) An emergency room in a hospital measures 17 variables like blood pressure, age, etc.\\nof newly admitted patients. A decision has to be made whether to put the patient in an\\nICU. Due to the high cost of ICU, only patients who may survive a month or more are\\ngiven higher priority. Such patients are labeled as “low-risk patients” and others are\\nlabeled “high-risk patients”. The problem is to device a rule to classify a patient as a\\n“low-risk patient” or a “high-risk patient”.\\n(b) A credit card company receives hundreds of thousands of applications for new cards.\\nThe applications contain information regarding several attributes like annual salary,\\nage, etc. The problem is to devise a rule to classify the applicants to those who are\\ncredit-worthy, who are not credit-worthy or to those who require further analysis.\\n(c) Astronomers have been cataloguing distant objects in the sky using digital images cre-\\nated using special devices. The objects are to be labeled as star, galaxy, nebula, etc.\\nThe data is highly noisy and are very faint. The problem is to device a rule using which\\na distant object can be correctly labeled.CHAPTER 1. INTRODUCTION TO MACHINE LEARNING 9\\n4. Discriminant\\nAdiscriminant of a classiﬁcation problem is a rule or a function that is used to assign labels to new\\nobservations.\\nExamples\\ni) Consider the data given in Table 1.1 and the associated classiﬁcation problem. We may\\nconsider the following rules for the classiﬁcation of the new data:\\nIF Score1+Score2≥60, THEN “Pass” ELSE “Fail”.\\nIF Score1 ≥20AND Score2 ≥40THEN “Pass” ELSE “Fail”.\\nOr, we may consider the following rules with unspeciﬁed values for M;m 1;m2and then by\\nsome method estimate their values.\\nIF Score1+Score2≥M, THEN “Pass” ELSE “Fail”.\\nIF Score1 ≥m1AND Score2 ≥m2THEN “Pass” ELSE “Fail”.\\nii) Consider a ﬁnance company which lends money to customers. Before lending money, the\\ncompany would like to assess the risk associated with the loan. For simplicity, let us assume\\nthat the company assesses the risk based on two variables, namely, the annual income and\\nthe annual savings of the customers.\\nLetx1be the annual income and x2be the annual savings of a customer.\\n• After using the past data, a rule of the following form with suitable values for \\x121and\\n\\x122may be formulated:\\nIFx1>\\x121ANDx2>\\x122THEN “low-risk” ELSE “high-risk”.\\nThis rule is an example of a discriminant.\\n• Based on the past data, a rule of the following form may also be formulated:\\nIFx2−0:2x1>0THEN “low-risk” ELSE “high-risk”.\\nIn this case the rule may be thought of as the discriminant. The function f(x1;x2)=\\nx2−0;2x1can also be considered as the discriminant.\\n5. Algorithms\\nThere are several machine learning algorithms for classiﬁcation. The following are some of the\\nwell-known algorithms.\\na) Logistic regression\\nb) Naive Bayes algorithm\\nc)k-NN algorithm\\nd) Decision tree algorithm\\ne) Support vector machine algorithm\\nf) Random forest algorithmCHAPTER 1. INTRODUCTION TO MACHINE LEARNING 10\\nRemarks\\n• A classiﬁcation problem requires that examples be classiﬁed into one of two or more classes.\\n• A classiﬁcation can have real-valued or discrete input variables.\\n• A problem with two classes is often called a two-class or binary classiﬁcation problem.\\n• A problem with more than two classes is often called a multi-class classiﬁcation problem.\\n• A problem where an example is assigned multiple classes is called a multi-label classiﬁcation\\nproblem.\\n1.5.3 Regression\\n1. Deﬁnition\\nIn machine learning, a regression problem is the problem of predicting the value of a numeric vari-\\nable based on observed values of the variable. The value of the output variable may be a number,\\nsuch as an integer or a ﬂoating point value. These are often quantities, such as amounts and sizes.\\nThe input variables may be discrete or real-valued.\\n2. Example\\nConsider the data on car prices given in Table 1.2.\\nPrice Age Distance Weight\\n(US$) (years) (KM) (pounds)\\n13500 23 46986 1165\\n13750 23 72937 1165\\n13950 24 41711 1165\\n14950 26 48000 1165\\n13750 30 38500 1170\\n12950 32 61000 1170\\n16900 27 94612 1245\\n18600 30 75889 1245\\n21500 27 19700 1185\\n12950 23 71138 1105\\nTable 1.2: Prices of used cars: example data for regression\\nSuppose we are required to estimate the price of a car aged 25 years with distance 53240 KM\\nand weight 1200 pounds. This is an example of a regression problem beause we have to predict the\\nvalue of the numeric variable “Price”.\\n3. General approach\\nLetxdenote the set of input variables and ythe output variable. In machine learning, the general\\napproach to regression is to assume a model, that is, some mathematical relation between xandy,\\ninvolving some parameters say, \\x12, in the following form:\\ny=f(x;\\x12)\\nThe function f(x;\\x12)is called the regression function . The machine learning algorithm optimizes\\nthe parameters in the set \\x12such that the approximation error is minimized; that is, the estimates\\nof the values of the dependent variable yare as close as possible to the correct values given in the\\ntraining set.CHAPTER 1. INTRODUCTION TO MACHINE LEARNING 11\\nExample\\nFor example, if the input variables are “Age”, “Distance” and “Weight” and the output variable\\nis “Price”, the model may be\\ny=f(x;\\x12)\\nPrice=a0+a1×(Age)+a2×(Distance)+a3×(Weight)\\nwherex=(Age, Distance, Weight )denotes the the set of input variables and \\x12=(a0;a1;a2;a3)\\ndenotes the set of parameters of the model.\\n4. Different regression models\\nThere are various types of regression techniques available to make predictions. These techniques\\nmostly differ in three aspects, namely, the number and type of independent variables, the type of\\ndependent variables and the shape of regression line. Some of these are listed below.\\n•Simple linear regression : There is only one continuous independent variable xand the as-\\nsumed relation between the independent variable and the dependent variable yis\\ny=a+bx:\\n•Multivariate linear regression : There are more than one independent variable, say x1;:::;xn,\\nand the assumed relation between the independent variables and the dependent variable is\\ny=a0+a1x1+/uni22EF+anxn:\\n•Polynomial regression : There is only one continuous independent variable xand the assumed\\nmodel is\\ny=a0+a1x+/uni22EF+anxn:\\n•Logistic regression : The dependent variable is binary, that is, a variable which takes only the\\nvalues 0and1. The assumed model involves certain probability distributions.\\n1.6 Different types of learning\\nIn general, machine learning algorithms can be classiﬁed into three types.\\n1.6.1 Supervised learning\\nSupervised learning is the machine learning task of learning a function that maps an input to an\\noutput based on example input-output pairs.\\nIn supervised learning, each example in the training set is a pair consisting of an input object\\n(typically a vector) and an output value. A supervised learning algorithm analyzes the training\\ndata and produces a function, which can be used for mapping new examples. In the optimal case,\\nthe function will correctly determine the class labels for unseen instances. Both classiﬁcation and\\nregression problems are supervised learning problems.\\nA wide range of supervised learning algorithms are available, each with its strengths and weak-\\nnesses. There is no single learning algorithm that works best on all supervised learning problems.CHAPTER 1. INTRODUCTION TO MACHINE LEARNING 12\\nFigure 1.4: Supervised learning\\nRemarks\\nA “supervised learning” is so called because the process of an algorithm learning from the training\\ndataset can be thought of as a teacher supervising the learning process. We know the correct answers\\n(that is, the correct outputs), the algorithm iteratively makes predictions on the training data and\\nis corrected by the teacher. Learning stops when the algorithm achieves an acceptable level of\\nperformance.\\nExample\\nConsider the following data regarding patients entering a clinic. The data consists of the\\ngender and age of the patients and each patient is labeled as “healthy” or “sick”.\\ngender age label\\nM 48 sick\\nM 67 sick\\nF 53 healthy\\nM 49 healthy\\nF 34 sick\\nM 21 healthy\\nBased on this data, when a new patient enters the clinic, how can one predict whether he/she\\nis healthy or sick?\\n1.6.2 Unsupervised learning\\nUnsupervised learning is a type of machine learning algorithm used to draw inferences from datasets\\nconsisting of input data without labeled responses.\\nIn unsupervised learning algorithms, a classiﬁcation or categorization is not included in the\\nobservations. There are no output values and so there is no estimation of functions. Since the\\nexamples given to the learner are unlabeled, the accuracy of the structure that is output by the\\nalgorithm cannot be evaluated.\\nThe most common unsupervised learning method is cluster analysis, which is used for ex-\\nploratory data analysis to ﬁnd hidden patterns or grouping in data.\\nExample\\nConsider the following data regarding patients entering a clinic. The data consists of the\\ngender and age of the patients.CHAPTER 1. INTRODUCTION TO MACHINE LEARNING 13\\ngender age\\nM 48\\nM 67\\nF 53\\nM 49\\nF 34\\nM 21\\nBased on this data, can we infer anything regarding the patients entering the clinic?\\n1.6.3 Reinforcement learning\\nReinforcement learning is the problem of getting an agent to act in the world so as to maximize its\\nrewards.\\nA learner (the program) is not told what actions to take as in most forms of machine learning, but\\ninstead must discover which actions yield the most reward by trying them. In the most interesting\\nand challenging cases, actions may affect not only the immediate reward but also the next situations\\nand, through that, all subsequent rewards.\\nFor example, consider teaching a dog a new trick: we cannot tell it what to do, but we can\\nreward/punish it if it does the right/wrong thing. It has to ﬁnd out what it did that made it get the\\nreward/punishment. We can use a similar method to train computers to do many tasks, such as\\nplaying backgammon or chess, scheduling jobs, and controlling robot limbs.\\nReinforcement learning is different from supervised learning. Supervised learning is learning\\nfrom examples provided by a knowledgeable expert.\\n1.7 Sample questions\\n(a) Short answer questions\\n1. What is meant by “learning” in the context of machine learning?\\n2. List out the types of machine learning.\\n3. Distinguish between classiﬁcation and regression.\\n4. What are the differences between supervised and unsupervised learning?\\n5. What is meant by supervised classiﬁcation?\\n6. Explain supervised learning with an example.\\n7. What do you mean by reinforcement learning?\\n8. What is an association rule?\\n9. Explain the concept of Association rule learning. Give the names of two algorithms for gen-\\nerating association rules.\\n10. What is a classiﬁcation problem in machine learning. Illustrate with an example.\\n11. Give three examples of classiﬁcation problems from real life situations.\\n12. What is a discriminant in a classiﬁcation problem?\\n13. List three machine learning algorithms for solving classiﬁcation problems.\\n14. What is a binary classiﬁcation problem? Explain with an example. Give also an example for\\na classiﬁcation problem which is not binary.\\n15. What is regression problem. What are the different types of regression?CHAPTER 1. INTRODUCTION TO MACHINE LEARNING 14\\n(b) Long answer questions\\n1. Give a deﬁnition of the term “machine learning”. Explain with an example the concept of\\nlearning in the context of machine learning.\\n2. Describe the basic components of the machine learning process.\\n3. Describe in detail applications of machine learning in any three different knowledge domains.\\n4. Describe with an example the concept of association rule learning. Explain how it is made\\nuse of in real life situations.\\n5. What is the classiﬁcation problem in machine learning? Describe three real life situations in\\ndifferent domains where such problems arise.\\n6. What is meant by a discriminant of a classiﬁcation problem? Illustrate the idea with examples.\\n7. Describe in detail with examples the different types of learning like the supervised learning,\\netc.Chapter 2\\nSome general concepts\\nIn this chapter we introduce some general concepts related to one of the simplest examples of su-\\npervised learning, namely, the classiﬁcation problem. We consider mainly binary classiﬁcation\\nproblems. In this context we introduce the concepts of hypothesis, hypothesis space and version\\nspace. We conclude the chapter with a brief discussion on how to select hypothesis models and how\\nto evaluate the performance of a model.\\n2.1 Input representation\\nThe general classiﬁcation problem is concerned with assigning a class label to an unknown instance\\nfrom instances of known assignments of labels. In a real world problem, a given situation or an\\nobject will have large number of features which may contribute to the assignment of the labels.\\nBut in practice, not all these features may be equally relevant or important. Only those which are\\nsigniﬁcant need be considered as inputs for assigning the class labels. These features are referred to\\nas the “input features” for the problem. They are also said to constitute an “ input representation ”\\nfor the problem.\\nExample\\nConsider the problem of assigning the label “family car” or “not family car” to cars. Let us\\nassume that the features that separate a family car from other cars are the price and engine\\npower. These attributes or features constitute the input representation for the problem. While\\ndeciding on this input representation, we are ignoring various other attributes like seating\\ncapacity or colour as irrelevant.\\n2.2 Hypothesis space\\nIn the following discussions we consider only “binary classiﬁcation” problems; that is, classiﬁcation\\nproblems with only two class labels. The class labels are usually taken as “ 1” and “ 0”. The label “1”\\nmay indicate “True”, or “Yes”, or “Pass”, or any such label. The label “0” may indicate “False”, or\\n“No” or “Fail”, or any such label. The examples with class labels 1are called “positive examples”\\nand examples with labels “0” are called “negative examples”.\\n2.2.1 Deﬁnition\\n1.Hypothesis\\nIn a binary classiﬁcation problem, a hypothesis is a statement or a proposition purporting to\\nexplain a given set of facts or observations.\\n15CHAPTER 2. SOME GENERAL CONCEPTS 16\\n2.Hypothesis space\\nThehypothesis space for a binary classiﬁcation problem is a set of hypotheses for the problem\\nthat might possibly be returned by it.\\n3.Consistency and satisfying\\nLetxbe an example in a binary classiﬁcation problem and let c(x)denote the class label\\nassigned tox(c(x)is 1 or 0). Let Dbe a set of training examples for the problem. Let hbe a\\nhypothesis for the problem and h(x)be the class label assigned to xby the hypothesis h.\\n(a) We say that the hypothesis hisconsistent with the set of training examples Difh(x)=\\nc(x)for allx∈D.\\n(b) We say that an example xsatisﬁes the hypothesis hifh(x)=1.\\n2.2.2 Examples\\n1. Consider the set of observations of a variable xwith the associated class labels given in Table\\n2.1:\\nx 27 15 23 20 25 17 12 30 6 10\\nClass 1 0 1 1 1 0 0 1 0 0\\nTable 2.1: Sample data to illustrate the concept of hypotheses\\nFigure 2.1 shows the data plotted on the x-axis.\\nx\\n0 27 23 20 25 30 10 17 12 15 6\\nFigure 2.1: Data in Table 2.1 with hollow dots representing positive examples and solid dots repre-\\nsenting negative examples\\nLooking at Figure 2.1, it appears that the class labeling has been done based on the following\\nrule.\\nh′: IFx≥20THEN “1” ELSE “0”. (2.1)\\nNote thath′is consistent with the training examples in Table 2.1. For example, we have:\\nh′(27)=1; c(27)=1; h′(27)=c(27)\\nh′(15)=0; c(15)=0; h′(15)=c(15)\\nNote also that, for x=5andx=28(not in training data),\\nh′(5)=0; h′(28)=1:\\nThe hypothesis h′explains the data. The following proposition also explains the data:\\nh′′: IFx≥19THEN “0” ELSE “1”. (2.2)\\nIt is not enough that the hypothesis explains the given data; it must also predict correctly the\\nclass label of future observations. So we consider a set of such hypotheses and choose the\\n“best” one. The set of hypotheses can be deﬁned using a parameter, say m, as given below:\\nhm: IFx≥mTHEN “1” ELSE ”0”. (2.3)CHAPTER 2. SOME GENERAL CONCEPTS 17\\nThe set of all hypotheses obtained by assigning different values to mconstitutes the hypothesis\\nspaceH; that is,\\nH={hm∶mis a real number }: (2.4)\\nFor the same data, we can have different hypothesis spaces. For example, for the data in Table\\n2.1, we may also consider the hypothesis space deﬁned by the following proposition:\\nh′\\nm: IFx≤mTHEN “0” ELSE “1”.\\n2. Consider a situation with four binary variables x1,x2,x3,x4and one binary output variable\\ny. Suppose we have the following observations.\\nx1x2x3x4y\\n0 0 0 1 1\\n0 1 0 1 0\\n1 1 0 0 1\\n0 0 1 0 0\\nThe problem is to predict a function fofx1,x2,x3,x4which predicts the value of yfor any\\ncombination of values of x1,x2,x3,x4. In this problem, the hypothesis space is the set of all\\npossible functions f. It can be shown that the size of the hypothesis space is 2(24)=65536 .\\n3. Consider the problem of assigning the label “family car” or “not family car” to cars. For\\nconvenience, we shall replace the label “family car” by “1” and “not family car” by “0”.\\nSuppose we choose the features “price (’000 $)” and “power (hp)” as the input representation\\nfor the problem. Further, suppose that there is some reason to believe that for a car to be a\\nfamily car, its price and power should be in certain ranges. This supposition can be formulated\\nin the form of the following proposition:\\nIF(p1<price<p2)AND(e1<power<e2)THEN “1” ELSE ”0” (2.5)\\nfor suitable values of p1,p2,e1ande2. Since a solution to the problem is a proposition of the\\nform Eq.(2.5) with speciﬁc values for p1,p2,e1ande2, the hypothesis space for the problem\\nis the set of all such propositions obtained by assigning all possible values for p1,p2,e1and\\ne2.\\npower (hp)\\nprice (’000 $)\\np1 p2e1e2\\nh(x1;x2)=1\\nx1x2hypothesish\\nFigure 2.2: An example hypothesis deﬁned by Eq. (2.5)\\nIt is interesting to observe that the set of points in the power–price plane which satisﬁes the\\ncondition\\n(p1<price<p2)AND(e1<power<e2)\\ndeﬁnes a rectangular region (minus the boundary) in the price–power space as shown in Figure\\n2.2. The sides of this rectangular region are parallel to the coordinate axes. Such a rectangleCHAPTER 2. SOME GENERAL CONCEPTS 18\\nis called an axis-aligned rectangle Ifhis the hypothesis deﬁned by Eq.(2.5), and (x1;x2)\\nis any point in the price–power plane, then h(x1;x2)=1if and only if (x1;x2)is within\\nthe rectangular region. Hence we may identify the hypothesis hwith the rectangular region.\\nThus, the hypothesis space for the problem can be thought of as the set of all axis-aligned\\nrectangles in the price–power plane.\\n4. Consider the trading agent trying to infer which books or articles the user reads based on\\nkeywords supplied in the article. Suppose the learning agent has the following data (“1\"\\nindicates “True” and “0” indicates “False”):\\narticle crime academic local music reads\\na1 true false false true 1\\na2 true false false false 1\\na3 false true false false 0\\na4 false false true false 0\\na5 true true false false 1\\nThe aim is to learn which articles the user reads. The aim is to ﬁnd a deﬁnition such as\\nIF (crime OR (academic AND (NOT music))) THEN ”1” ELSE ”0”.\\nThe hypothesis space H could be all boolean combinations of the input features or could be\\nmore restricted, such as conjunctions or propositions deﬁned in terms of fewer than three\\nfeatures.\\n2.3 Ordering of hypotheses\\nDeﬁnition\\nLetXbe the set of all possible examples for a binary classiﬁcation problem and let h′andh′′be\\ntwo hypotheses for the problem.\\nS′={x∈X∶h′(x)=1}S′′={x∈X∶h′′(x)=1}\\nFigure 2.3: Hypothesis h′is more general than hypothesis h′′if and only if S′′⊆S′\\n1. We say that h′ismore general than h′′if and only if for every x∈X, ifxsatisﬁesh′′thenx\\nsatisﬁesh′also; that is, if h′′(x)=1thenh′(x)=1also. The relation “is more general than”\\ndeﬁnes a partial ordering relation in hypothesis space.\\n2. We say that h′ismore speciﬁc thanh′′, ifh′′is more general than h′.\\n3. We say that h′isstrictly more general than h′′ifh′is more general than h′′andh′′isnot\\nmore general than h′.\\n4. We say that h′isstrictly more speciﬁc than h′′ifh′is more speciﬁc than h′′andh′′isnot\\nmore speciﬁc than h′.CHAPTER 2. SOME GENERAL CONCEPTS 19\\nExample\\nConsider the hypotheses h′andh′′deﬁned in Eqs.(2.1),(2.2). Then it is easy to check that if\\nh′(x)=1thenh′′(x)=1also. So,h′′is more general than h′. But,h′is not more general\\nthanh′′and soh′′is strictly more general than h′.\\n2.4 Version space\\nDeﬁnition\\nConsider a binary classiﬁcation problem. Let Dbe a set of training examples and Ha hypothesis\\nspace for the problem. The version space for the problem with respect to the set Dand the space H\\nis the set of hypotheses from Hconsistent with D; that is, it is the set\\nVSD;H={h∈H∶h(x)=c(x)for allx∈D}:\\n2.4.1 Examples\\nExample 1\\nConsider the data Dgiven in Table 2.1 and the hypothesis space deﬁned by Eqs.(2.3)-(2.4).\\nx\\n0 27 23 20 25 30 10 17 12 15 6m\\nFigure 2.4: Values of mwhich deﬁne the version space with data in Table 2.1 and hypothesis space\\ndeﬁned by Eq.(2.4)\\nFrom Figure 2.4 we can easily see that the hypothesis space with respect this dataset Dand\\nhypothesis space His as given below:\\nVSD;H={hm∶17<m≤20}:\\nExample 2\\nConsider the problem of assigning the label “family car” (indicated by “1”) or “not family car”\\n(indicated by “0”) to cars. Given the following examples for the problem and assuming that the\\nhypothesis space is as deﬁned by Eq. (2.5), the version space for the problem.\\nx1: Price in ’000 ($) 32 82 44 34 43 80 38\\nx2: Power (hp) 170 333 220 235 245 315 215\\nClass 0 0 1 1 1 0 1\\nx1 47 27 56 28 20 25 66 75\\nx2 260 290 320 305 160 300 250 340\\nClass 1 0 0 0 0 0 0 0\\nSolution\\nFigure 2.5 shows a scatter plot of the given data. In the ﬁgure, the data with class label “1” (family\\ncar) is shown as hollow circles and the data with class labels “0” (not family car) are shown as solid\\ndots.\\nA hypothesis as given by Eq.(2.5) with speciﬁc values for the parameters p1,p2,e1ande2\\nspeciﬁes an axis-aligned rectangle as shown in Figure 2.2. So the hypothesis space for the problem\\ncan be thought as the set of axis-aligned rectangles in the price-power plane.CHAPTER 2. SOME GENERAL CONCEPTS 20\\npower (hp)\\nprice (’000 $)\\n10 20 30 40 50 60 70 80 90150200250300350\\nFigure 2.5: Scatter plot of price-power data (hollow circles indicate positive examples and solid dots\\nindicate negative examples)\\npower (hp)\\nprice (’000 $)\\n10 20 30 40 50 60 70 80 90150200250300350\\n(32;170)(66;250)(27;290)\\n(34;235)\\n(38;215)(47;260)\\nFigure 2.6: The version space consists of hypotheses corresponding to axis-aligned rectangles con-\\ntained in the shaded region\\nThe version space consists of all hypotheses speciﬁed by axis-aligned rectangles contained in\\nthe shaded region in Figure 2.6. The inner rectangle is deﬁned by\\n(34<price<47)AND(215<power<260)\\nand the outer rectangle is deﬁned by\\n(27<price<66)AND(170<power<290):\\nExample 3\\nConsider the problem of ﬁnding a rule for determining days on which one can enjoy water sport. The\\nrule is to depend on a few attributes like “temp”, ”humidity”, etc. Suppose we have the following\\ndata to help us devise the rule. In the data, a value of “1” for “enjoy” means “yes” and a value of\\n“0” indicates ”no”.CHAPTER 2. SOME GENERAL CONCEPTS 21\\nExample sky temp humidity wind water forecast enjoy\\n1 sunny warm normal strong warm same 1\\n2 sunny warm high strong warm same 1\\n3 rainy cold high strong warm change 0\\n4 sunny warm high strong cool change 1\\nFind the hypothesis space and the version space for the problem. (For a detailed discussion of this\\nproblem see [4] Chapter2.)\\nSolution\\nWe are required to ﬁnd a rule of the following form, consistent with the data, as a solution of the\\nproblem.\\n(sky=x1)∧(temp=x2)∧(humidity=x3)∧\\n(wind=x4)∧(water=x5)∧(forecast=x6)↔yes (2.6)\\nwhere\\nx1=sunny, warm, /uni22C6\\nx2=warm, cold, /uni22C6\\nx3=normal, high, /uni22C6\\nx4=strong,/uni22C6\\nx5=warm, cool, /uni22C6\\nx6=same, change, /uni22C6\\n(Here a “/uni22C6” indicates other possible values of the attributes.) The hypothesis may be represented\\ncompactly as a vector\\n(a1;a2;a3;a4;a5;a6)\\nwhere, in the positions of a1;:::;a 6, we write\\n• a “?” to indicate that any value is acceptable for the corresponding attribute,\\n• a ”/uni2205” to indicate that no value is acceptable for the corresponding attribute,\\n• some speciﬁc single required value for the corresponding attribute\\nFor example, the vector\\n(?, cold, high, ?, ?, ?)\\nindicates the hypothesis that one enjoys the sport only if “temp” is “cold” and “humidity” is “high”\\nwhatever be the values of the other attributes.\\nIt can be shown that the version space for the problem consists of the following six hypotheses\\nonly:\\n(sunny, warm, ?, strong, ?, ?)\\n(sunny, ?, ?, strong, ?, ?)\\n(sunny, warm, ?, ?, ?, ?)\\n(?, warm, ?, strong, ?, ?)\\n(sunny, ?, ?, ?, ?, ?)\\n(?, warm, ?, ?, ?, ?)CHAPTER 2. SOME GENERAL CONCEPTS 22\\n2.5 Noise\\n2.5.1 Noise and their sources\\nNoise is any unwanted anomaly in the data ([2] p.25). Noise may arise due to several factors:\\n1. There may be imprecision in recording the input attributes, which may shift the data points in\\nthe input space.\\n2. There may be errors in labeling the data points, which may relabel positive instances as nega-\\ntive and vice versa. This is sometimes called teacher noise.\\n3. There may be additional attributes, which we have not taken into account, that affect the label\\nof an instance. Such attributes may be hidden or latent in that they may be unobservable. The\\neffect of these neglected attributes is thus modeled as a random component and is included in\\n“noise.”\\n2.5.2 Effect of noise\\nNoise distorts data. When there is noise in data, learning problems may not produce accurate results.\\nAlso, simple hypotheses may not be sufﬁcient to explain the data and so complicated hypotheses\\nmay have to be formulated. This leads to the use of additional computing resources and the needless\\nwastage of such resources.\\nFor example, in a binary classiﬁcation problem with two variables, when there is noise, there\\nmay not be a simple boundary between the positive and negative instances and to separate them. A\\nrectangle can be deﬁned by four numbers, but to deﬁne a more complicated shape one needs a more\\ncomplex model with a much larger number of parameters. So, when there is noise, we may make a\\ncomplex model which makes a perfect ﬁt to the data and attain zero error; or, we may use a simple\\nmodel and allow some error.\\n2.6 Learning multiple classes\\nSo far we have been discussing binary classiﬁcation problems. In a general case there may be more\\nthan two classes. Two methods are generally used to handle such cases. These methods are known\\nby the names “one-against-all\" and “one-against-one”.\\n2.6.1 Procedures for learning multiple classes\\n“One-against all” method\\nConsider the case where there are Kclasses denoted by C1;:::;CK. Each input instance belongs\\nto exactly one of them.\\nWe view aK-class classiﬁcation problem as Ktwo-class problems. In the i-th two-class prob-\\nlem, the training examples belonging to Ciare taken as the positive examples and the examples of\\nall other classes are taken as the negative examples. So, we have to ﬁnd Khypothesesh1;:::;hK\\nwherehiis deﬁned by\\nhi(x)=/uni23A7/uni23AA/uni23AA/uni23A8/uni23AA/uni23AA/uni23A91ifxis in classCi\\n0otherwise\\nFor a given x, ideally only one of hi(x)is1and then we assign the class Citox. But, when\\nno, or, two or more, hi(x)is1, we cannot choose a class. In such a case, we say that the classiﬁer\\nrejects such cases.CHAPTER 2. SOME GENERAL CONCEPTS 23\\n“One-against-one” method\\nIn the one-against-one (OAO) (also called one-vs-one (OVO)) strategy, a classiﬁer is constructed\\nfor each pair of classes. If there are Kdifferent class labels, a total of K(K−1)/slash.left2classiﬁers are\\nconstructed. An unknown instance is classiﬁed with the class getting the most votes. Ties are broken\\narbitrarily.\\nFor example, let there be three classes, A,BandC. In the OVO method we construct 3(3−\\n1)/slash.left2=3binary classiﬁers. Now, if any xis to be classiﬁed, we apply each of the three classiﬁers to\\nx. Let the three classiﬁers assign the classes A,B,Brespectively to x. Since a label to xis assigned\\nby the majority voting, in this example, we assign the class label of Btox.\\n2.7 Model selection\\nAs we have pointed earlier in Section 1.1.1, there is no universally accepted deﬁnition of the term\\n“model”. It may be understood as some mathematical expression or equation, or some mathematical\\nstructures such as graphs and trees, or a division of sets into disjoint subsets, or a set of logical “if\\n:::then:::else:::” rules, or some such thing.\\nIn order to formulate a hypothesis for a problem, we have to choose some model and the term\\n“model selection” has been used to refer to the process of choosing a model. However, the term has\\nbeen used to indicate several things. In some contexts it has been used to indicates the process of\\nchoosing one particular approach from among several different approaches. This may be choosing\\nan appropriate algorithms from a selection of possible algorithms, or choosing the sets of features\\nto be used for input, or choosing initial values for certain parameters. Sometimes “model selection”\\nrefers to the process of picking a particular mathematical model from among different mathematical\\nmodels which all purport to describe the same data set. It has also been described as the process of\\nchoosing the right inductive bias.\\n2.7.1 Inductive bias\\nIn a learning problem we only have the data. But data by itself is not sufﬁcient to ﬁnd the solution.\\nWe should make some extra assumptions to have a solution with the data we have. The set of\\nassumptions we make to have learning possible is called the inductive bias of the learning algorithm.\\nOne way we introduce inductive bias is when we assume a hypothesis class.\\nExamples\\n• In learning the class of family car, there are inﬁnitely many ways of separating the positive\\nexamples from the negative examples. Assuming the shape of a rectangle is an inductive bias.\\n• In regression, assuming a linear function is an inductive bias.\\nThe model selection is about choosing the right inductive bias.\\n2.7.2 Advantages of a simple model\\nEven though a complex model may not be making any errors in prediction, there are certain advan-\\ntages in using a simple model.\\n1. A simple model is easy to use.\\n2. A simple model is easy to train. It is likely to have fewer parameters.\\nIt is easier to ﬁnd the corner values of a rectangle than the control points of an arbitrary shape.\\n3. A simple model is easy to explain.CHAPTER 2. SOME GENERAL CONCEPTS 24\\n4. A simple model would generalize better than a complex model. This principle is known as\\nOccam’s razor, which states that simpler explanations are more plausible and any unnecessary\\ncomplexity should be shaved off.\\nRemarks\\nA model should not be too simple! With a small training set when the training instances differ a\\nlittle bit, we expect the simpler model to change less than a complex model: A simple model is thus\\nsaid to have less variance . On the other hand, a too simple model assumes more, is more rigid, and\\nmay fail if indeed the underlying class is not that simple. A simpler model has more bias. Finding\\nthe optimal model corresponds to minimizing both the bias and the variance.\\n2.8 Generalisation\\nHow well a model trained on the training set predicts the right output for new instances is called\\ngeneralization .\\nGeneralization refers to how well the concepts learned by a machine learning model apply to\\nspeciﬁc examples not seen by the model when it was learning. The goal of a good machine learning\\nmodel is to generalize well from the training data to any data from the problem domain. This allows\\nus to make predictions in the future on data the model has never seen. Overﬁtting and underﬁtting\\nare the two biggest causes for poor performance of machine learning algorithms. The model should\\nbe selected having the best generalisation. This is said to be the case if these problems are avoided.\\n•Underﬁtting\\nUnderﬁtting is the production of a machine learning model that is not complex enough to\\naccurately capture relationships between a datasetâ ˘A´Zs features and a target variable.\\n•Overﬁtting\\nOverﬁtting is the production of an analysis which corresponds too closely or exactly to a\\nparticular set of data, and may therefore fail to ﬁt additional data or predict future observations\\nreliably.\\nExample 1\\n(a) Given dataset (b) “Just right” model\\n(c) Underﬁtting model (d) Overﬁtting model\\nFigure 2.7: Examples for overﬁtting and overﬁtting modelsCHAPTER 2. SOME GENERAL CONCEPTS 25\\nConsider a dataset shown in Figure 2.7(a). Let it be required to ﬁt a regression model to the data. The\\ngraph of a model which looks “just right” is shown in Figure 2.7(b). In Figure 2.7(c)we have a linear\\nregression model for the same dataset and this model does seem to capture the essential features of\\nthe dataset. So this model suffers from underﬁtting. In Figure 2.7(d) we have a regression model\\nwhich corresponds too closely to the given dataset and hence it does not account for small random\\nnoises in the dataset. Hence it suffers from overﬁtting.\\nExample 2\\n(a) Underﬁtting (b) Right ﬁtting (c) Overﬁtting\\nFigure 2.8: Fitting a classiﬁcation boundary\\nSuppose we have to determine the classiﬁcation boundary for a dataset two class labels. An example\\nsituation is shown in Figure 2.8 where the curved line is the classiﬁcation boundary. The three ﬁgures\\nillustrate the cases of underﬁtting, right ﬁtting and overﬁtting.\\n2.8.1 Testing generalisation: Cross-validation\\nWe can measure the generalization ability of a hypothesis, namely, the quality of its inductive bias,\\nif we have access to data outside the training set. We simulate this by dividing the training set we\\nhave into two parts. We use one part for training (that is, to ﬁnd a hypothesis), and the remaining\\npart is called the validation set and is used to test the generalization ability. Assuming large enough\\ntraining and validation sets, the hypothesis that is the most accurate on the validation set is the best\\none (the one that has the best inductive bias). This process is called cross-validation .\\n2.9 Sample questions\\n(a) Short answer questions\\n1. Explain the general-to-speciﬁc ordering of hypotheses.\\n2. In the context of classiﬁcation problems explain with examples the following: (i) hypothesis\\n(ii) hypothesis space.\\n3. Deﬁne the version space of a binary classiﬁcation problem.\\n4. Explain the “one-against-all” method for learning multiple classes.\\n5. Describe the “one-against-one” method for learning multiple classes.\\n6. What is meant by inductive bias in machine learning? Give an example.\\n7. What is meant by overﬁtting of data? Explain with an example.\\n8. What is meant by overﬁtting and underﬁtting of data with examples.CHAPTER 2. SOME GENERAL CONCEPTS 26\\n(b) Long answer questions\\n1. Deﬁne version space and illustrate it with an example.\\n2. Given the following data\\nx 0 3 5 9 12 18 23\\nLabel 0 0 0 1 1 1 1\\nand the hypothesis space\\nH={hm/divides.alt0ma real number }\\nwherehmis deﬁned by\\nIFx≤mTHEN 1ELSE 0;\\nﬁnd the version space the problem with respect to DandH.\\n3. What is meant by “noise” in data? What are its sources and how it is affecting results?\\n4. Consider the following data:\\nx 2 3 5 8 10 15 16 18 20\\ny 12 15 10 6 8 10 7 9 10\\nClass label 0 0 1 1 1 1 0 0 0\\nDetermine the version space if the hypothesis space consists of all hypotheses of the form\\nIF(x1<x<x2)AND(y1<y<y2)THEN “1” ELSE ”0” :\\n5. For the date in problem 4, what would be the version space if the hypothesis space consists of\\nall hypotheses of the form\\nIF(x−x1)2+(y−y1)2≤r2THEN “1” ELSE ”0” :\\n6. What issues are to be considered while selecting a model for applying machine learning in a\\ngiven problem.Chapter 3\\nVC dimension and PAC learning\\nThe concepts of Vapnik-Chervonenkis dimension (VC dimension) and probably approximate correct\\n(PAC) learning are two important concepts in the mathematical theory of learnability and hence are\\nmathematically oriented. The former is a measure of the capacity (complexity, expressive power,\\nrichness, or ﬂexibility) of a space of functions that can be learned by a classiﬁcation algorithm.\\nIt was originally deﬁned by Vladimir Vapnik and Alexey Chervonenkis in 1971. The latter is a\\nframework for the mathematical analysis of learning algorithms. The goal is to check whether the\\nprobability for a selected hypothesis to be approximately correct is very high. The notion of PAC\\nlearning was proposed by Leslie Valiant in 1984.\\n3.1 Vapnik-Chervonenkis dimension\\nLetHbe the hypothesis space for some machine learning problem. The Vapnik-Chervonenkis\\ndimension of H, also called the VC dimension of H, and denoted by VC(H), is a measure of the\\ncomplexity (or, capacity, expressive power, richness, or ﬂexibility) of the space H. To deﬁne the VC\\ndimension we require the notion of the shattering of a set of instances.\\n3.1.1 Shattering of a set\\nLetDbe a dataset containing Nexamples for a binary classiﬁcation problem with class labels 0\\nand1. LetHbe a hypothesis space for the problem. Each hypothesis hinHpartitionsDinto two\\ndisjoint subsets as follows:\\n{x∈D/divides.alt0h(x)=0}and{x∈D/divides.alt0h(x)=1}:\\nSuch a partition of Sis called a “ dichotomy ” inD. It can be shown that there are 2Npossible\\ndichotomies in D. To each dichotomy of Dthere is a unique assignment of the labels “1” and “0”\\nto the elements of D. Conversely, if Sis any subset of Dthen,Sdeﬁnes a unique hypothesis has\\nfollows:\\nh(x)=/uni23A7/uni23AA/uni23AA/uni23A8/uni23AA/uni23AA/uni23A91ifx∈S\\n0otherwise\\nThus to specify a hypothesis h, we need only specify the set {x∈D/divides.alt0h(x)=1}.\\nFigure 3.1 shows all possible dichotomies of DifDhas three elements. In the ﬁgure, we have\\nshown only one of the two sets in a dichotomy, namely the set {x∈D/divides.alt0h(x)=1}. The circles and\\nellipses represent such sets.\\n27CHAPTER 3. VC DIMENSION AND PAC LEARNING 28\\na\\nbca\\nbca\\nbca\\nbc\\n(i) Emty set (ii) (iii) (iv)\\na\\nbca\\nbca\\nbca\\nbc\\n(v) (vi) (vii) (viii) Full set D\\nFigure 3.1: Different forms of the set {x∈S∶h(x)=1}forD={a;b;c}\\nWe require the notion of a hypothesis consistent with a set of examples introduced in Section 2.4\\nin the following deﬁnition.\\nDeﬁnition\\nA set of examples Dis said to be shattered by a hypothesis space Hif and only if for every di-\\nchotomy ofDthere exists some hypothesis in Hconsistent with the dichotomy of D.\\n3.1.2 Vapnik-Chervonenkis dimension\\nThe following example illustrates the concept of Vapnik-Chervonenkis dimension.\\nExample\\nLet the instance space Xbe the set of all real numbers. Consider the hypothesis space deﬁned by\\nEqs.(2.3)-(2.4):\\nH={hm∶mis a real number };\\nwhere\\nhm∶IFx≥mTHEN ”1” ELSE “0” :\\ni) LetDbe a subset of Xcontaining only a single number, say, D={3:5}. There are 2\\ndichotomies for this set. These correspond to the following assignment of class labels:\\nx 3.25\\nLabel 0x 3.25\\nLabel 1\\nh4∈His consistent with the former dichotomy and h3∈His consistent with the latter. So,\\nto every dichotomy in Dthere is a hypothesis in Hconsistent with the dichotomy. Therefore,\\nthe setDis shattered by the hypothesis space H.\\nii) LetDbe a subset of Xcontaining two elements, say, D={3:25;4:75}. There are 4 di-\\nchotomies in Dand they correspond to the assignment of class labels shown in Table 3.1.\\nIn these dichotomies, h5is consistent with (a), h4is consistent with (b) and h3is consistent\\nwith (d). But there is no hypothesis hm∈Hconsistent with (c). Thus the two-element set D\\nis not shattered by H. In a similar way it can be shown that there is no two-element subset\\nofXwhich is shattered by H.\\nIt follows that the size of the largest ﬁnite subset of Xshattered by His1. This number is the\\nVC dimension of H.CHAPTER 3. VC DIMENSION AND PAC LEARNING 29\\nx 3.25 4.75\\nLabel 0 0x 3.25 4.75\\nLabel 0 1\\n(a) (b)\\nx 3.25 4.75\\nLabel 1 0x 3.25 4.75\\nLabel 1 1\\n(c) (d)\\nTable 3.1: Different assignments of class labels to the elements of {3:25;4:75}\\nDeﬁnition\\nTheVapnik-Chervonenkis dimension (VC dimension ) of a hypothesis space Hdeﬁned over an in-\\nstance space (that is, the set of all possible examples) X, denoted by VC(H), is the size of the\\nlargest ﬁnite subset of Xshattered by H. If arbitrarily large subsets of Xcan be shattered by H,\\nthen we deﬁne VC(H)=∞.\\nRemarks\\nIt can be shown that VC(H)≤log2(/divides.alt0H/divides.alt0)whereHis the number of hypotheses in H.\\n3.1.3 Examples\\n1. LetXbe the set of all real numbers (say, for example, the set of heights of people). For any\\nreal numbers aandbdeﬁne a hypothesis ha;bas follows:\\nha;b(x)=/uni23A7/uni23AA/uni23AA/uni23A8/uni23AA/uni23AA/uni23A91ifa<x<b\\n0otherwise\\nLet the hypothesis space Hconsist of all hypotheses of the form ha;b. We show that VC(H)=\\n2. We have to show that there is a subset of Xof size 2shattered by Hand there is no subset\\nof size 3shattered by H.\\n• Consider the two-element set D={3:25;4:75}. The various dichotomies of Dare\\ngiven in Table 3.1. It can be seen that the hypothesis h5;6is consistent with (a), h4;5is\\nconsistent with (b), h3;4is consistent with (c) and h3;5is consistent with (d). So the set\\nDis shattered by H.\\n• Consider a three-element subset D={x1;x2;x3}. Let us assume that x1<x2<x3.H\\ncannot shatter this subset because the dichotomy represented by the set {x1;x3}cannot\\nbe represented by a hypothesis in H(any interval containing both x1andx3will contain\\nx2also).\\nTherefore, the size of the largest subset of Xshattered by His2and soVC(H)=2.\\n2. Let the instance space Xbe the set of all points (x;y)in a plane. For any three real numbers,\\na;b;c deﬁne a class labeling as follows:\\nha;b;c(x;y)=/uni23A7/uni23AA/uni23AA/uni23A8/uni23AA/uni23AA/uni23A91ifax+by+c>0\\n0otherwiseCHAPTER 3. VC DIMENSION AND PAC LEARNING 30\\nOxy\\nha;b;c(x;y)=0\\nax+by+c=0\\n(assumec<0)ha;b;c(x;y)=0\\nax+by+c<0ha;b;c(x;y)=1\\nax+by+c>0\\nFigure 3.2: Geometrical representation of the hypothesis ha;b;c\\nLetHbe the set of all hypotheses of the form ha;b;c. We show that VC(H)=3. We have\\nshow that there is a subset of size 3shattered by Hand there is no subset of size 4shattered\\nbyH.\\n• Consider a set D={A;B;C }of three non-collinear points in the plane. There are 8sub-\\nsets ofDand each of these deﬁnes a dichotomy of D. We can easily ﬁnd 8hypotheses\\ncorresponding to the dichotomies deﬁned by these subsets (see Figure 3.3).\\nA\\nBC\\nFigure 3.3: A hypothesis ha;b;c consistent with the dichotomy deﬁned by the subset\\n{A;C}of{A;B;C }\\n• Consider a set S={A;B;C;D }of four points in the plane. Let no three of these points\\nbe collinear. Then, the points form a quadrilateral. It can be easily seen that, in this case,\\nthere is no hypothesis for which the two element set formed by the ends of a diagonal is\\nthe corresponding dichotomy (see Figure 3.4).\\nA\\nBCD\\nFigure 3.4: There is no hypothesis ha;b;c consistent with the dichotomy deﬁned by the\\nsubset{A;C}of{A;B;C;D }\\nSo the set cannot be shattered by H. If any three of them are collinear, then by some\\ntrial and error, it can be seen that in this case also the set cannot be shattered by H. No\\nset with four elements cannot be shattered by H.\\nFrom the above discussion we conclude that VC(H)=3.\\n3. LetXbe set of all conjunctions of nboolean literals. Let the hypothesis space Hconsists of\\nconjunctions of up to nliterals. It can be shown that VC(H)=n. (The full details of the\\nproof of this is beyond the scope of these notes.)CHAPTER 3. VC DIMENSION AND PAC LEARNING 31\\n3.2 Probably approximately correct learning\\nIn computer science, computational learning theory (or just learning theory ) is a subﬁeld of artiﬁcial\\nintelligence devoted to studying the design and analysis of machine learning algorithms. In compu-\\ntational learning theory, probably approximately correct learning (PAC learning) is a framework for\\nmathematical analysis of machine learning algorithms. It was proposed in 1984 by Leslie Valiant.\\nIn this framework, the learner (that is, the algorithm) receives samples and must select a hypoth-\\nesis from a certain class of hypotheses. The goal is that, with high probability (the “probably” part),\\nthe selected hypothesis will have low generalization error (the “approximately correct” part).\\nIn this section we ﬁrst give an informal deﬁnition of PAC-learnability. After introducing a few\\nnore notions, we give a more formal, mathematically oriented, deﬁnition of PAC-learnability. At the\\nend, we mention one of the applications of PAC-learnability.\\n3.2.1 PAC-learnability\\nTo deﬁne PAC-learnability we require some speciﬁc terminology and related notations.\\n• LetXbe a set called the instance space which may be ﬁnite or inﬁnite. For example, Xmay\\nbe the set of all points in a plane.\\n• Aconcept class CforXis a family of functions c∶X→{0;1}. A member of Cis called a\\nconcept . A concept can also be thought of as a subset of X. IfCis a subset of X, it deﬁnes a\\nunique function \\x16C∶X→{0;1}as follows:\\n\\x16C(x)=/uni23A7/uni23AA/uni23AA/uni23A8/uni23AA/uni23AA/uni23A91ifx∈C\\n0otherwise\\n• Ahypothesishis also a function h∶X→{0;1}. So, as in the case of concepts, a hypothesis\\ncan also be thought of as a subset of X.Hwill denote a set of hypotheses.\\n• We assume that Fis an arbitrary, but ﬁxed, probability distribution overX.\\n• Training examples are obtained by taking random samples from X. We assume that the\\nsamples are randomly generated from Xaccording to the probability distribution F.\\nNow, we give below an informal deﬁnition of PAC-learnability.\\nDeﬁnition (informal)\\nLetXbe an instance space, Ca concept class for X,ha hypothesis in CandFan arbitrary,\\nbut ﬁxed, probability distribution. The concept class Cis said to be PAC-learnable if there is an\\nalgorithmAwhich, for samples drawn with any probability distribution Fand any concept c∈C,\\nwill with high probability produce a hypothesis h∈Cwhose error is small.\\nAdditional notions\\n•True error\\nTo formally deﬁne PAC-learnability, we require the concept of the true error of a hypothesis\\nhwith respect to a target concept cdenoted by error F(h). It is deﬁned by\\nerrorF(h)=Px∈F(h(x)≠c(x))\\nwhere the notation Px∈Findicates that the probability is taken for xdrawn from Xaccording\\nto the distribution F. This error is the probability that hwill misclassify an instance xdrawn\\nat random from Xaccording to the distribution F. This error is not directly observable to the\\nlearner; it can only see the training error of each hypothesis (that is, how often h(x)≠c(x)\\nover training instances).CHAPTER 3. VC DIMENSION AND PAC LEARNING 32\\n•Length or dimension of an instance\\nWe require the notion of the length or dimension or size of an instance in the instance space X.\\nIf the instance space Xis then-dimensional Euclidean space, then each example is speciﬁed\\nbynreal numbers and so the length of the examples may be taken as n. Similarly, if Xis the\\nspace of the conjunctions of nBoolean literals, then the length of the examples may be taken\\nasn. These are the commonly considered instance spaces in computational learning theory.\\n•Size of a concept\\nWe need the notion of the size of a concept c. For any concept c, we deﬁne size (c)to be the\\nsize of the smallest representation of cusing some ﬁnite alphabet \\x06.\\n(For a detailed discussion of these and related ideas, see [6] pp.7-15.)\\nDeﬁnition ([4] p.206)\\nConsider a concept class Cdeﬁned over a set of instances Xof lengthnand a learner (algorithm) L\\nusing hypothesis space H.Cis said to be PAC-learnable by LusingHif for allc∈C, distribution\\nFoverX,\\x0fsuch that 0<\\x0f<1/slash.left2and\\x0esuch that 0<\\x0e<1/slash.left2, learnerLwill with probability at least\\n(1−\\x0e)output a hypothesis hsuch that error F(h)≤\\x0f, in time that is polynomial in 1/slash.left\\x0f,1/slash.left\\x0e,nand\\nsize(c).\\n3.2.2 Examples\\nTo illustrate the deﬁnition of PAC-learnability, let us consider some concrete examples.\\ny\\nx\\na bcd\\n(x;y)\\nxyconcept/hypothesis\\nFigure 3.5: An axis-aligned rectangle in the Euclidean plane\\nExample 1\\n• Let the instance space be the set Xof all points in the Euclidean plane. Each point is repre-\\nsented by its coordinates (x;y). So, the dimension or length of the instances is 2.\\n• Let the concept class Cbe the set of all “axis-aligned rectangles” in the plane; that is, the set\\nof all rectangles whose sides are parallel to the coordinate axes in the plane (see Figure 3.5).\\n• Since an axis-aligned rectangle can be deﬁned by a set of inequalities of the following form\\nhaving four parameters\\na≤x≤b; c≤y≤d\\nthe size of a concept is 4.\\n• We take the set Hof all hypotheses to be equal to the set Cof concepts, H=C.CHAPTER 3. VC DIMENSION AND PAC LEARNING 33\\n• Given a set of sample points labeled positive or negative, let Lbe the algorithm which outputs\\nthe hypothesis deﬁned by the axis-aligned rectangle which gives the tightest ﬁt to the posi-\\ntive examples (that is, that rectangle with the smallest area that includes all of the positive\\nexamples and none of the negative examples) (see Figure 3.6).\\ny\\nx\\nFigure 3.6: Axis-aligned rectangle which gives the tightest ﬁt to the positive examples\\nIt can be shown that, in the notations introduced above, the concept class Cis PAC-learnable by\\nthe algorithm Lusing the hypothesis space Hof all axis-aligned rectangles.\\nExample 2\\n• LetXthe set of all n-bit strings. Each n-bit string may be represented by an ordered n-tuple\\n(a1;:::;an)where eachaiis either 0or1. This may be thought of as an assignment of 0or\\n1tonboolean variables x1;:::;xn. The setXis sometimes denoted by {0;1}n.\\n• To deﬁne the concept class, we distinguish certain subsets of Xin a special way. By a literal\\nwe mean, a Boolean variable xior its negation /slash.leftxi. We consider conjunctions of literals over\\nx1;:::;xn. Each conjunction deﬁnes a subset of X. for example, the conjunction x1∧/slash.leftx2∧x4\\ndeﬁnes the following subset of X:\\n{a=(a1;:::;an)∈X/divides.alt0a1=1;a2=0;a4=1}\\nThe concept class Cconsists of all subsets of Xdeﬁned by conjunctions of Boolean literals\\noverx1;:::;xn.\\n• The hypothesis class His deﬁned as equal to the concept class C.\\n• LetLbe a certain algorithm called “Find-S algorithm” used to ﬁnd a most speciﬁc hypothesis\\n(see [4] p.26).\\nThe concept class Cof all subsets of X={0;1}ndeﬁned by conjunctions of Boolean literals\\noverx1;:::;xnis PAC-learnable by the Find-S algorithm using the hypothesis space H=C.\\n3.2.3 Applications\\nTo make the discussions complete, we introduce one simple application of the PAC-learning theory.\\nThe application is the derivation of a mathematical expression to estimate the size of samples that\\nwould produce a hypothesis with a given high probability and which has a generalization error of\\ngiven low probability.\\nWe use the following assumptions and notations:\\n• We assume that the hypothesis space Hisﬁnite . Let/divides.alt0H/divides.alt0denote the number of elements in H.CHAPTER 3. VC DIMENSION AND PAC LEARNING 34\\n• We assume that the concept class Cbe equal toH.\\n• Letmbe the number of elements in the set of samples.\\n• Let\\x0fand\\x0ebe such that 0<\\x0f;\\x0e<1.\\n• The algorithm can be any consistent algorithm , that is, any algorithm which correctly classiﬁes\\nthe training examples.\\nIt can be shown that, if mis chosen such that\\nm≥1\\n\\x0f(ln(/divides.alt0H/divides.alt0)+ln(1/slash.left\\x0e))\\nthen any consistent algorithm will successfully produce any concept in Hwith probability (1−\\x0e)\\nand with an error having a maximum probability of \\x0f.\\n3.3 Sample questions\\n(a) Short answer questions\\n1. What is VC dimension?\\n2. Explain Vapnik-Chervonenkis dimension.\\n3. Give an informal deﬁnition of PAC learnability.\\n4. Give a precise deﬁnition of PAC learnability.\\n5. Give an application of PAC learnable algorithm.\\n(b) Long answer questions\\n1. LetXbe the set of all real numbers. Describe a hypothesis for Xfor which the VC dimension\\nis0.\\n2. LetXbe the set of all real numbers. Describe a hypothesis for Xfor which the VC dimension\\nis1.\\n3. LetXbe the set of all real numbers. Describe a hypothesis for Xfor which the VC dimension\\nis2. Describe an example for which the VC dimension is 3.\\n4. Describe an example of a PAC learnable concept class.\\n5. An open interval in Ris deﬁned as (a;b)={x∈R/divides.alt0a<x<b}. It has two parameters aandb.\\nShow that the sets of all open intervals has a VC dimension of 2.Chapter 4\\nDimensionality reduction\\nThe complexity of any classiﬁer or regressor depends on the number of inputs. This determines both\\nthe time and space complexity and the necessary number of training examples to train such a clas-\\nsiﬁer or regressor. In this chapter, we discuss various methods for decreasing input dimensionality\\nwithout losing accuracy.\\n4.1 Introduction\\nIn many learning problems, the datasets have large number of variables. Sometimes, the number\\nof variables is more than the number of observations. For example, such situations have arisen in\\nmany scientiﬁc ﬁelds such as image processing, mass spectrometry, time series analysis, internet\\nsearch engines, and automatic text analysis among others. Statistical and machine learning methods\\nhave some difﬁculty when dealing with such high-dimensional data. Normally the number of input\\nvariables is reduced before the machine learning algorithms can be successfully applied.\\nIn statistical and machine learning, dimensionality reduction or dimension reduction is the pro-\\ncess of reducing the number of variables under consideration by obtaining a smaller set of principal\\nvariables.\\nDimensionality reduction may be implemented in two ways.\\n•Feature selection\\nIn feature selection, we are interested in ﬁnding kof the total of nfeatures that give us the\\nmost information and we discard the other (n−k)dimensions. We are going to discuss subset\\nselection as a feature selection method.\\n•Feature extraction\\nIn feature extraction, we are interested in ﬁnding a new set of kfeatures that are the combina-\\ntion of the original nfeatures. These methods may be supervised or unsupervised depending\\non whether or not they use the output information. The best known and most widely used\\nfeature extraction methods are Principal Components Analysis (PCA) and Linear Discrimi-\\nnant Analysis (LDA), which are both linear projection methods, unsupervised and supervised\\nrespectively.\\nMeasures of error\\nIn both methods we require a measure of the error in the model.\\n• In regression problems, we may use the Mean Squared Error (MSE) or the Root Mean\\nSquared Error (RMSE) as the measure of error. MSE is the sum, over all the data points,\\nof the square of the difference between the predicted and actual target variables, divided by\\n35CHAPTER 4. DIMENSIONALITY REDUCTION 36\\nthe number of data points. If y1;:::;ynare the observed values and ^yi;:::; ^ynare the pre-\\ndicted values, then\\nMSE=1\\nnn\\n/summation.disp\\ni=1(yi−^yi)2\\n• In classiﬁcation problems, we may use the misclassiﬁcation rate as a measure of the error.\\nThis is deﬁned as follows:\\nmisclassiﬁcation rate =no. of misclassiﬁed examples\\ntotal no. of examples\\n4.2 Why dimensionality reduction is useful\\nThere are several reasons why we are interested in reducing dimensionality.\\n• In most learning algorithms, the complexity depends on the number of input dimensions, d,\\nas well as on the size of the data sample, N, and for reduced memory and computation, we\\nare interested in reducing the dimensionality of the problem. Decreasing d also decreases the\\ncomplexity of the inference algorithm during testing.\\n• When an input is decided to be unnecessary, we save the cost of extracting it.\\n• Simpler models are more robust on small datasets. Simpler models have less variance, that is,\\nthey vary less depending on the particulars of a sample, including noise, outliers, and so forth.\\n• When data can be explained with fewer features, we get a better idea about the process that\\nunderlies the data, which allows knowledge extraction.\\n• When data can be represented in a few dimensions without loss of information, it can be\\nplotted and analyzed visually for structure and outliers.\\n4.3 Subset selection\\nIn machine learning subset selection , sometimes also called feature selection , orvariable selection ,\\norattribute selection , is the process of selecting a subset of relevant features (variables, predictors)\\nfor use in model construction.\\nFeature selection techniques are used for four reasons:\\n• simpliﬁcation of models to make them easier to interpret by researchers/users\\n• shorter training times,\\n• to avoid the curse of dimensionality\\n• enhanced generalization by reducing overﬁtting\\nThe central premise when using a feature selection technique is that the data contains many\\nfeatures that are either redundant or irrelevant, and can thus be removed without incurring much loss\\nof information.\\nThere are several approaches to subset selection. In these notes, we discuss two of the simplest\\napproaches known as forward selection and backward selection methods.\\n4.3.1 Forward selection\\nInforward selection , we start with no variables and add them one by one, at each step adding the one\\nthat decreases the error the most, until any further addition does not decrease the error (or decreases\\nit only sightly).CHAPTER 4. DIMENSIONALITY REDUCTION 37\\nProcedure\\nWe use the following notations:\\nn : number of input variables\\nx1;:::;xn: input variables\\nFi : a subset of the set of input variables\\nE(Fi) : error incurred on the validation sample when only the inputs\\ninFiare used\\n1. SetF0=/uni2205andE(F0)=∞.\\n2. Fori=0;1;:::, repeat the following until E(Fi+1)≥E(Fi):\\n(a) For all possible input variables xj, train the model with the input variables Fi∪{xj}and\\ncalculateE(Fi∪{xj})on the validation set.\\n(b) Choose that input variable xmthat causes the least error E(Fi∪{xj}):\\nm=arg min\\njE(Fi∪{xj})\\n(c) SetFi+1=Fi∪{xm}.\\n3. The setFiis outputted as the best subset.\\nRemarks\\n1. In this procedure, we stop if adding any feature does not decrease the error E. We may\\neven decide to stop earlier if the decrease in error is too small, where there is a user-deﬁned\\nthreshold that depends on the application constraints.\\n2. This process may be costly because to decrease the dimensions from ntok, we need to train\\nand test the system\\nn+(n−l)+(n−2)+/uni22EF+(n−k)\\ntimes, which is O(n2).\\n4.3.2 Backward selection\\nIn sequential backward selection, we start with the set containing all features and at each step remove\\nthe one feature that causes the least error.\\nProcedure\\nWe use the following notations:\\nn : number of input variables\\nx1;:::;xn: input variables\\nFi : a subset of the set of input variables\\nE(Fi) : error incurred on the validation sample when only the inputs\\ninFiare used\\n1. SetF0={x1;:::;xn}andE(F0)=∞.\\n2. Fori=0;1;:::, repeat the following until E(Fi+1)≥E(Fi):\\n(a) For all possible input variables xj, train the model with the input variables Fi−{xj})\\nand calculate E(Fi−{xj})on the validation set.\\n(b) Choose that input variable xmthat causes the least error E(Fi−{xj}):\\nm=arg min\\njE(Fi−{xj})CHAPTER 4. DIMENSIONALITY REDUCTION 38\\n(c) SetFi+1=Fi−{xm}.\\n3. The setFiis outputted as the best subset.\\n4.4 Principal component analysis\\nPrincipal component analysis (PCA) is a statistical procedure that uses an orthogonal transforma-\\ntion to convert a set of observations of possibly correlated variables into a set of values of linearly\\nuncorrelated variables called principal components. The number of principal components is less\\nthan or equal to the smaller of the number of original variables or the number of observations. This\\ntransformation is deﬁned in such a way that the ﬁrst principal component has the largest possible\\nvariance (that is, accounts for as much of the variability in the data as possible), and each succeeding\\ncomponent in turn has the highest variance possible under the constraint that it is orthogonal to the\\npreceding components.\\n4.4.1 Graphical illustration of the idea\\nConsider a two-dimensional data, that is, a dataset consisting of examples having two features. Let\\neach of the features be numeric data. So, each example can be plotted on a coordinate plane ( x-\\ncoordinate indicating the ﬁrst feature and y-coordinate indicating the second feature). Plotting the\\nexample, we get a scatter diagram of the data. Now let us examine some typical scatter diagram\\nand make some observations regarding the directions in which the points in the scatter diagram are\\nspread out.\\nLet us examine the ﬁgures in Figure 4.1.\\n(i) Figure 4.1a shows a scatter diagram of a two-dimensional data.\\n(ii) Figure 4.1b shows spread of the data in the xdirection and Figure 4.1c shows the spread of\\nthe data in the y-direction. We note that the spread in the x-direction is more than the spread\\nin theydirection.\\n(iii) Examining Figures 4.1d and 4.1e, we note that the maximum spread occurs in the direction\\nshown in Figure 4.1e. Figure 4.1e also shows the point whose coordinates are the mean\\nvalues of the two features in the dataset. This direction is called the direction of the ﬁrst\\nprincipal component of the given dataset.\\n(iv) The direction which is perpendicular (orthogonal) to the direction of the ﬁrst principal com-\\nponent is called the direction of the second principal component of the dataset. This direc-\\ntion is shown in Figure 4.1f. (This is only with reference to a two-dimensional dataset.)\\n(v) The unit vectors along the directions of principal components are called the principal com-\\nponent vectors , or simply, principal components . These are shown in Figure 4.1g.\\nRemark\\nlet us consider a dataset consisting of examples with three or more features. In such a case, we have\\nann-dimensional dataset with n≥3. In this case, the ﬁrst principal component is deﬁned exactly as\\nin item iii above. But, for the second component, it may be noted that there would be many directions\\nperpendicular to the direction of the ﬁrst principal component. The direction of the second principal\\ncomponent is that direction, which is perpendicular to the ﬁrst principal component, in which the\\nspread of data is largest. The third and higher order principal components are constructed in a similar\\nway.CHAPTER 4. DIMENSIONALITY REDUCTION 39\\n(a) Scatter diagram\\n (b) Spread along x-direction\\n(c) Spread along y-direction\\n (d) Largest spread\\n(e) Direction of largest spread : Direction of the ﬁrst\\nprincipal component (solid dot is the point whose coor-\\ndinates are the means of xandy)\\n(f) Directions of principal components\\n(g) Principal component vectors (unit vectors in the di-\\nrections of principal components)\\nFigure 4.1: Principal components\\nA warning!\\nThe graphical illustration of the idea of PCA as explained above is slightly misleading. For the sake\\nof simplicity and easy geometrical representation, in the graphical illustration we have used range\\nas the measure of spread. The direction of the ﬁrst principal component was taken as the direction of\\nmaximum range. But, due to theoretical reasons, in the implementation of PCA in practice, it is the\\nvariance that is taken as as the measure of spread. The ﬁrst principal component is the the direction\\nin which the variance is maximum.CHAPTER 4. DIMENSIONALITY REDUCTION 40\\n4.4.2 Computation of the principal component vectors\\n(PCA algorithm)\\nThe following is an outline of the procedure for performing a principal component analysis on a\\ngiven data. The procedure is heavily dependent on mathematical concepts. A knowledge of these\\nconcepts is essential to carry out this procedure.\\nStep 1. Data\\nWe consider a dataset having nfeatures or variables denoted by X1;X2;:::;Xn. Let there\\nbeNexamples. Let the values of the i-th featureXibeXi1;Xi2;:::;XiN(see Table 4.1).\\nFeatures Example 1 Example 2 /uni22EF ExampleN\\nX1X11X12/uni22EFX1N\\nX2X21X22/uni22EFX2N\\n⋮\\nXiXi1Xi2/uni22EFXiN\\n⋮\\nXnXn1Xn2/uni22EFXnN\\nTable 4.1: Data for PCA algorithm\\nStep 2. Compute the means of the variables\\nWe compute the mean \\x16Xiof the variable Xi:\\n\\x16Xi=1\\nN(Xi1+Xi2+/uni22EF+XiN):\\nStep 3. Calculate the covariance matrix\\nConsider the variables XiandXj(iandjneed not be different). The covariance of the\\nordered pair (Xi;Xj)is deﬁned as1\\nCov(Xi;Xj)=1\\nN−1N\\n/summation.disp\\nk=1(Xik−\\x16Xi)(Xjk−\\x16Xj): (4.1)\\nWe calculate the following n×nmatrixScalled the covariance matrix of the data. The\\nelement in the i-th rowj-th column is the covariance Cov (Xi;Xj):\\nS=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A3Cov(X1;X1)Cov(X1;X2)/uni22EFCov(X1;Xn)\\nCov(X2;X1)Cov(X2;X2)/uni22EFCov(X2;Xn)\\n⋮\\nCov(Xn;X1)Cov(Xn;X2)/uni22EFCov(Xn;Xn)/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6\\nStep 4. Calculate the eigenvalues and eigenvectors of the covariance matrix\\nLetSbe the covariance matrix and let Ibe the identity matrix having the same dimension\\nas the dimension of S.\\ni) Set up the equation:\\ndet(S−\\x15I)=0: (4.2)\\nThis is a polynomial equation of degree nin\\x15. It hasnreal roots (some of the\\nroots may be repeated) and these roots are the eigenvalues of S. We ﬁnd the nroots\\n\\x151;\\x152;:::;\\x15nof Eq. (4.2).\\n1There is an alternative deﬁnition of covariance. In this deﬁnition, covariance is deﬁned as in Eq. (4.1) with N−1\\nreplaced byN. There are certain theoretical reasons for adopting the deﬁnition as given here.CHAPTER 4. DIMENSIONALITY REDUCTION 41\\nii) If\\x15=\\x15′is an eigenvalue, then the corresponding eigenvector is a vector\\nU=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A3u1\\nu2\\n⋮\\nun/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6\\nsuch that\\n(S−\\x15′I)U=0:\\n(This is a system of nhomogeneous linear equations in u1,u2,:::,unand it al-\\nways has a nontrivial solution.) We next ﬁnd a set of northogonal eigenvectors\\nU1;U2;:::;Unsuch thatUiis an eigenvector corresponding to \\x15i.2\\niii) We now normalise the eigenvectors. Given any vector Xwe normalise it by dividing\\nXby its length. The length (or, the norm) of the vector\\nX=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A3x1\\nx2\\n⋮\\nxn/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6\\nis deﬁned as\\n/divides.alt0/divides.alt0X/divides.alt0/divides.alt0=/radical.alt2\\nx2\\n1+x2\\n2+/uni22EF+x2n:\\nGiven any eigenvector U, the corresponding normalised eigenvector is computed as\\n1\\n/divides.alt0/divides.alt0U/divides.alt0/divides.alt0U:\\nWe compute the nnormalised eigenvectors e1;e2;:::;enby\\nei=1\\n/divides.alt0/divides.alt0Ui/divides.alt0/divides.alt0Ui; i=1;2;:::;n:\\nStep 5. Derive new data set\\nOrder the eigenvalues from highest to lowest. The unit eigenvector corresponding to the\\nlargest eigenvalue is the ﬁrst principal component. The unit eigenvector corresponding to\\nthe next highest eigenvalue is the second principal component, and so on.\\ni) Let the eigenvalues in descending order be \\x151≥\\x152≥:::≥\\x15nand let the corre-\\nsponding unit eigenvectors be e1;e2;:::;en.\\nii) Choose a positive integer psuch that 1≤p≤n.\\niii) Choose the eigenvectors corresponding to the eigenvalues \\x151,\\x152,:::,\\x15pand form\\nthe following p×nmatrix (we write the eigenvectors as row vectors):\\nF=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A3eT\\n1\\neT\\n2\\n⋮\\neT\\np/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6;\\nwhereTin the superscript denotes the transpose.\\n2Fori≠j, the vectorsUiandUjare orthogonal means UT\\niUj=0whereTdenotes the transpose.CHAPTER 4. DIMENSIONALITY REDUCTION 42\\niv) We form the following n×Nmatrix:\\nX=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A3X11−\\x16X1X12−\\x16X1/uni22EFX1N−\\x16X1\\nX21−\\x16X2X22−\\x16X2/uni22EFX2N−\\x16X2\\n⋮\\nXn1−\\x16XnXn2−\\x16Xn/uni22EFXnN−\\x16Xn/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6\\nv) Next compute the matrix:\\nXnew=FX:\\nNote that this is a p×Nmatrix. This gives us a dataset of Nsamples having p\\nfeatures.\\nStep 6. New dataset\\nThe matrix Xnewis the new dataset. Each row of this matrix represents the values of a\\nfeature. Since there are only prows, the new dataset has only features.\\nStep 7. Conclusion\\nThis is how the principal component analysis helps us in dimensional reduction of the\\ndataset. Note that it is not possible to get back the original n-dimensional dataset from\\nthe new dataset.\\n4.4.3 Illustrative example\\nWe illustrate the ideas of principal component analysis by considering a toy example. In the discus-\\nsions below, all the details of the computations are given. This is to give the reader an idea of the\\ncomplexity of computations and also to help the reader do a “worked example” by hand computa-\\ntions without recourse to software packages.\\nProblem\\nGiven the data in Table 4.2, use PCA to reduce the dimension from 2to1.\\nFeature Example 1 Example 2 Example 3 Example 4\\nX1 4 8 13 7\\nX2 11 4 5 14\\nTable 4.2: Data for illustrating PCA\\nSolution\\n1. Scatter plot of data\\nWe have\\n\\x16X1=1\\n4(4+8+13+7)=8;\\n\\x16X2=1\\n4(11+4+5+14)=8:5:\\nFigure 4.2 shows the scatter plot of the data together with the point (\\x16X1;\\x16X2).CHAPTER 4. DIMENSIONALITY REDUCTION 43\\nX1X2\\n024681012142468101214\\n(\\x16X1;\\x16X2)\\nFigure 4.2: Scatter plot of data in Table 4.2\\n2. Calculation of the covariance matrix\\nThe covariances are calculated as follows:\\nCov(X1;X2)=1\\nN−1N\\n/summation.disp\\nk=1(X1k−\\x16X1)2\\n=1\\n3/parenleft.alt1(4−8)2+(8−8)2+(13−8)2+(7−8)2/parenright.alt1\\n=14\\nCov(X1;X2)=1\\nN−1N\\n/summation.disp\\nk=1(X1k−\\x16X1)(X2k−\\x16X2)\\n=1\\n3((4−8)(11−8:5)+(8−8)(4−8:5)\\n+(13−8)(5−8:5)+(7−8)(14−8:5)\\n=−11\\nCov(X2;X1)=Cov(X1;X2)\\n=−11\\nCov(X2;X2)=1\\nN−1N\\n/summation.disp\\nk=1(X2k−\\x16X2)2\\n=1\\n3/parenleft.alt1(11−8:5)2+(4−8:5)2+(5−8:5)2+(14−8:5)2/parenright.alt1\\n=23\\nThe covariance matrix is\\nS=/bracketleft.alt4Cov(X1;X1)Cov(X1;X2)\\nCov(X2;X1)Cov(X2;X2)/bracketright.alt4\\n=/bracketleft.alt414−11\\n−11 23/bracketright.alt4\\n3. Eigenvalues of the covariance matrix\\nThe characteristic equation of the covariance matrix is\\n0=det(S−\\x15I)\\n=/divides.alt414−\\x15−11\\n−11 23−\\x15/divides.alt4\\n=(14−\\x15)(23−\\x15)−(−11)×(−11)\\n=\\x152−37\\x15+201CHAPTER 4. DIMENSIONALITY REDUCTION 44\\nSolving the characteristic equation we get\\n\\x15=1\\n2(37±√\\n565)\\n=30:3849;6:6151\\n=\\x151;\\x152(say)\\n4. Computation of the eigenvectors\\nTo ﬁnd the ﬁrst principal components, we need only compute the eigenvector corresponding to the\\nlargest eigenvalue. In the present example, the largest eigenvalue is \\x151and so we compute the\\neigenvector corresponding to \\x151.\\nThe eigenvector corresponding to \\x15=\\x151is a vectorU=/bracketleft.alt4u1\\nu2/bracketright.alt4satisfying the following equation:\\n/bracketleft.alt40\\n0/bracketright.alt4=(S−\\x151I)X\\n=/bracketleft.alt414−\\x151−11\\n−11 23−\\x151/bracketright.alt4/bracketleft.alt4u1\\nu2/bracketright.alt4\\n=/bracketleft.alt4(14−\\x151)u1−11u2\\n−11u1+(23−\\x151)u2/bracketright.alt4\\nThis is equivalent to the following two equations:\\n(14−\\x151)u1−11u2=0\\n−11u1+(23−\\x151)u2=0\\nUsing the theory of systems of linear equations, we note that these equations are not independent\\nand solutions are given byu1\\n11=u2\\n14−\\x151=t;\\nthat is\\nu1=11t; u 2=(14−\\x151)t;\\nwheretis any real number. Taking t=1, we get an eigenvector corresponding to \\x151as\\nU1=/bracketleft.alt411\\n14−\\x151/bracketright.alt4:\\nTo ﬁnd a unit eigenvector, we compute the length of X1which is given by\\n/divides.alt0/divides.alt0U1/divides.alt0/divides.alt0=/radical.alt1\\n112+(14−\\x151)2\\n=/radical.alt1\\n112+(14−30:3849)2\\n=19:7348\\nTherefore, a unit eigenvector corresponding to lambda 1is\\ne1=/bracketleft.alt411/slash.left/divides.alt0/divides.alt0U1/divides.alt0/divides.alt0\\n(14−\\x151)/slash.left/divides.alt0/divides.alt0U1/divides.alt0/divides.alt0/bracketright.alt4\\n=/bracketleft.alt411/slash.left19:7348\\n(14−30:3849)/slash.left19:7348/bracketright.alt4\\n=/bracketleft.alt40:5574\\n−0:8303/bracketright.alt4\\nBy carrying out similar computations, the unit eigenvector e2corresponding to the eigenvalue\\n\\x15=\\x152can be shown to be\\ne2=/bracketleft.alt40:8303\\n0:5574/bracketright.alt4:CHAPTER 4. DIMENSIONALITY REDUCTION 45\\nX1X2\\n024681012142468101214\\ne1e2\\n(\\x16X1;\\x16X2)\\nFigure 4.3: Coordinate system for principal components\\n5. Computation of ﬁrst principal components\\nLet/bracketleft.alt4X1k\\nX2k/bracketright.alt4be thek-th sample in Table 4.2. The ﬁrst principal component of this example is given\\nby (here “T” denotes the transpose of the matrix)\\neT\\n1/bracketleft.alt4X1k−\\x16X1\\nX2k−\\x16X2/bracketright.alt4=/bracketleft.alt10:5574−0:8303/bracketright.alt/bracketleft.alt4X1k−\\x16X1\\nX2k−\\x16X2/bracketright.alt4\\n=0:5574(X1k−\\x16X1)−0:8303(X2k−\\x16X2):\\nFor example, the ﬁrst principal component corresponding to the ﬁrst example /bracketleft.alt4X11\\nX21/bracketright.alt4=/bracketleft.alt44\\n11/bracketright.alt4is\\ncalculated as follows:\\n/bracketleft.alt10:5574−0:8303/bracketright.alt/bracketleft.alt4X11−\\x16X1\\nX21−\\x16X2/bracketright.alt4=0:5574(X11−\\x16X1)−0:8303(X21−\\x16X2)\\n=0:5574(4−8)−0:8303(11−8;5)\\n=−4:30535\\nThe results of calculations are summarised in Table 4.3.\\nX1 4 8 13 7\\nX2 11 4 5 14\\nFirst principal components -4.3052 3.7361 5.6928 -5.1238\\nTable 4.3: First principal components for data in Table 4.2\\n6. Geometrical meaning of ﬁrst principal components\\nAs we have seen in Figure 4.1, we introduce new coordinate axes. First we shift the origin to\\nthe “center” (\\x16X1;\\x16X2)and then change the directions of coordinate axes to the directions of the\\neigenvectors e1ande2(see Figure 4.3).\\nNext, we drop perpendiculars from the given data points to the e1-axis (see Figure 4.4). The ﬁrst\\nprincipal components are the e1-coordinates of the feet of perpendiculars, that is, the projections on\\nthee1-axis. The projections of the data points on e1-axis may be taken as approximations of the\\ngiven data points hence we may replace the given data set with these points. Now, each of theseCHAPTER 4. DIMENSIONALITY REDUCTION 46\\nX1X2\\n024681012142468101214\\ne1e2 (4;11)\\n(8;4)(13;5)(7;14)\\n(\\x16X1;\\x16X2)\\nFigure 4.4: Projections of data points on the axis of the ﬁrst principal component\\nPC1 components -4.305187 3.736129 5.692828 -5.123769\\nTable 4.4: One-dimensional approximation to the data in Table 4.2\\napproximations can be unambiguously speciﬁed by a single number, namely, the e1-coordinate of\\napproximation. Thus the two-dimensional data set given in Table 4.2 can be represented approxi-\\nmately by the following one-dimensional data set (see Figure 4.5):\\nX1X2\\n024681012142468101214\\ne1e2\\n(4,11)\\n(8,4)(13, 5)(7,14)\\n(\\x16X1;\\x16X2)\\nX1X2\\n0 24681012142468101214\\ne1e2\\n(\\x16X1;\\x16X2)\\nFigure 4.5: Geometrical representation of one-dimensional approximation to the data in Table 4.2\\n4.5 Sample questions\\n(a) Short answer questions\\n1. What is dimensionality reduction? How is it implemented?\\n2. Explain why dimensionality reduction is useful in machine learning.\\n3. What are the commonly used dimensionality reduction techniques in machine learning?\\n4. How is the subset selection method used for dimensionality reduction?\\n5. Explain the method of principal component analysis in machine learning.\\n6. What are the ﬁrst principal components of a data?\\n7. Is subset selection problem an unsupervised learning problem? Why?CHAPTER 4. DIMENSIONALITY REDUCTION 47\\n8. Is principal component analysis a supervised learning problem? Why?\\n(b) Long answer questions\\n1. Describe the forward selection algorithm for implementing the subset selection procedure for\\ndimensionality reduction.\\n2. Describe the backward selection algorithm for implementing the subset selection procedure\\nfor dimensionality reduction.\\n3. What is the ﬁrst principal component of a data? How one can compute it?\\n4. Describe with the use of diagrams the basic principle of PCA.\\n5. Explain the procedure for the computation of the principal components of a given data.\\n6. Describe how principal component analysis is carried out to reduce dimensionality of data\\nsets.\\n7. Given the following data, compute the principal component vectors and the ﬁrst principal\\ncomponents:\\nx 2 3 7\\ny11 14 26\\n8. Given the following data, compute the principal component vectors and the ﬁrst principal\\ncomponents:\\nx-3 1 -2\\ny 2 -1 3Chapter 5\\nEvaluation of classiﬁers\\nIn machine learning, there are several classiﬁcation algorithms and, given a certain problem, more\\nthan one may be applicable. So there is a need to examine how we can assess how good a se-\\nlected algorithm is. Also, we need a method to compare the performance of two or more different\\nclassiﬁcation algorithms. These methods help us choose the right algorithm in a practical situation.\\n5.1 Methods of evaluation\\n5.1.1 Need for multiple validation sets\\nWhen we apply a classiﬁcation algorithm in a practical situation, we always do a validation test.\\nWe keep a small sample of examples as validation set and the remaining set as the training set. The\\nclassiﬁer developed using the training set is applied to the examples in the validation set. Based on\\nthe performance on the validation set, the accuracy of the classiﬁer is assessed. But, the performance\\nmeasure obtained by a single validation set alone does not give a true picture of the performance of a\\nclassiﬁer. Also these measures alone cannot be meaningfully used to compare two algorithms. This\\nrequires us to have different validation sets.\\nCross-validation in general, and k-fold cross-validation in particular, are two common method\\nfor generating multiple training-validation sets from a given dataset.\\n5.1.2 Statistical distribution of errors\\nWe use a classiﬁcation algorithm on a dataset and generate a classiﬁer. If we do the training once,\\nwe have one classiﬁer and one validation error. To average over randomness (in training data, initial\\nweights, etc.), we use the same algorithm and generate multiple classiﬁers. We test these classiﬁers\\non multiple validation sets and record a sample of validation errors. We base our evaluation of the\\nclassiﬁcation algorithm on the statistical distribution of these validation errors . We can use this\\ndistribution for assessing the expected error rate of the classiﬁcation algorithm for that problem, or\\ncompare it with the error rate distribution of some other classiﬁcation algorithm.\\nA detailed discussion of these ideas is beyond the scope of these notes.\\n5.1.3 No-free lunch theorem\\nWhatever conclusion we draw from our analysis is conditioned on the dataset we are given. We\\nare not comparing classiﬁcation algorithms in a domain-independent way but on some particular\\napplication. We are not saying anything about the expected error-rate of a learning algorithm, or\\ncomparing one learning algorithm with another algorithm, in general. Any result we have is only\\ntrue for the particular application. There is no such thing as the “best” learning algorithm. For any\\n48CHAPTER 5. EVALUATION OF CLASSIFIERS 49\\nlearning algorithm, there is a dataset where it is very accurate and another dataset where it is very\\npoor. This is called the No Free Lunch Theorem .1\\n5.1.4 Other factors\\nClassiﬁcation algorithms can be compared based not only on error rates but also on several other\\ncriteria like the following:\\n• risks when errors are generalized using loss functions\\n• training time and space complexity,\\n• testing time and space complexity,\\n• interpretability, namely, whether the method allows knowledge extraction which can be checked\\nand validated by experts, and\\n• easy programmability.\\n5.2 Cross-validation\\nTo test the performance of a classiﬁer, we need to have a number of training/validation set pairs\\nfrom a dataset X. To get them, if the sample Xis large enough, we can randomly divide it then\\ndivide each part randomly into two and use one half for training and the other half for validation.\\nUnfortunately, datasets are never large enough to do this. So, we use the same data split differently;\\nthis is called cross-validation .\\nCross-validation is a technique to evaluate predictive models by partitioning the original sample\\ninto a training set to train the model, and a test set to evaluate it.\\nTheholdout method is the simplest kind of cross validation. The data set is separated into two\\nsets, called the training set and the testing set. The algorithm ﬁts a function using the training set\\nonly. Then the function is used to predict the output values for the data in the testing set (it has never\\nseen these output values before). The errors it makes are used to evaluate the model.\\n5.3 K-fold cross-validation\\nInK-fold cross-validation, the dataset Xis divided randomly into Kequal-sized parts, Xi,i=\\n1;:::;K . To generate each pair, we keep one of the Kparts out as the validation set Vi, and combine\\nthe remaining K−1parts to form the training set Ti. Doing this Ktimes, each time leaving out\\nanother one of the Kparts out, we get Kpairs(Vi;Ti):\\nV1=X1; T 1=X2∪X3∪:::∪XK\\nV2=X2; T 2=X1∪X3∪:::∪XK\\n/uni22EF\\nVK=XK; TK=X1∪X2∪:::∪XK−1\\nRemarks\\n1. There are two problems with this: First, to keep the training set large, we allow validation sets\\nthat are small. Second, the training sets overlap considerably, namely, any two training sets\\nshareK−2parts.\\n1“We have dubbed the associated results NFL theorems because they demonstrate that if an algorithm performs well on\\na certain class of problems then it necessarily pays for that with degraded performance on the set of all remaining prob-\\nlems.”(David Wolpert and William Macready in [7])CHAPTER 5. EVALUATION OF CLASSIFIERS 50\\n2.Kis typically 10or30. AsKincreases, the percentage of training instances increases and we\\nget more robust estimators, but the validation set becomes smaller. Furthermore, there is the\\ncost of training the classiﬁer Ktimes, which increases as Kis increased.\\ntest set\\ntest set\\ntest set\\ntest set\\ntest settraining set\\ntraining set\\ntraining set\\ntraining settraining set\\ntraining set\\ntraining set\\ntraining set1-st fold\\n2-nd fold\\n3-rd fold\\n4-th fold\\n5-th fold\\nFigure 5.1: One iteration in a 5-fold cross-validation\\nLeave-one-out cross-validation\\nAn extreme case of K-fold cross-validation is leave-one-out where given a dataset of Ninstances,\\nonly one instance is left out as the validation set and training uses the remaining N−1instances.\\nWe then get Nseparate pairs by leaving out a different instance at each iteration. This is typically\\nused in applications such as medical diagnosis, where labeled data is hard to ﬁnd.\\n5.3.1 5×2cross-validation\\nIn this method, the dataset Xis divided into two equal parts X(1)\\n1andX(2)\\n1. We take as the training\\nset andX(2)\\n1as the validation set. We then swap the two sets and take X(2)\\n1as the training set and\\nX(1)\\n1as the validation set. This is the ﬁrst fold. the process id repeated four more times to get ten\\npairs of training sets and validation sets.\\nT1=X(1)\\n1; V 1=X(2)\\n1\\nT2=X(2)\\n1; V 2=X(1)\\n1\\nT3=X(1)\\n2; V 3=X(2)\\n2\\nT4=X(2)\\n2; V 4=X(1)\\n2\\n⋮\\nT9=X(1)\\n5; V 3=X(2)\\n5\\nT10=X(2)\\n5; V 10=X(1)\\n5\\nIt has been shown that after ﬁve folds, the validation error rates become too dependent and do\\nnot add new information. On the other hand, if there are fewer than ﬁve folds, we get fewer data\\n(fewer than ten) and will not have a large enough sample to ﬁt a distribution and test our hypothesis.CHAPTER 5. EVALUATION OF CLASSIFIERS 51\\n5.3.2 Bootstrapping\\nBootstrapping in statistics\\nIn statistics, the term “bootstrap sampling”, the “bootstrap” or “bootstrapping” for short, refers to\\nprocess of “random sampling with replacement”.\\nExample\\nFor example, let there be ﬁve balls labeled A, B, C, D, E in an urn. We wish to select different\\nsamples of balls from the urn each sample containing two balls. The following procedure may be\\nused to select the samples. This is an example for bootstrap sampling.\\n1. We select two balls from the basket. Let them be A and E. Record the labels.\\n2. Put the two balls back in the basket.\\n3. We select two balls from the basket. Let them be C and E. Record the labels.\\n4. Put the two balls back into the basket.\\nThis is repeated as often as required. So we get different samples of size 2, say, A, E; B, E; etc.\\nThese samples are obtained by sampling with replacement, that is, by bootstrapping.\\nBootstrapping in machine learning\\nIn machine learning, bootstrapping is the process of computing performance measures using several\\nrandomly selected training and test datasets which are selected through a precess of sampling with\\nreplacement, that is, through bootstrapping. Sample datasets are selected multiple times.\\nThe bootstrap procedure will create one or more new training datasets some of which are re-\\npeated. The corresponding test datasets are then constructed from the set of examples that were not\\nselected for the respective training datasets.\\n5.4 Measuring error\\n5.4.1 True positive, false positive, etc.\\nDeﬁnitions\\nConsider a binary classiﬁcation model derived from a two-class dataset. Let the class labels be cand\\n¬c. Letxbe a test instance.\\n1.True positive\\nLet the true class label of xbec. If the model predicts the class label of xasc, then we say\\nthat the classiﬁcation of xistrue positive .\\n2.False negative\\nLet the true class label of xbec. If the model predicts the class label of xas¬c, then we say\\nthat the classiﬁcation of xisfalse negative .\\n3.True negative\\nLet the true class label of xbe¬c. If the model predicts the class label of xas¬c, then we say\\nthat the classiﬁcation of xistrue negative .\\n4.False positive\\nLet the true class label of xbe¬c. If the model predicts the class label of xasc, then we say\\nthat the classiﬁcation of xisfalse positive .CHAPTER 5. EVALUATION OF CLASSIFIERS 52\\nActual label of xiscActual label of xis¬c\\nPredicted label of xisc True positive False positive\\nPredicted label of xis¬c False negative True negative\\n5.4.2 Confusion matrix\\nA confusion matrix is used to describe the performance of a classiﬁcation model (or “classiﬁer”) on\\na set of test data for which the true values are known. A confusion matrix is a table that categorizes\\npredictions according to whether they match the actual value.\\nTwo-class datasets\\nFor a two-class dataset, a confusion matrix is a table with two rows and two columns that reports the\\nnumber of false positives, false negatives, true positives, and true negatives.\\nAssume that a classiﬁer is applied to a two-class test dataset for which the true values are known.\\nLet TP denote the number of true positives in the predicted values, TN the number of true negatives,\\netc. Then the confusion matrix of the predicted values can be represented as follows:\\nActual condition\\nis trueActual condition\\nis false\\nPredicted condi-\\ntion is trueTP FP\\nPredicted condi-\\ntion is falseFN FN\\nTable 5.1: Confusion matrix for two-class dataset\\nMulticlass datasets\\nConfusion matrices can be constructed for multiclass datasets also.\\nExample\\nIf a classiﬁcation system has been trained to distinguish between cats, dogs and rabbits, a confusion\\nmatrix will summarize the results of testing the algorithm for further inspection. Assuming a sample\\nof 27 animals - 8 cats, 6 dogs, and 13 rabbits, the resulting confusion matrix could look like the table\\nbelow: This confusion matrix shows that, for example, of the 8 actual cats, the system predicted that\\nActual “cat” Actual “dog” Actual “rabbit”\\nPredicted “cat” 5 2 0\\nPredicted “dog” 3 3 2\\nPredicted “ rabbit” 0 1 11\\nthree were dogs, and of the six dogs, it predicted that one was a rabbit and two were cats.\\n5.4.3 Precision and recall\\nIn machine learning, precision and recall are two measures used to assess the quality of results\\nproduced by a binary classiﬁer. They are formally deﬁned as follows.CHAPTER 5. EVALUATION OF CLASSIFIERS 53\\nDeﬁnitions\\nLet a binary classiﬁer classify a collection of test data. Let\\nTP=Number of true positives\\nTN=Number of true negatives\\nFP=Number of false positives\\nFN=Number of false negatives\\nTheprecisionPis deﬁned as\\nP=TP\\nTP+FP\\nTherecallRis deﬁned as\\nR=TP\\nTP+FN\\nProblem 1\\nSuppose a computer program for recognizing dogs in photographs identiﬁes eight dogs in a picture\\ncontaining 12 dogs and some cats. Of the eight dogs identiﬁed, ﬁve actually are dogs while the rest\\nare cats. Compute the precision and recall of the computer program.\\nSolution\\nWe have:\\nTP=5\\nFP=3\\nFN=7\\nTheprecisionPis\\nP=TP\\nTP+FP=5\\n5+3=5\\n8\\nTherecallRis\\nR=TP\\nTP+FN=5\\n5+7=5\\n12\\nProblem 2\\nLet there be 10 balls (6 white and 4 red balls) in a box and let it be required to pick up the red balls\\nfrom them. Suppose we pick up 7 balls as the red balls of which only 2 are actually red balls. What\\nare the values of precision and recall in picking red ball?\\nSolution\\nObviously we have:\\nTP=2\\nFP=7−2=5\\nFN=4−2=2\\nTheprecisionPis\\nP=TP\\nTP+FP=2\\n2+5=2\\n7\\nTherecallRis\\nR=TP\\nTP+FN=2\\n2+2=1\\n2CHAPTER 5. EVALUATION OF CLASSIFIERS 54\\nProblem 3\\nAssume the following: A database contains 80 records on a particular topic of which 55 are relevant\\nto a certain investigation. A search was conducted on that topic and 50 records were retrieved. Of the\\n50 records retrieved, 40 were relevant. Construct the confusion matrix for the search and calculate\\nthe precision and recall scores for the search.\\nSolution\\nEach record may be assigned a class label “relevant\" or “not relevant”. All the 80 records were\\ntested for relevance. The test classiﬁed 50 records as “relevant”. But only 40 of them were actually\\nrelevant. Hence we have the following confusion matrix for the search:\\nActual ”relevant”Actual “not rele-\\nvant”\\nPredicted “rele-\\nvant”40 10\\nPredicted “not\\nrelevant”15 25\\nTable 5.2: Example for confusion matrix\\nTP=40\\nFP=10\\nFN=15\\nTheprecisionPis\\nP=TP\\nTP+FP=40\\n40+10=4\\n5\\nTherecallRis\\nR=TP\\nTP+FN=40\\n40+15=40\\n55\\n5.4.4 Other measures of performance\\nUsing the data in the confusion matrix of a classiﬁer of two-class dataset, several measures of per-\\nformance have been deﬁned. A few of them are listed below.\\n1. Accuracy =TP+TN\\nTP+TN+FP+FN\\n2. Error rate =1−Accuracy\\n3. Sensitivity =TP\\nTP+FN\\n4. Speciﬁcity =TN\\nTN+FP\\n5.F-measure=2×TP\\n2×TP+FP+FN\\n5.5 Receiver Operating Characteristic (ROC)\\nThe acronym ROC stands for Receiver Operating Characteristic, a terminology coming from signal\\ndetection theory. The ROC curve was ﬁrst developed by electrical engineers and radar engineers\\nduring World War II for detecting enemy objects in battleﬁelds. They are now increasingly used in\\nmachine learning and data mining research.CHAPTER 5. EVALUATION OF CLASSIFIERS 55\\nTPR and FPR\\nLet a binary classiﬁer classify a collection of test data. Let, as before,\\nTP=Number of true positives\\nTN=Number of true negatives\\nFP=Number of false positives\\nFN=Number of false negatives\\nNow we introduce the following terminology:\\nTPR=True Positive Rate\\n=TP\\nTP+FN\\n=Fraction of positive examples correctly classiﬁed\\n=Sensitivity\\nFPR=False Positive Rate\\n=FP\\nFP+TN\\n=Fraction of negative examples incorrectly classiﬁed\\n=1−Speciﬁcity\\nROC space\\nWe plot the values of FPR along the horizontal axis (that is , x-axis) and the values of TPR along\\nthe vertical axis (that is, y-axis) in a plane. For each classiﬁer, there is a unique point in this plane\\nwith coordinates (FPR;TPR). The ROC space is the part of the plane whose points correspond to\\n(FPR;TPR). Each prediction result or instance of a confusion matrix represents one point in the\\nROC space.\\nThe position of the point (FPR;TPR)in the ROC space gives an indication of the performance\\nof the classiﬁer. For example, let us consider some special points in the space.\\nSpecial points in ROC space\\n1.The left bottom corner point (0;0): Always negative prediction\\nA classiﬁer which produces this point in the ROC space never classiﬁes an example as positive,\\nneither rightly nor wrongly, because for this point TP =0and FP=0. It always makes\\nnegative predictions. All positive instances are wrongly predicted and all negative instances\\nare correctly predicted. It commits no false positive errors.\\n2.The right top corner point (1;1): Always positive prediction\\nA classiﬁer which produces this point in the ROC space always classiﬁes an example as posi-\\ntive because for this point FN =0and TN=0. All positive instances are correctly predicted\\nand all negative instances are wrongly predicted. It commits no false negative errors.\\n3.The left top corner point (0;1): Perfect prediction\\nA classiﬁer which produces this point in the ROC space may be thought as a perfect classiﬁer.\\nIt produces no false positives and no false negatives.\\n4.Points along the diagonal: Random performance\\nConsider a classiﬁer where the class labels are randomly guessed, say by ﬂipping a coin. Then,\\nthe corresponding points in the ROC space will be lying very near the diagonal line joining\\nthe points (0;0)and(1;1).CHAPTER 5. EVALUATION OF CLASSIFIERS 56\\n.0.0\\n.1.1\\n.2.2\\n.3.3\\n.4.4\\n.5.5\\n.6.6\\n.7.7\\n.8.8\\n.9.9\\n11\\nFalse Positive Rate (FPR) →True Positive Rate (TPR) →ROC space\\nAlways negative predictionAlways positive prediction Perfect prediction\\nPoint on diagonal\\n(Random performance)\\nFigure 5.2: The ROC space and some special points in the space\\nROC curve\\nIn the case of certain classiﬁcation algorithms, the classiﬁer may depend on a parameter. Different\\nvalues of the parameter will give different classiﬁers and these in turn give different values to TPR\\nand FPR. The ROC curve is the curve obtained by plotting in the ROC space the points (TPR;FPR)\\nobtained by assigning all possible values to the parameter in the classiﬁer.CHAPTER 5. EVALUATION OF CLASSIFIERS 57\\n.0.0\\n.1.1\\n.2.2\\n.3.3\\n.4.4\\n.5.5\\n.6.6\\n.7.7\\n.8.8\\n.9.9\\n11\\nFalse Positive Rate (FPR) →True Positive Rate (TPR) →ROC space\\nABC\\nFigure 5.3: ROC curves of three different classiﬁers A, B, C\\nThe closer the ROC curve is to the top left corner (0;1)of the ROC space, the better the accuracy\\nof the classiﬁer. Among the three classiﬁers A, B, C with ROC curves as shown in Figure 5.3, the\\nclassiﬁer C is closest to the top left corner of the ROC space. Hence, among the three, it gives the\\nbest accuracy in predictions.\\nExample\\nCut-off value of BMIBreast cancer Normal personsTPR FPRTP FN FP TN\\n18 100 0 200 0 1.00 1.000\\n20 100 0 198 2 1.00 0.990\\n22 99 1 177 23 0.99 0.885\\n24 95 5 117 83 0.95 0.585\\n26 85 15 80 120 0.85 0.400\\n28 66 34 53 147 0.66 0.265\\n30 47 53 27 173 0.47 0.135\\n32 34 66 17 183 0.34 0.085\\n34 21 79 14 186 0.21 0.070\\n36 17 83 6 194 0.17 0.030\\n38 7 93 4 196 0.07 0.020\\n40 1 99 1 199 0.01 0.005\\nTable 5.3: Data on breast cancer for various values of BMI\\nThe body mass index (BMI) of a person is deﬁned as (weight(kg)/height(m)2). Researchers have\\nestablished a link between BMI and the risk of breast cancer among women. The higher the BMI\\nthe higher the risk of developing breast cancer. The critical threshold value of BMI may depend on\\nseveral parameters like food habits, socio-cultural-economic background, life-style, etc. Table 5.3CHAPTER 5. EVALUATION OF CLASSIFIERS 58\\ngives real data of a breast cancer study with a sample having 100 patients and 200 normal persons.2\\nThe table also shows the values of TPR and FPR for various cut-off values of BMI. The ROC curve\\nof the data in Table 5.3 is shown in Figure 5.4.\\n.0.0\\n.1.1\\n.2.2\\n.3.3\\n.4.4\\n.5.5\\n.6.6\\n.7.7\\n.8.8\\n.9.9\\n11\\nFalse Positive Rate (FPR) →True Positive Rate (TPR) →ROC space\\nCut-off BMI = 26\\nCut-off BMI = 28\\nAUC=Area of shaded region\\nFigure 5.4: ROC curve of data in Table 5.3 showing the points closest to the perfect prediction point\\n(0;1)\\nArea under the ROC curve\\nThe measure of the area under the ROC curve is denoted by the acronym AUC (see Figure 5.4). The\\nvalue of AUC is a measure of the performance of a classiﬁer. For the perfect classiﬁer, AUC =1.0.\\n5.6 Sample questions\\n(a) Short answer questions\\n1. What is cross-validation in machine learning?\\n2. What is meant by 5×2cross-validation?\\n3. What is meant by leave-one-out cross validation?\\n4. What is meant by the confusion matrix of a binary classiﬁcation problem.\\n5. Deﬁne the following terms: precision, recall, sensitivity, speciﬁcity.\\n6. What is ROC curve in machine learning?\\n7. What are true positive rates and false positive rates in machine learning?\\n8. What is AUC in relation to ROC curves?\\n2https://www.ncbi.nlm.nih.gov/ pmc/articles/PMC3755824/CHAPTER 5. EVALUATION OF CLASSIFIERS 59\\n(b) Long answer questions\\n1. Explain cross-validation in machine learning. Explain the different types of cross-validations.\\n2. What is meant by true positives etc.? What is meant by confusion matrix of a binary classiﬁ-\\ncation problem? Explain how this can be extended to multi-class problems.\\n3. What are ROC space and ROC curve in machine learning? In ROC space, which points\\ncorrespond to perfect prediction, always positive prediction and always negative prediction?\\nWhy?\\n4. Consider a two-class classiﬁcation problem of predicting whether a photograph contains a\\nman or a woman. Suppose we have a test dataset of 10 records with expected outcomes and a\\nset of predictions from our classiﬁcation algorithm.\\nExpected Predicted\\n1 man woman\\n2 man man\\n3 woman woman\\n4 man man\\n5 woman man\\n6 woman woman\\n7 woman woman\\n8 man man\\n9 man woman\\n10 woman woman\\n(a) Compute the confusion matrix for the data.\\n(b) Compute the accuracy, precision, recall, sensitivity and speciﬁcity of the data.\\n5. Suppose 10000 patients get tested for ﬂu; out of them, 9000 are actually healthy and 1000\\nare actually sick. For the sick people, a test was positive for 620 and negative for 380. For\\nthe healthy people, the same test was positive for 180 and negative for 8820. Construct a\\nconfusion matrix for the data and compute the accuracy, precision and recall for the data.\\n6. Given the following data, construct the ROC curve of the data. Compute the AUC.\\nThreshold TP TN FP FN\\n1 0 25 0 29\\n2 7 25 0 22\\n3 18 24 1 11\\n4 26 20 5 3\\n5 29 11 14 0\\n6 29 0 25 0\\n7 29 0 25 0\\n7. Given the following hypothetical data at various cut-off points of mid-arm circumference of\\nmid-arm circumference to detect low birth-weight construct the ROC curve for the data.CHAPTER 5. EVALUATION OF CLASSIFIERS 60\\nMid-arm circumference (cm) Normal birth-weight Low birth-weight\\nTP TN\\n≤8:3 13 867\\n≤8:4 24 844\\n≤8:5 73 826\\n≤8:6 90 800\\n≤8:7 113 783\\n≤8:8 119 735\\n≤8:9 121 626\\n≤9:0 125 505\\n≤9:1 127 435\\n≤9:2and above 130 0Chapter 6\\nBayesian classiﬁer and ML\\nestimation\\nThe Bayesian classiﬁer is an algorithm for classifying multiclass datasets. This is based on the\\nBayes’ theorem in probability theory. Bayes in whose name the theorem is known was an English\\nstatistician who was known for having formulated a speciﬁc case of a theorem that bears his name.\\nThe classiﬁer is also known as “naive Bayes Algorithm” where the word “naive” is an English word\\nwith the following meanings: simple, unsophisticated, or primitive. We ﬁrst explain Bayes’ theorem\\nand then describe the algorithm. Of course, we require the notion of conditional probability.\\n6.1 Conditional probability\\nThe probability of the occurrence of an event Agiven that an event Bhas already occurred is called\\ntheconditional probability of AgivenBand is denoted by P(A/divides.alt0B). We have\\nP(A/divides.alt0B)=P(A∩B)\\nP(B)ifP(B)≠0:\\n6.1.1 Independent events\\n1. Two events AandBare said to be independent if\\nP(A∩B)=P(A)P(B):\\n2. Three events A;B;C are said to be pairwise independent if\\nP(B∩C)=P(B)P(C)\\nP(C∩A)=P(C)P(A)\\nP(A∩B)=P(A)P(B)\\n3. Three events A;B;C are said to be mutually independent if\\nP(B∩C)=P(B)P(C) (6.1)\\nP(C∩A)=P(C)P(A) (6.2)\\nP(A∩B)=P(A)P(B) (6.3)\\nP(A∩B∩C)=P(A)P(B)P(C) (6.4)\\n4. In general, a family of keventsA1;A2;:::;Akis said to be mutually independent if for any\\nsubfamily consisting of Ai1;:::Aimwe have\\nP(Ai1∩:::∩Aim)=P(Ai1):::P(Aim):\\n61CHAPTER 6. BAYESIAN CLASSIFIER AND ML ESTIMATION 62\\nRemarks\\nConsider events and respective probabilities as shown in Figure 6.1. It can be seen that, in this case,\\nthe conditions Eqs.(6.1)–(6.3) are satisﬁed, but Eq.(6.4) is not satisﬁed. But if the probabilities are\\nas in Figure 6.2, then Eq.(6.4) is satisﬁed but all the conditions in Eqs.(6.1)–(6.2) are not satisﬁed.\\nFigure 6.1: Events A;B;C which are not mutually independent: Eqs.(6.1)–(6.3) are satisﬁed, but\\nEq.(6.4) is not satisﬁed.\\nFigure 6.2: Events A;B;C which are not mutually independent: Eq.(6.4) is satisﬁed but Eqs.(6.1)–\\n(6.2) are not satisﬁed.\\n6.2 Bayes’ theorem\\n6.2.1 Theorem\\nLetAandBany two events in a random experiment. If P(A)≠0, then\\nP(B/divides.alt0A)=P(A/divides.alt0B)P(B)\\nP(A):\\n6.2.2 Remarks\\n1. The importance of the result is that it helps us to “invert” conditional probabilities, that is, to\\nexpress the conditional probability P(A/divides.alt0B)in terms of the conditional probability P(B/divides.alt0A).\\n2. The following terminology is used in this context:\\n•Ais called the proposition andBis called the evidence .\\n•P(A)is called the prior probability of proposition and P(B)is called the prior proba-\\nbility of evidence.CHAPTER 6. BAYESIAN CLASSIFIER AND ML ESTIMATION 63\\n•P(A/divides.alt0B)is called the posterior probability ofAgivenB.\\n•P(B/divides.alt0A)is called the likelihood ofBgivenA.\\n6.2.3 Generalisation\\nLet the sample space be divided into disjoint events B1;B2;:::;BnandAbe any event. Then we\\nhave\\nP(Bk/divides.alt0A)=P(A/divides.alt0Bk)P(Bk)\\n∑n\\ni=1P(A/divides.alt0Bi)P(Bi)\\n6.2.4 Examples\\nProblem 1\\nConsider a set of patients coming for treatment in a certain clinic. Let Adenote the event that\\na “Patient has liver disease” and Bthe event that a “Patient is an alcoholic.” It is known from\\nexperience that 10% of the patients entering the clinic have liver disease and 5% of the patients are\\nalcoholics. Also, among those patients diagnosed with liver disease, 7% are alcoholics. Given that\\na patient is alcoholic, what is the probability that he will have liver disease?\\nSolution\\nUsing the notations of probability, we have\\nP(A)=10%=0:10\\nP(B)=5%=0:05\\nP(B/divides.alt0A)=7%=0:07\\nP(A/divides.alt0B)=P(B/divides.alt0A)P(A)\\nP(B)\\n=0:07×0:10\\n0:05\\n=0:14\\nProblem 2\\nThree factories A, B, C of an electric bulb manufacturing company produce respectively 35%. 35%\\nand 30% of the total output. Approximately 1.5%, 1% and 2% of the bulbs produced by these\\nfactories are known to be defective. If a randomly selected bulb manufactured by the company was\\nfound to be defective, what is the probability that the bulb was manufactures in factory A?\\nSolution\\nLetA;B;C denote the events that a randomly selected bulb was manufactured in factory A, B, C\\nrespectively. Let Ddenote the event that a bulb is defective. We have the following data:\\nP(A)=0:35; P(B)=0:35; P(C)=0:30\\nP(D/divides.alt0A)=0:015; P(D/divides.alt0B)=0:010; P(D/divides.alt0C)=0:020\\nWe are required to ﬁnd P(A/divides.alt0D). By the generalisation of the Bayes’ theorem we have:\\nP(A/divides.alt0D)=P(D/divides.alt0A)P(A)\\nP(D/divides.alt0A)P(A)+P(D/divides.alt0B)P(B)+P(D/divides.alt0C)P(C)\\n=0:015×0:35\\n0:015×0:35+0:010×0:35+0:020×0:30\\n=0:356:CHAPTER 6. BAYESIAN CLASSIFIER AND ML ESTIMATION 64\\n6.3 Naive Bayes algorithm\\n6.3.1 Assumption\\nThe naive Bayes algorithm is based on the following assumptions:\\n• All the features are independent and are unrelated to each other. Presence or absence of a\\nfeature does not inﬂuence the presence or absence of any other feature.\\n• The data has class-conditional independence , which means that events are independent so\\nlong as they are conditioned on the same class value.\\nThese assumptions are, in general, true in many real world problems. It is because of these assump-\\ntions, the algorithm is called a naive algorithm.\\n6.3.2 Basic idea\\nSuppose we have a training data set consisting of Nexamples having nfeatures. Let the features\\nbe named as (F1;:::;Fn). A feature vector is of the form (f1;f2;:::;fn). Associated with each\\nexample, there is a certain class label. Let the set of class labels be {c1;c2;:::;cp}.\\nSuppose we are given a test instance having the feature vector\\nX=(x1;x2;:::;xn):\\nWe are required to determine the most appropriate class label that should be assigned to the test\\ninstance. For this purpose we compute the following conditional probabilities\\nP(c1/divides.alt0X);P(c2/divides.alt0X);:::;P(cp/divides.alt0X): (6.5)\\nand choose the maximum among them. Let the maximum probability be P(ci/divides.alt0X). Then, we choose\\ncias the most appropriate class label for the training instance having Xas the feature vector.\\nThe direct computation of the probabilities given in Eq.(6.5) are difﬁcult for a number of reasons.\\nThe Bayes’ theorem can b applied to obtain a simpler method. This is explained below.\\n6.3.3 Computation of probabilities\\nUsing Bayes’ theorem, we have:\\nP(ck/divides.alt0X)=P(X/divides.alt0ck)P(ck)\\nP(X)(6.6)\\nSince, by assumption, the data has class-conditional independence, we note that the events “ x1/divides.alt0ck”,\\n“x2/divides.alt0ck”,/uni22EF,xn/divides.alt0ckare independent (because they are all conditioned on the same class label ck).\\nHence we have\\nP(X/divides.alt0ck)=P((x1;x2;:::;xn)/divides.alt0ck)\\n=P(x1/divides.alt0ck)P(x2/divides.alt0ck)/uni22EFP(xn/divides.alt0ck)\\nUsing this in Eq,(6.6) we get\\nP(ck/divides.alt0X)=P(x1/divides.alt0ck)P(x2/divides.alt0ck)/uni22EFP(xn/divides.alt0ck)P(ck)\\nP(X):\\nSince the denominator P(X)is independent of the class labels, we have\\nP(ck/divides.alt0X)∝P(x1/divides.alt0ck)P(x2/divides.alt0ck)/uni22EFP(xn/divides.alt0ck)P(ck):\\nSo it is enough to ﬁnd the maximum among the following values:\\nP(x1/divides.alt0ck)P(x2/divides.alt0ck)/uni22EFP(xn/divides.alt0ck)P(ck); k=1;:::;p:CHAPTER 6. BAYESIAN CLASSIFIER AND ML ESTIMATION 65\\nRemarks\\nThe various probabilities in the above expression are computed as follows:\\nP(ck)=No. of examples with class label ck\\nTotal number of examples\\nP(xj/divides.alt0ck)=No. of examples with jth feature equal to xjand class label ck\\nNo. of examples with class label ck\\n6.3.4 The algorithm\\nAlgorithm: Naive Bayes\\nLet there be a training data set having nfeaturesF1;:::;Fn. Letf1denote an arbitrary value of F1,\\nf2ofF2, and so on. Let the set of class labels be {c1;c2;:::;cp}. Let there be given a test instance\\nhaving the feature vector\\nX=(x1;x2;:::;xn):\\nWe are required to determine the most appropriate class label that should be assigned to the test\\ninstance.\\nStep 1. Compute the probabilities P(ck)fork=1;:::;p .\\nStep 2. Form a table showing the conditional probabilities\\nP(f1/divides.alt0ck); P(f2/divides.alt0ck); ::: ;P (fn/divides.alt0ck)\\nfor all values of f1;f2;:::;fnand fork=1;:::;p .\\nStep 3. Compute the products\\nqk=P(x1/divides.alt0ck)P(x2/divides.alt0ck)/uni22EFP(xn/divides.alt0ck)P(ck)\\nfork=1;:::;p .\\nStep 4. Findjsuchqj=max{q1;q2;:::;qp}.\\nStep 5. Assign the class label cjto the test instance X.\\nRemarks\\nIn the above algorithm, Steps 1 and 2 constitute the learning phase of the algorithm. The remaining\\nsteps constitute the testing phase. For testing purposes, only the table of probabilities is required;\\nthe original data set is not required.\\n6.3.5 Example\\nProblem\\nConsider a training data set consisting of the fauna of the world. Each unit has three features named\\n“Swim”, “Fly” and “Crawl”. Let the possible values of these features be as follows:\\nSwim Fast, Slow, No\\nFly Long, Short, Rarely, No\\nCrawl Yes, No\\nFor simplicity, each unit is classiﬁed as “Animal”, “Bird” or “Fish”. Let the training data set be as in\\nTable 6.1. Use naive Bayes algorithm to classify a particular species if its features are (Slow, Rarely,\\nNo)?CHAPTER 6. BAYESIAN CLASSIFIER AND ML ESTIMATION 66\\nSl. No. Swim Fly Crawl Class\\n1 Fast No No Fish\\n2 Fast No Yes Animal\\n3 Slow No No Animal\\n4 Fast No No Animal\\n5 No Short No Bird\\n6 No Short No Bird\\n7 No Rarely No Animal\\n8 Slow No Yes Animal\\n9 Slow No No Fish\\n10 Slow No Yes Fish\\n11 No Long No Bird\\n12 Fast No No Bird\\nTable 6.1: Sample data set for naive Bayes algorithm\\nSolution\\nIn this example, the features are\\nF1=“Swim”; F 2=“Fly”; F 3=“Crawl”:\\nThe class labels are\\nc1=“Animal”; c 2=“ Bird”; c 3=“Fish”:\\nThe test instance is (Slow, Rarely, No) and so we have:\\nx1=“Slow”; x 2=“Rarely”; x 3=“No”:\\nWe construct the frequency table shown in Table 6.2 which summarises the data. (It may be noted\\nthat the construction of the frequency table is not part of the algorithm.)\\nClassFeatures\\nTotal Swim (F1) Fly (F2) Crawl (F3)\\nFast Slow No Long Short Rarely No Yes No\\nAnimal (c1) 2 2 1 0 0 1 4 2 3 5\\nBird (c2) 1 0 3 1 2 0 1 1 3 4\\nFish (c3) 1 2 0 0 0 0 3 0 3 3\\nTotal 4 4 4 1 2 1 8 4 8 12\\nTable 6.2: Frequency table for the data in Table 6.1\\nStep 1. We compute following probabilities.\\nP(c1)=No. of records with class label “Animal”\\nTotal number of examples\\n=5/slash.left12\\nP(c2)=No. of records with class label “Bird”\\nTotal number of examples\\n=4/slash.left12\\nP(c3)=No of records with class label “Fish”\\nTotal number of examples\\n=3/slash.left12CHAPTER 6. BAYESIAN CLASSIFIER AND ML ESTIMATION 67\\nStep 2. We construct the following table of conditional probabilities:\\nClassFeatures\\nSwim (F1) Fly (F2) Crawl (F3)\\nf1 f2 f3\\nFast Slow No Long Short Rarely No Yes No\\nAnimal (c1)2/5 2/5 1/5 0/5 0/5 1/5 4/5 2/5 3/5\\nBird (c2) 1/4 0/4 3/4 1/4 2/4 0/4 1/4 0/4 4/4\\nFish (c3) 1 3 2/3 0/3 0/3 0/3 0/3 3/3 0/3 3/3\\nTable 6.3: Table of the conditional probabilities P(fi/divides.alt0ck)\\nNote: The conditional probabilities are calculated as follows:\\nP((F1=Slow)/divides.alt0c1)=No. of records with F1= Slow and class label c1\\nNo. of records with class label c1\\n=2/slash.left5:\\nStep 3. We now calculate the following numbers:\\nq1=P(x1/divides.alt0c1)P(x2/divides.alt0c1)P(x3/divides.alt0c1)P(c1)\\n=(2/slash.left5)×(1/slash.left5)×(3/slash.left5)×(5/slash.left12)\\n=0:02\\nq2=P(x1/divides.alt0c2)P(x2/divides.alt0c2)P(x3/divides.alt0c2)P(c2)\\n=(0/slash.left4)×(0/slash.left4)×(3/slash.left4)×(4/slash.left12)\\n=0\\nq3=P(x1/divides.alt0c3)P(x2/divides.alt0c3)P(x3/divides.alt0c3)P(c3)\\n=(2/slash.left3)×(0/slash.left3)×(3/slash.left3)×(3/slash.left12)\\n=0\\nStep 4. Now\\nmax{q1;q2;q3}=0:05:\\nStep 5. The maximum is q1an it corresponds to the class label\\nc1=“ Animal”:\\nSo we assign the class label “Animal” to the test instance “(Slow, Rarely, No)”.\\n6.4 Using numeric features with naive Bayes algorithm\\nThe naive Bayes algorithm can be applied to a data set only if the features are categorical. This is\\nso because, the various probabilities are computed using the various frequencies and the frequencies\\ncan be counted only if each feature has a limited set of values.\\nIf a feature is numeric, it has to be discretized before applying the algorithm. The discretization\\nis effected by putting the numeric values into categories known as bins. Because of this discretization\\nis also known as binning . This is ideal when there are large amounts of data.\\nThere are several different ways to discretize a numeric feature.\\n1. If there are natural categories or cut points in the distribution of values, use these cut points to\\ncreate the bins. For example, let the data consists of records of times when certain activities\\nwere carried out. The the categories, or bins, may be created as in Figure 6.3.CHAPTER 6. BAYESIAN CLASSIFIER AND ML ESTIMATION 68\\nFigure 6.3: Discretization of numeric data: Example\\n2. If there are no obvious cut points, we may discretize the feature using quantiles. We may\\ndivide the data into three bins with tertiles, four bins with quartiles, or ﬁve bins with quintiles,\\netc.\\n6.5 Maximum likelihood estimation (ML estimation)\\nTo develop a Bayesian classiﬁer, we need the probabilities P(x/divides.alt0ck)for the class labels c1;:::;ck.\\nThese probabilities are estimated from the given data. There is need to know whether the sample\\nis truly random so that the computed probabilities are good approximations to true probabilities. If\\nthey are good approximations of true probabilities, then there would be an underlying probability\\ndistribution. Suppose we have reasons to believe that the underlying distribution has a particular\\nform, say binomial, Poisson or normal. These forms are deﬁned by probability functions or proba-\\nbility density functions. There are parameters which deﬁne these functions, and these parameters are\\nto be estimated to test whether a given data follow some particular distribution. Maximum likelihood\\nestimation is particular method to estimate the parameters of a probability distribution.\\nDeﬁnition\\nMaximum likelihood estimation (MLE) is a method of estimating the parameters of a statistical\\nmodel, given observations. MLE attempts to ﬁnd the parameter values that maximize the likelihood\\nfunction , given the observations. The resulting estimate is called a maximum likelihood estimate ,\\nwhich is also abbreviated as MLE.\\n6.5.1 The general MLE method\\nSuppose we have a random sample X={x1;:::;xn}taken from a probability distribution having\\nthe probability mass function or probability density function p(x/divides.alt0\\x12)wherexdenotes a value of the\\nrandom variable and \\x12denotes the set of parameters that appear in the function.\\nThelikelihood of sampleXis a function of the parameter \\x12and is deﬁned as\\nl(\\x12)=p(x1/divides.alt0\\x12)p(x2/divides.alt0\\x12):::p(xn/divides.alt0\\x12):\\nIn maximum likelihood estimation, we ﬁnd the value of \\x12that makes the value of the likelihood\\nfunction maximum. For computation convenience, we deﬁne the log likelihood function as the\\nlogarithm of the likelihood function:\\nL(\\x12)=logl(\\x12)\\n=logp(x1/divides.alt0\\x12)+logp(x2/divides.alt0\\x12)+/uni22EF+ logp(xn/divides.alt0\\x12):CHAPTER 6. BAYESIAN CLASSIFIER AND ML ESTIMATION 69\\nA value of\\x12that maximizes L(\\x12)will also maximise l(\\x12)and vice-versa. Hence, in maximum like-\\nlihood estimation, we ﬁnd \\x12that maximizes the log likelihood function. Sometimes the maximum\\nlikelihood estimate of \\x12is denoted by ^\\x12.\\n6.5.2 Special cases\\n1. Bernoulli density\\nIn a Bernoulli distribution there are two outcomes: An event occurs or it does not, for example, an\\ninstance is a positive example of the class, or it is not. The event occurs and the Bernoulli random\\nvariableXtakes the value 1with probability p, and the nonoccurrence of the event has probability\\n1−pand this is denoted by Xtaking the value 0.\\nThe probability function of Xis given by\\nf(x/divides.alt0p)=px(1−p)1−x; x=0;1:\\nIn this function, the probability pis the only parameter.\\nEstimation of p\\nConsider a random sample X={x1;:::;xn}taken from a Bernoulli distribution with the probability\\nfunctionf(x/divides.alt0p). The log likelihood function is\\nL(p)=logf(x1/divides.alt0p)+/uni22EF+ logf(xn/divides.alt0p)\\n=logpx1(1−p)1−x1+/uni22EF+ logpxn(1−p)1−xn\\n=[x1logp+(1−x1)log(1−p)]+/uni22EF+[xnlogp+(1−xn)log(1−p)]\\nTo ﬁnd the value of pthat maximizes L(p)we set up the equation\\ndL\\ndp=0;\\nthat is,\\n/bracketleft.alt4x1\\np−1−x1\\n1−p/bracketright.alt4+/uni22EF+/bracketleft.alt4xn\\np−1−xn\\n1−p/bracketright.alt4=0:\\nSolving this equation, we have the maximum likelihood estimate of pas\\n^p=1\\nn(x1+/uni22EF+xn):\\n2. Multinomial density\\nSuppose that the outcome of a random event is one of Kclasses, each of which has a probability of\\noccurringpiwith\\np1+/uni22EF+pK=1:\\nWe represent each outcome by an ordered K-tuple x=(x1;:::;xK)where exactly one of x1;:::;xK\\nis1and all others are 0.xi=1if the outcome in the i-th class occurs. The probability function can\\nbe expressed as\\nf(x/divides.alt0p;:::;pK)=px1\\n1:::pxK\\nK:\\nHere,p1;:::;pKare the parameters.\\nWe choosenrandom samples. The i-the sample may be represented by\\nxi=(x1i;:::;xKi):\\nThe values of the parameters that maximizes the likelihood function can be shown to be\\n^pk=1\\nn(xk1+xk2+/uni22EF+xkn):\\n(We leave the details of the derivation as an exercise.)CHAPTER 6. BAYESIAN CLASSIFIER AND ML ESTIMATION 70\\n3. Gaussian (normal) density\\nA continuous random variable Xhas the Gaussian or normal distribution if its density function is\\nf(x/divides.alt0\\x16;\\x1b)=1\\n\\x1b√\\n2\\x19exp/parenleft.alt4−(x−\\x16)2\\n2\\x1b2/parenright.alt4;−∞<x<∞:\\nHere\\x16and\\x1bare the parameters.\\nGiven a sample x1;x2;:::;xnfrom the distribution. the log likelihood function is\\nL(\\x16;\\x1b)=−n\\n2log(2\\x19)−nlog\\x1b−1\\n2\\x1b2/bracketleft.alt1(x1−\\x16)2+/uni22EF+(xn−\\x16)2/bracketright.alt:\\nSetting up the equations\\ndL\\nd\\x16=0;dL\\nd\\x1b=0\\nand solving for \\x16and\\x1bwe get the maximum likelihood estimates of \\x16and\\x1bas\\n^\\x16=1\\nn(x1+/uni22EF+xn)\\n^\\x1b2=1\\nn((x1−^\\x16)2+/uni22EF+(xn−^\\x16)2)\\n(We leave the details of the derivation as an exercise.)\\n6.6 Sample questions\\n(a) Short answer questions\\n1. What are the assumptions under the naive Bayes algorithm?\\n2. Why is naive Bayes algorithm “naive”?\\n3. Given an instance Xof a feature vector and a class label ck, explain how Bayes theorem is\\nused to compute the probability P(ck/divides.alt0X).\\n4. What does a naive Bayes classiﬁer do?\\n5. What is naive Bayes used for?\\n6. Is naive Bayes supervised or unsupervised? Why?\\n7. What is meant by the likelihood of a random sample taken from population?\\n8. How do we use numeric features in naive Bayes algorithm?\\n(b) Long answer questions\\n1. State Bayes theorem and illustrate it with an example.\\n2. Explain naive Bayes algorithm.\\n3. Use naive Bayes algorithm to determine whether a red domestic SUV car is a stolen car or not\\nusing the following data:CHAPTER 6. BAYESIAN CLASSIFIER AND ML ESTIMATION 71\\nExample no. Colour Type Origin Whether stolen\\n1 red sports domestic yes\\n2 red sports domestic no\\n3 red sports domestic yes\\n4 yellow sports domestic no\\n5 yellow sports imported yes\\n6 yellow SUV imported no\\n7 yellow SUV imported yes\\n8 yellow SUV domestic no\\n9 red SUV imported no\\n10 red sports imported yes\\n4. Based on the following data determine the gender of a person having height 6 ft., weight 130\\nlbs. and foot size 8 in. (use naive Bayes algorithm).\\nperson height (feet) weight (lbs) foot size (inches)\\nmale 6.00 180 10\\nmale 6.00 180 10\\nmale 5.50 170 8\\nmale 6.00 170 10\\nfemale 5.00 130 8\\nfemale 5.50 150 6\\nfemale 5.00 130 6\\nfemale 6.00 150 8\\n5. Given the following data on a certain set of patients seen by a doctor, can the doctor conclude\\nthat a person having chills, fever, mild headache and without running nose has the ﬂu?\\nchills running nose headache fever has ﬂu\\nY N mild Y N\\nY Y no N Y\\nY N strong Y Y\\nN Y mild Y Y\\nN N no N N\\nN Y strong Y Y\\nN Y strong N N\\nY Y mild Y Y\\n6. Explain the general MLE method for estimating the parameters of a probability distribution.\\n7. Find the ML estimate for the parameter pin the binomial distribution whose probability func-\\ntion is\\nf(x)=/parenleft.alt3n\\nx/parenright.alt3px(1−p)n−x; x=0;1;2;:::;n\\n8. Compute the ML estimate for the parameter \\x15in the Poisson distribution whose probability\\nfunction is\\nf(x)=e−\\x15\\x15x\\nx!; x=0;1;2;:::\\nFind the ML estimate of the parameter pin the geometric distribution deﬁned by the proba-\\nbility mass function\\nf(x)=(1−p)px; x=1;2;3;:::Chapter 7\\nRegression\\nWe have seen in Section 1.5.3 that regression is a supervised learning problem where there is an\\ninputxan outputyand the task is to learn the mapping from the input to the output. We have also\\nseen that the approach in machine learning is that we assume a model, that is, a relation between x\\nandycontaining a set of parameters, say, \\x12in the following form:\\ny=g(x;\\x12):\\ng(x;\\x12)is the regression function. The machine learning program optimizes the parameters \\x12such\\nthat the approximation error is minimized, that is, our estimates are as close as possible to the correct\\nvalues given in the training set. In this chapter we discuss a method, known as ordinary least squares\\nmethod, to estimate the parameters. In fact this method can be derived from the maximum likelihood\\nestimation method discussed in Section 6.5.\\n7.1 Deﬁnition\\nAregression problem is the problem of determining a relation between one or more independent\\nvariables and an output variable which is a real continuous variable, given a set of observed values\\nof the set of independent variables and the corresponding values of the output variable.\\n7.1.1 Examples\\n1. Let us say we want to have a system that can predict the price of a used car. Inputs are the\\ncar attributes â ˘AˇT brand, year, engine capacity, mileage, and other information â ˘AˇT that we\\nbelieve affect a car’s worth. The output is the price of the car.\\n2. Consider the navigation of a mobile robot, say an autonomous car. The output is the angle by\\nwhich the steering wheel should be turned at each time, to advance without hitting obstacles\\nand deviating from the route. Inputs are provided by sensors on the car like a video camera,\\nGPS, and so forth.\\n3. In ﬁnance, the capital asset pricing model uses regression for analyzing and quantifying the\\nsystematic risk of an investment.\\n4. In economics, regression is the predominant empirical tool. For example, it is used to predict\\nconsumption spending, inventory investment, purchases of a country’s exports, spending on\\nimports, labor demand, and labor supply.\\n7.1.2 Different regression models\\nThe different regression models are deﬁned based on type of functions used to represent the relation\\nbetween the dependent variable yand the independent variables.\\n72CHAPTER 7. REGRESSION 73\\n1.Simple linear regression\\nAssume that there is only one independent variable x. If the relation between xandyis\\nmodeled by the relation\\ny=a+bx\\nthen we have a simple linear regression.\\n2.Multiple regression\\nLet there be more than one independent variable, say x1,x2,:::,xn, and let the relation\\nbetweenyand the independent variables be modeled as\\ny=\\x0b0+\\x0b1x1+/uni22EF+\\x0bnxn\\nthen it is case of multiple linear regression or multiple regression.\\n3.Polynomial regression\\nLet there be only one variable xand let the relation between xybe modeled as\\ny=a0+a1x+a2x2+/uni22EF+anxn\\nfor some positive integer n>1, then we have a polynomial regression.\\n4.Logistic regression\\nLogistic regression is used when the dependent variable is binary (0/1, True/False, Yes/No)\\nin nature. Even though the output is a binary variable, what is being sought is a probability\\nfunction which may take any value from 0to1.\\n7.2 Criterion for minimisation of error\\nIn regression, we would like to write the numeric output y, called the dependent variable, as a\\nfunction of the input x, called the independent variable. We assume that the output is the sum of a\\nfunctionf(x)of the input and some random error denoted by \\x0f:\\ny=f(x)+\\x0f:\\nHere the function f(x)is unknown and we would like to approximate it by some estimator g(x;\\x12)\\ncontaining a set of parameters \\x12. We assume that the random error \\x0ffollows normal distribution\\nwith mean 0.\\nLetx1;:::;xnbe a random sample of observations of the input variable xandy1;:::;ynthe\\ncorresponding observed values of the output variable y.\\nUsing the assumption that the error \\x0ffollows normal distribution, we can apply the method of\\nmaximum likelihood estimation to estimate the values of the parameter \\x12. It can be shown that the\\nvalues of\\x12which maximizes the likelihood function are the values of \\x12that minimizes the following\\nsum of squares:\\nE(\\x12)=(y1−g(x1;\\x12))2+/uni22EF+(yn−g(xn;\\x12))2:\\nThe method of ﬁnding the value of \\x12as that value of \\x12that minimizes E(\\x12)is known as the ordinary\\nleast squares method .\\nThe full details of the derivation of the above result are beyond the scope of these notes.CHAPTER 7. REGRESSION 74\\nxx1x2/uni22EFxn\\nyy1y2/uni22EFyn\\nTable 7.1: Data set for simple linear regression\\nxy\\nActual value\\nPredicted valueErrorRegression model\\nFigure 7.1: Errors in observed values\\n7.3 Simple linear regression\\nLetxbe the independent predictor variable and ythe dependent variable. Assume that we have a set\\nof observed values of xandy:\\nA simple linear regression model deﬁnes the relationship between xandyusing a line deﬁned\\nby an equation in the following form:\\ny=\\x0b+\\x0cx\\nIn order to determine the optimal estimates of \\x0band\\x0c, an estimation method known as Ordinary\\nLeast Squares (OLS) is used.\\nThe OLS method\\nIn the OLS method, the values of y-intercept and slope are chosen such that they minimize the sum\\nof the squared errors; that is, the sum of the squares of the vertical distance between the predicted\\ny-value and the actual y-value (see Figure 7.1). Let ^yibe the predicted value of yi. Then the sum of\\nsquares of errors is given by\\nE=n\\n/summation.disp\\ni=1(yi−^yi)2\\n=n\\n/summation.disp\\ni=1[yi−(\\x0b+\\x0cxi)]2\\nSo we are required to ﬁnd the values of \\x0band\\x0csuch thatEis minimum. Using methods of calculus,\\nwe can show that the values of aandb, which are respectively the values of \\x0band\\x0cfor whichEis\\nminimum, can be obtained by solving the following equations.\\nn\\n/summation.disp\\ni=1yi=na+bn\\n/summation.disp\\ni=1xiCHAPTER 7. REGRESSION 75\\nn\\n/summation.disp\\ni=1xiyi=an\\n/summation.disp\\ni=1xi+bn\\n/summation.disp\\ni=1x2\\ni\\nFormulas to ﬁnd aandb\\nRecall that the means of xandyare given by\\n\\x16x=1\\nn/summation.dispxi\\n\\x16y=1\\nn/summation.dispyi\\nand also that the variance of xis given by\\nVar(x)=1\\nn−1/summation.disp(xi−\\x16xi)2:\\nThecovariance of xandy, denoted by Cov (x;y)is deﬁned as\\nCov(x;y)=1\\nn−1/summation.disp(xi−\\x16x)(yi−\\x16y)\\nIt can be shown that the values of aandbcan be computed using the following formulas:\\nb=Cov(x;y)\\nVar(x)\\na=\\x16y−b\\x16x\\nRemarks\\nIt is interesting to note why the least squares method discussed above is christened as “ordinary”\\nleast squares method. Several different variants of the least squares method have been developed\\nover the years. For example, in the weighted least squares method, the coefﬁcients aandbare\\nestimated such that the weighted sum of squares of errors\\nE=n\\n/summation.disp\\ni=1wi[yi−(a+bxi)]2;\\nfor some positive constants w1;:::;wn, is minimum. There are also methods known by the names\\ngeneralised least squares method, partial least squares method, total least squares method, etc. The\\nreader may refer to Wikipedia , a free online encyclopedia, to obtain further information about these\\nmethods.\\nThe OLS method has a long history. The method is usually credited to Carl Friedrich Gauss\\n(1795), but it was ﬁrst published by Adrien-Marie Legendre (1805).\\nExample\\nObtain a linear regression for the data in Table 7.2 assuming that yis the independent variable.\\nx1:0 2:0 3:0 4:0 5:0\\ny1:00 2:00 1:30 3:75 2:25\\nTable 7.2: Example data for simple linear regressionCHAPTER 7. REGRESSION 76\\nFigure 7.2: Regression model for Table 7.2\\nSolution\\nIn the usual notations of simple linear regression, we have\\nn=5\\n\\x16x=1\\n5(1:0+2:0+3:0+4:0+5:0)\\n=3:0\\n\\x16y=1\\n5(1:00+2:00+1:30+3:75+2:25)\\n=2:06\\nCov(x;y)=1\\n4[(1:0−3:0)(1:00−2:06)+/uni22EF+(5:0−3:0)(2:25−2:06)]\\n=1:0625\\nVar(x)=1\\n4[(1:0−3:0)2+/uni22EF+(5:0−3:0)2]\\n=2:5\\nb=1:0625\\n2:5\\n=0:425\\na=2:06−0:425×3:0\\n=0:785\\nTherefore, the linear regression model for the data is\\ny=0:785+0:425x: (7.1)\\nRemark\\nFigure 7.2 in page 76 shows the data in Table 7.2 and the line given by Eq. (7.1). The ﬁgure was\\ncreated using R.CHAPTER 7. REGRESSION 77\\n7.4 Polynomial regression\\nLetxbe the independent predictor variable and ythe dependent variable. Assume that we have a set\\nof observed values of xandyas in Table 7.1 in page 74.\\nA polynomial regression model deﬁnes the relationship between xandyby an equation in the\\nfollowing form:\\ny=\\x0b0+\\x0b1x+\\x0b2x2+/uni22EF+\\x0bkxk:\\nTo determine the optimal values of the parameters \\x0b0,\\x0b1,:::,\\x0bkthe method of ordinary least\\nsquares is used. The values of the parameters are those values which minimizes the sum of squares:\\nE=n\\n/summation.disp\\ni=1[yi−(\\x0b0+\\x0b1xi+\\x0b2x2\\ni+/uni22EF+\\x0bkxk\\ni)]2:\\nThe optimal values of the parameters are obtained by solving the following system of equations:\\n@E\\n@\\x0bi=0; i=0;1;:::;k: (7.2)\\nLet the values of values of the parameters which minimizes Ebe\\n\\x0bi=ai; i=0;1;2;:::;n: (7.3)\\nSimplifying Eq. (7.2) and using Eq. (7.3), we can see that the values of aican be obtained by\\nsolving the the following system of (k+1)linear equations:\\n/summation.dispyi=\\x0b0n+\\x0b1(/summation.dispxi)+/uni22EF+\\x0bk(/summation.dispxk\\ni)\\n/summation.dispyixi=\\x0b0(/summation.dispxi)+\\x0b1(/summation.dispx2\\ni)+/uni22EF+\\x0bk(/summation.dispxk+1\\ni)\\n/summation.dispyix2\\ni=\\x0b0(/summation.dispx2\\ni)+\\x0b1(/summation.dispx3\\ni)+/uni22EF+\\x0bk(/summation.dispxk+2\\ni)\\n⋮\\n/summation.dispyixk\\ni=\\x0b0(/summation.dispxk\\ni)+\\x0b1(/summation.dispxk+1\\ni)+/uni22EF+\\x0bk(/summation.dispx2k\\ni)\\nSolving this system of linear equations we get the optimal values for the parameters.\\nRemarks\\nThe linear system of equations to ﬁnd ai’s, has a compact matrix representation. We write:\\nD=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A31x1x2\\n1/uni22EFxk\\n1\\n1x2x2\\n2/uni22EFxk\\n2\\n⋮\\n1xnx2\\nn/uni22EFxk\\nn/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6;/uni20D7y=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A3y1\\ny2\\n⋮\\nyn/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6;/uni20D7a=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A3a0\\na1\\n⋮\\nak/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6\\nThen we have\\n/uni20D7a=(DTD)−1DT/uni20D7y;\\nwhere the superscript Tdenotes the transpose of the matrix.\\n7.4.1 Example\\nFind a quadratic regression model for the following data:\\nx 3 4 5 6 7\\ny2.5 3.2 3.8 6.5 11.5CHAPTER 7. REGRESSION 78\\nFigure 7.3: Plot of quadratic polynomial model\\nSolution\\nLet the quadratic regression model be\\ny=\\x0b0+\\x0b1x+\\x0b2x2:\\nThe values of \\x0b0,\\x0b1and\\x0b2which minimises the sum of squares of errors are a0,a1anda2which\\nsatisfy the following system of equations:\\n/summation.dispyi=na0+a1(/summation.dispxi)+a2(/summation.dispx2\\ni)\\n/summation.dispyixi=a0(/summation.dispxi)+a1(/summation.dispx2\\ni)+a2(/summation.dispx3\\ni)\\n/summation.dispyix2\\ni=a0(/summation.dispx2\\ni)+a1(/summation.dispx3\\ni)+a2(/summation.dispx4\\ni)\\nUsing the given data we have\\n27:5=5a0+25a1+135a2\\n158:8=25a0+135a1+775a2\\n966:2=135a0+775a1+4659a2\\nSolving this system of equations we get\\na0=12:4285714\\na1=−5:5128571\\na2=0:7642857\\nThe required quadratic polynomial model is\\ny=12:4285714−5:5128571x+0:7642857x2:\\nFigure 7.3 shows plots of the data and the quadratic polynomial model.\\n7.5 Multiple linear regression\\nWe assume that there are Nindependent variables x1,x2,/uni22EF,xN. Let the dependent variable be y.\\nLet there also be nobserved values of these variables:CHAPTER 7. REGRESSION 79\\nVariables Values (examples)\\n(features) Example 1 Example 2 /uni22EF Examplen\\nx1 x11 x12/uni22EFx1n\\nx2 x21 x22/uni22EFx2n\\n/uni22EF\\nxN xN1xN2/uni22EFxNn\\ny(outcomes) y1 y2/uni22EFyn\\nTable 7.3: Data for multiple linear regression\\nThe multiple linear regression model deﬁnes the relationship between the Nindependent vari-\\nables and the dependent variable by an equation of the following form:\\ny=\\x0c0+\\x0c1x1+/uni22EF+\\x0cNxN\\nAs in simple linear regression, here also we use the ordinary least squares method to obtain the\\noptimal estimates of \\x0c0,\\x0c1,/uni22EF,\\x0cN. The method yields the following procedure for the computation\\nof these optimal estimates. Let\\nX=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A31x11x21/uni22EFxN1\\n1x12x22/uni22EFxN2\\n⋮\\n1x1nx2n/uni22EFxNn/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6; Y=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A3y1\\ny2\\n⋮\\nyn/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6; B=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A3\\x0c0\\n\\x0c1\\n⋮\\n\\x0cN/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6\\nThen it can be shown that the regression coefﬁcients are given by\\nB=(XTX)−1XTY\\n7.5.1 Example\\nExample\\nFit a multiple linear regression model to the following data:\\nx1 1 1 2 0\\nx2 1 2 2 1\\ny 3.25 6.5 3.5 5.0\\nTable 7.4: Example data for multi-linear regression\\nSolution\\nIn this problem, there are two independent variables andfour sets of values of the variables. Thus,\\nin the notations used above, we have n=2andN=4. The multiple linear regression model for this\\nproblem has the form\\ny=\\x0c0+\\x0c1x1+\\x0c2x2:\\nThe computations are shown below.\\nX=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A31 1 1\\n1 1 2\\n1 2 2\\n1 0 1/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6; Y=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A33:25\\n6:5\\n3:5\\n5:0/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6; B=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A3\\x0c0\\n\\x0c1\\n\\x0c2/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6CHAPTER 7. REGRESSION 80\\nXTX=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A34 4 6\\n4 6 7\\n6 7 10/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6\\n(XTX)−1=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A311\\n41\\n2−2\\n1\\n21−1\\n−2−1 2/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6\\nB=(XTX)−1XTY\\n=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A32:0625\\n−2:3750\\n3:2500/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6\\nThe required model is\\ny=2:0625−2:3750x1+3:2500x2:\\nx1x2y\\n(1,1,3.25)(1,2,6.25)\\n(2,2,3.25)(0,1,5.0)\\ny=2:0625−2:3750x1+3:2500x2\\nFigure 7.4: The regression plane for the data in Table 7.4\\n7.6 Sample questions\\n(a) Short answer questions\\n1. What are the different types of regression.\\n2. Is regression a supervised learning? Why?\\n3. Explain the ordinary least squares method for regression.\\n4. What are linear, multinomial and polynomial regressions.\\n5. If model used for regression is\\ny=a+b(x−1)2;\\nis it a multinomial regression? If not, what type of regression is it?\\n6. What does the line of regression tell you?CHAPTER 7. REGRESSION 81\\n(b) Long answer questions\\n1. Discuss linear regression with an example.\\n2. In the table below, the xirow shows scores in an aptitude test. Similarly, the yirow shows\\nstatistics grades. If a student made an 80 on the aptitude test, what grade would we expect her\\nto make in statistics?\\nStudenti1 2 3 4 5\\nxi 95 85 80 70 60\\nyi 85 95 70 65 70\\n3. Use the following data to construct a linear regression model for the auto insurance premium\\nas a function of driving experience.\\nDriving experience (in years) 5 2 12 9 15 6 25 16\\nMonthly auto insurance premium ($) 64 87 50 71 44 56 42 60\\n4. Determine the regression equation by ﬁnding the regression slope coefﬁcient and the intercept\\nvalue using the following data.\\nx55 60 65 70 80\\ny52 54 56 58 62\\n5. The following table contains measurements of yield from an experiment done at ﬁve different\\ntemperature levels. The variables are y= yield and x= temperature in degrees Fahrenheit.\\nCompute a second degree polynomial regression model to predict the yield given the temper-\\nature.\\nTemperature ( x) Yield (y)\\n50 3.0\\n70 2.7\\n80 2.6\\n90 2.9\\n100 3.3\\n6. An experiment was done to assess how moisture content and sweetness of a pastry product\\naffect a tasterâ ˘A´Zs rating of the product. The following table summarises the ﬁndings.\\nRating Moisture Sweetness\\n64 4 2\\n73 4 4\\n61 4 2\\n76 4 4\\n72 6 2\\n80 6 4\\n71 6 2\\n83 6 4\\n83 8 2\\n89 8 4\\n86 8 2\\n93 8 4\\n88 10 2\\n95 10 4\\n94 10 2\\n100 10 4CHAPTER 7. REGRESSION 82\\nCompute a linear regression model to predict the rating of the pastry product.\\n7. The following data contains the Performance IQ scores (PIQ) (in appropriate scales), brain\\nsizes (in standard units), heights (in inches) and weights (in pounds) of 15 American college\\nstudents. Obtain a linear regression model to predict the PIQ given the values of the other\\nfeatures.\\nPIQ Brain Height Weight\\n124 81.69 64.5 118\\n150 103.84 73.3 143\\n128 96.54 68.8 172\\n134 95.15 65.0 147\\n110 92.88 69.0 146\\n131 99.13 64.5 138\\n98 85.43 66.0 175\\n84 90.49 66.3 134\\n147 95.55 68.8 172\\n124 83.39 64.5 118\\n128 107.95 70.0 151\\n124 92.41 69.0 155\\n147 85.65 70.5 155\\n90 87.89 66.0 146\\n96 86.54 68.0 135\\n8. Use the following data to generate a linear regression model for annual salary as function of\\nGPA and number of months worked.\\nExample no. Annual salary ($) GPA Months worked\\n1 20000 2.8 48\\n2 24500 3.4 24\\n3 23000 3.2 24\\n4 25000 3.8 24\\n5 20000 3.2 48\\n6 22500 3.4 36\\n7 27500 4.0 24\\n8 19000 2.6 48\\n9 24000 3.2 36\\n10 28500 3.8 12Chapter 8\\nDecision trees\\n“Decision tree learning is a method for approximating discrete valued target functions, in which the\\nlearned function is represented by a decision tree. Decision tree learning is one of the most widely\\nused and practical methods for inductive inference.” ([4] p.52)\\n8.1 Decision tree: Example\\nConsider the following situation. Somebody is hunting for a job. At the very beginning, he decides\\nthat he will consider only those jobs for which the monthly salary is at least Rs.50,000. Our job\\nhunter does not like spending much time traveling to place of work. He is comfortable only if the\\ncommuting time is less than one hour. Also, he expects the company to arrange for a free coffee\\nevery morning! The decisions to be made before deciding to accept or reject a job offer can be\\nschematically represented as in Figure 8.6. This ﬁgure represents a decision tree1.\\nRoot node\\nSalary≥Rs.50000?\\nCommute one hour?\\nDecline offerYes\\nOffers free coffee?\\nAccept offerYes\\nDecline offerNoNoYes\\nDecline offerNo\\nFigure 8.1: Example for a decision tree\\nHere, the term “tree” refers to the concept of a tree in graph theory in mathematics2.In graph\\ntheory, a tree is deﬁned as an undirected graph in which any two vertices are connected by exactly\\none path. Using the conventions of graph theory, the decision tree shown in Figure 8.6 can be\\nrepresented as a graph-theoretical tree as in Figure 8.2. Since a decision tree is a graph-theoretical\\ntree, all terminology related to graph-theoretical trees can be applied to describe decision trees also.\\nFor example, in Figure 8.6, the nodes or vertices shown as ellipses are called the leaf nodes . All\\nother nodes, except the root node, are called the internal nodes .\\n1In such diagrams, the “tree” is shown upside down with the root node at the top and all the leaves at the bottom.\\n2The term “tree” was coined in 1857 by the British mathematician Arthur Cayley (see Wikipedia).\\n83CHAPTER 8. DECISION TREES 84\\nRoot node\\nYes\\nYes NoNoYes No\\nFigure 8.2: The graph-theoretical representation of the decision tree in Figure 8.6\\n8.2 Two types of decision trees\\nThere are two types of decision trees.\\n1.Classiﬁcation trees\\nTree models where the target variable can take a discrete set of values are called classiﬁcation\\ntrees . In these tree structures, leaves represent class labels and branches represent conjunc-\\ntions of features that lead to those class labels.\\n2.Regression trees\\nDecision trees where the target variable can take continuous values (real numbers) like the\\nprice of a house, or a patient’s length of stay in a hospital, are called regression trees .\\n8.3 Classiﬁcation trees\\nWe illustrate the concept with an example.\\n8.3.1 Example\\nData\\nNamFeaturesClass label\\ngives birthaquatic\\nanimalaerial\\nanimalhas legs\\nhuman yes no no yes mammal\\npython no no no no reptile\\nsalmon no yes no no ﬁsh\\nfrog no semi no yes amphibian\\nbat yes no yes yes bird\\npigeon no no yes yes bird\\ncat yes no no yes mammal\\nshark yes yes no no ﬁsh\\nturtle no semi no yes amphibian\\nsalamander no semi no yes amphibian\\nTable 8.1: The vertebrate data setCHAPTER 8. DECISION TREES 85\\nConsider the data given in Table 8.1 which specify the features of certain vertebrates and the class\\nto which they belong. For each species, four features have been identiﬁed: “gives birth”, ”aquatic\\nanimal”, “aerial animal” and “has legs”. There are ﬁve class labels, namely, “amphibian”, “bird”,\\n“ﬁsh”, “mammal” and “reptile”. The problem is how to use this data to identify the class of a newly\\ndiscovered vertebrate.\\nConstruction of the tree\\nStep 1\\nWe split the set of examples given in Table 8.1 into disjoint subsets according to the values of the\\nfeature “gives birth”. Since there are only two possible values for this feature, we have only two\\nsubsets: One subset consisting of those examples for which the value of “gives birth” is “yes” and\\none subset for which the value is “no”. The former is given in Table 8.2 and the latter in Table 8.3.\\nThis stage of the classiﬁcation can be represented as in Figure 8.3.\\nName Gives\\nbirthAquatic\\nanimalAerial\\nanimalHas legs Class la-\\nbel\\nhuman yes no no yes mammal\\nbat yes no yes yes bird\\ncat yes no no yes mammal\\nshark yes yes no no ﬁsh\\nTable 8.2: The subset of Table 8.1 with “gives birth” =”yes\"\\nName gives birth aquatic\\nanimalaerial\\nanimalhas legs Class la-\\nbel\\npython no no no no reptile\\nsalmon no yes no no ﬁsh\\nfrog no semi no yes amphibian\\npigeon no no yes yes bird\\nturtle no semi no yes amphibian\\nsalamander no semi no yes amphibian\\nTable 8.3: The subset of Table 8.1 with “gives birth” =”no\"\\nRoot node\\nTable 8.1:\\ngives birth?\\nTable 8.2:\\naquatic?Yes\\nTable 8.3:\\naquatic?No\\nFigure 8.3: Classiﬁcation tree\\nStep 2\\nWe now consider the examples in Table 8.2. We split these examples based on the values of the\\nfeature “aquatic animal”. There are three possible values for this feature. However, only two ofCHAPTER 8. DECISION TREES 86\\nName gives birth aquatic\\nanimalaerial\\nanimalhas legs Class la-\\nbel\\nhuman yes no no yes mammal\\nbat yes no yes yes bird\\ncat yes no no yes mammal\\nTable 8.5: The vertebrate data set\\nRoot node\\nTable 8.1:\\ngives birth?\\nTable 8.2:\\naquatic?\\nTable 8.4\\nﬁshyes\\nTable 8.5:\\naerial?\\nPart of\\nTable 8.5\\nbirdyes\\nPart of\\nTable 8.5\\nmammalnonoYes\\nTable 8.3:\\naquatic?no\\nFigure 8.4: Classiﬁcation tree\\nthese appear in Table 8.2. Accordingly, we need consider only two subsets. These are shown in\\nTables 8.4 and 8.5.\\nName gives birth aquatic\\nanimalaerial\\nanimalhas legs Class la-\\nbel\\nshark yes yes no no ﬁsh\\nTable 8.4: The vertebrate data set\\n• Table 8.4 contains only one example and hence no further splitting is required. It leads to the\\nassignment of the class label “ﬁsh”.\\n• The examples in Table 8.5 need to be split into subsets based on the values of “aerial animal”.\\nIt can be seen that these subsets immediately lead to unambiguous assignment of class labels:\\nThe value of “no” leads to “mammal” and the value “yes” leads to ”bird”.\\nAt this stage, the classiﬁcation tree is as shown in Figure 8.4CHAPTER 8. DECISION TREES 87\\nStep 3\\nNext we consider the examples in Table 8.3 and split them into disjoint subsets based on the values\\nof “aquatic animal”. We get the examples in Table 8.6 for “yes”, the examples in Table ??for “no”\\nand the examples in Table ??for “semi”. We now split the resulting subsets based on the values of\\nName gives birth aquatic\\nanimalaerial\\nanimalhas legs Class la-\\nbel\\nsalmon no yes no no ﬁsh\\nTable 8.6: The vertebrate data set\\nName gives birth aquatic\\nanimalaerial\\nanimalhas legs Class la-\\nbel\\nfrog no semi no yes amphibian\\nturtle no semi no yes amphibian\\nsalamander no semi no yes amphibian\\nTable 8.7: The vertebrate data set\\nName gives birth aquatic\\nanimalaerial\\nanimalhas legs Class la-\\nbel\\npython no no no no reptile\\npigeon no no yes yes bird\\nTable 8.8: The vertebrate data set\\n“has legs”, etc. Putting all these together, we get the the diagram in Figure 8.5 as the classiﬁcation\\ntree for the data in Table 8.1.\\n8.3.2 Classiﬁcation tree in rule format\\nThe classiﬁcation tree shown in Figure 8.5 can be presented as a set of rules in the form of an\\nalgorithm.\\nAlgorithm for classiﬁcation of vertebrates\\n1.ifgive birth = ”yes” then\\n2. ifaquatic = “yes” then\\n3. return class = “ﬁsh”\\n4. else\\n5. ifaerial = “yes” then\\n6. return class = “bird”\\n7. else\\n8. return class = “mammal”\\n9. end if\\n10. end if\\n11.else\\n12. ifaquatic = “yes” then\\n13. return class = “ﬁsh”CHAPTER 8. DECISION TREES 88\\nRoot node\\nTable 8.1:\\ngives birth?\\nTable 8.2:\\naquatic?\\nTable 8.4\\nﬁshyes\\nTable 8.5:\\naerial?\\nPart of\\nTable 8.5\\nbirdyes\\nPart of\\nTable 8.5\\nmammalnonoyes\\nTable 8.3:\\naquatic?\\nTable 8.6\\nﬁshyes\\nTable 8.7\\namphsemi\\nTable 8.8\\naerial?\\nPart of\\nTable 8.8\\nbirdyes\\nPart of\\nTable 8.8\\nreptilenonono\\nFigure 8.5: Classiﬁcation tree\\n14. end if\\n15. ifaquatic = “semi” then\\n16. return class = “amphibian”\\n17. else\\n18. ifaerial = “yes” then\\n19. return class = “amphibian”\\n20. else\\n21. return class = “reptile”\\n22. end if\\n23. end if\\n24.end if\\n8.3.3 Some remarks\\n1. On the elements of a classiﬁcation tree\\nThe various elements in a classiﬁcation tree are identiﬁed as follows.\\n• Nodes in the classiﬁcation tree are identiﬁed by the feature names of the given data.\\n• Branches in the tree are identiﬁed by the values of features.\\n• The leaf nodes identiﬁed by are the class labels.CHAPTER 8. DECISION TREES 89\\n2. On the order in which the features are selected\\nIn the example discussed above, initially we chose the feature “gives birth” to split the data set\\ninto disjoint subsets and then the feature “aquatic animal”, and so on. There was no theoretical\\njustiﬁcation for this choice. We could as well have chosen the feature “aquatic animal”, or any other\\nfeature, as the initial feature for splitting the data. The classiﬁcation tree depends on the order in\\nwhich the features are selected for partitioning the data.\\n3. Stopping criteria\\nA real-world data will contain much more example record than the example we considered earlier.\\nIn general, there will be a large number of features each feature having several possible values. Thus,\\nthe corresponding classiﬁcation trees will naturally be more complex. In such cases, it may not be\\nadvisable to construct all branches and leaf nodes of the tree. The following are some of commonly\\nused criteria for stopping the construction of further nodes and branches.\\n• All (or nearly all) of the examples at the node have the same class.\\n• There are no remaining features to distinguish among the examples.\\n• The tree has grown to a predeﬁned size limit.\\n8.4 Feature selection measures\\nIf a dataset consists of nattributes then deciding which attribute is to be to placed at the root or at\\ndifferent levels of the tree as internal nodes is a complicated problem. It is not enough that we just\\nrandomly select any node to be the root. If we do this, it may give us bad results with low accuracy.\\nThe most important problem in implementing the decision tree algorithm is deciding which\\nfeatures are to be considered as the root node and at each level. Several methods have been developed\\nto assign numerical values to the various features such that the values reﬂect the relative importance\\nof the various features. These are called the feature selection measures . Two of the popular feature\\nselection measures are information gain andGini index . These are explained in the next section.\\n8.5 Entropy\\nThe degree to which a subset of examples contains only a single class is known as purity , and any\\nsubset composed of only a single class is called a pure class. Informally, entropy3is a measure of\\n“impurity” in a dataset. Sets with high entropy are very diverse and provide little information about\\nother items that may also belong in the set, as there is no apparent commonality.\\nEntropy is measured in bits. If there are only two possible classes, entropy values can range from\\n0 to 1. Fornclasses, entropy ranges from 0tolog2(n). In each case, the minimum value indicates\\nthat the sample is completely homogeneous, while the maximum value indicates that the data are as\\ndiverse as possible, and no group has even a small plurality.\\n8.5.1 Deﬁnition\\nConsider a segment Sof a dataset having cnumber of class labels. Let pibe the proportion of\\nexamples in Shaving theith class label. The entropy of Sis deﬁned as\\nEntropy (S)=c\\n/summation.disp\\ni=1−pilog2(pi):\\n3From German Entropie “measure of the disorder of a system,” coined in 1865 (on analogy of Energie) by German\\nphysicist Rudolph Clausius (1822-1888), in his work on the laws of thermodynamics, from Greek entropia “a turning toward,”\\nfrom en “in” + trope “a turning, a transformation,”CHAPTER 8. DECISION TREES 90\\nFigure 8.6: Plot of pvs. Entropy\\nRemark\\nIn the expression for entropy, the value of 0×log2(0)is taken as zero.\\nSpecial case\\nLet the data segment Shas only two class labels, say, “yes” and “no”. If pis the proportion of\\nexamples having the label “yes” then the proportion of examples having label “no” will be 1−p. In\\nthis case, the entropy of Sis given by\\nEntropy (S)=−plog2(p)−(1−p)log2(1−p):\\nIf we plot the values of graph of Entropy (S)for all possible values of p, we get the diagram shown\\nin Figure 8.64.\\n8.5.2 Examples\\nLet “xxx” be some class label. We denote by pxxxthe proportion of examples with class label “xxx”.\\n1.Entropy of data in Table 8.1\\nLetSbe the data in Table 8.1. The class labels are ”amphi”, “bird”, ”ﬁsh”, ”mammal” and\\n”reptile”. In Swe have the following numbers.\\nNumber of examples with class label “amphi” = 3\\nNumber of examples with class label “bird” = 2\\nNumber of examples with class label “ﬁsh” = 2\\nNumber of examples with class label “mammal” = 2\\nNumber of examples with class label “reptile” = 1\\nTotal number of examples = 10\\nTherefore, we have:\\nEntropy (S)=/summation.disp\\nfor all classes “xxx”−pxxxlog2(pxxx)\\n4Plot created using R language.CHAPTER 8. DECISION TREES 91\\n=−pamphilog2(pamphi)−pbirdlog2(pbird)\\n−pﬁshlog2(pﬁsh)−pmammal log2(pmammal)\\n−preptilelog2(preptile)\\n=−(3/slash.left10)log2(3/slash.left10)−(2/slash.left10)log2(2/slash.left10)\\n−(2/slash.left10)log2(2/slash.left10)−(2/slash.left10)log2(2/slash.left10)\\n−(1/slash.left10)log2(1/slash.left10)\\n=2:2464\\n2.Entropy of data in Table 8.2\\nConsider the segment Sof the data in Table 8.1 given in Table 8.2. For quick reference, the\\ntable has been reproduced below:\\nName Gives\\nbirthAquatic\\nanimalAerial\\nanimalHas legs Class la-\\nbel\\nhuman yes no no yes mammal\\nbat yes no yes yes bird\\ncat yes no no yes mammal\\nshark yes yes no no ﬁsh\\nThree class labels appear in this segment, namely, “bird”, “ﬁsh” and “mammal”. We have:\\nNumber of examples with class label “bird” 1\\nNumber of examples with class label “ﬁsh” 1\\nNumber of examples with class label “mammal” 2\\nTotal number of examples 4\\nTherefore we have\\nEntropy (S)=/summation.disp\\nfor all classes “xxx”−pxxxlog2(pxxx)\\n=−pbirdlog2(pbird)−pﬁshlog2(pﬁsh)\\n−pmammal log2(pmammal)\\n=−(1/slash.left4)log2(1/slash.left4)−(1/slash.left4)log2(1/slash.left4)−(2/slash.left4)log2(2/slash.left4)\\n=−(1/slash.left4)×(−2)−(1/slash.left4)×(−2)−(2/slash.left4)×(−1)\\n=1:5 (8.1)\\n3.Entropy of data in Table 8.3\\nConsider the segment Sof the data in Table 8.1 given in Table 8.3. For quick reference, the\\ntable has been reproduced below:\\nName gives birth aquatic\\nanimalaerial\\nanimalhas legs Class la-\\nbel\\npython no no no no reptile\\nsalmon no yes no no ﬁsh\\nfrog no semi no yes amphibian\\npigeon no no yes yes bird\\nturtle no semi no yes amphibian\\nsalamander no semi no yes amphibian\\nFour class labels appear in this segment, namely, “amphi”, “bird”, “ﬁsh” and “reptile”. We\\nhave:CHAPTER 8. DECISION TREES 92\\nNumber of examples with class label “amphi” 3\\nNumber of examples with class label “bird” 1\\nNumber of examples with class label “ﬁsh” 1\\nNumber of examples with class label “reptile” 1\\nTotal number of examples 6\\nTherefore, we have:\\nEntropy (S)=/summation.disp\\nfor all classes “xxx”−pxxxlog2(pxxx)\\n=−pamphilog2(pamphi)−pbirdlog2(pbird)−pﬁshlog2(pﬁsh)\\n−preptilelog2(preptile)\\n=−(3/slash.left6)log2(3/slash.left6)−(1/slash.left6)log2(1/slash.left6)−(1/slash.left6)log2(1/slash.left6)\\n−(1/slash.left6)log2(1/slash.left6)\\n=1:7925 (8.2)\\n8.6 Information gain\\n8.6.1 Deﬁnition\\nLetSbe a set of examples, Abe a feature (or, an attribute), Svbe the subset of SwithA=v,\\nand Values (A)be the set of all possible values of A. Then the information gain of an attribute A\\nrelative to the set S, denoted by Gain (S;A), is deﬁned as\\nGain(S;A)=Entropy (S)−/summation.disp\\nv∈Values(A)/divides.alt0Sv/divides.alt0\\n/divides.alt0S/divides.alt0×Entropy (Sv):\\nwhere/divides.alt0S/divides.alt0denotes the number of elements in S.\\n8.6.2 Example 1\\nConsider the data Sgiven in Table 8.1. We have have already seen that\\n/divides.alt0S/divides.alt0=10\\nEntropy (S)=2:2464:\\nWe denote the information gain corresponding to the feature “xxx” by Gain (S;xxx).\\n1.Computation of Gain (S;gives birth )\\nA1=gives birth\\nValues ofA1={“yes”;“no”}\\nSA1=yes=Data in Table 8.2\\n/divides.alt0SA1=yes/divides.alt0=4\\nEntropy (SA1=yes)=1:5(See Eq.(8.1))\\nSA1=no=Data in Table 8.3\\n/divides.alt0SA1=no/divides.alt0=6\\nEntropy (SA1=no)=1:7925 (See Eq.(8.2))\\nNow we have\\nGain(S;A 1)=Entropy (S)−/summation.disp\\nv∈Values(A1)/divides.alt0Sv/divides.alt0\\n/divides.alt0S/divides.alt0×Entropy (Sv)CHAPTER 8. DECISION TREES 93\\n=Entropy (S)−/divides.alt0SA1=yes/divides.alt0\\n/divides.alt0S/divides.alt0×Entropy (SA1=yes)\\n−/divides.alt0SA1=no/divides.alt0\\n/divides.alt0S/divides.alt0×Entropy (SA1=no)\\n=2:2464−(4/slash.left10)×1:5−(6/slash.left10)×1:7925\\n=0:5709\\n2.Computation of Gain (S;aquatic)\\nA2=aquatic\\nValues ofA2={“yes”;“no”;“semi”}\\nSA2=yes=See Table 8.1\\n/divides.alt0SA2=yes/divides.alt0=2\\nEntropy (SA2=yes)=−pﬁshlog2(pﬁsh)\\n=−(2/slash.left2)log2(2/slash.left2)\\n=0\\nSA2=no=See Table 8.1\\n/divides.alt0SA2=no/divides.alt0=5\\nEntropy (SA2=no)=−pmammal log2(pmammal)−preptilelog2(preptile)\\n−pbirdlog2(pbird)\\n=−(2/slash.left5)×log2(2/slash.left5)−(1/slash.left5)×log2(1/slash.left5)\\n−(2/slash.left5)×log2(2/slash.left5)\\n=1:5219\\nSA2=semi=See Table 8.1\\n/divides.alt0SA2=semi/divides.alt0=3\\nEntropy (SA2=semi)=−pamphilog2(pamphi)\\n=−(3/slash.left3)×log2(3/slash.left3)\\n=0\\nGain(S;A 2)=Entropy (S)−/summation.disp\\nv∈Values(A2)/divides.alt0Sv/divides.alt0\\n/divides.alt0S/divides.alt0×Entropy (Sv)\\n=Entropy (S)−/divides.alt0SA1=yes/divides.alt0\\n/divides.alt0S/divides.alt0×Entropy (SA1=yes)\\n−/divides.alt0SA1=no/divides.alt0\\n/divides.alt0S/divides.alt0×Entropy (SA1=no)\\n−/divides.alt0SA1=semi/divides.alt0\\n/divides.alt0S/divides.alt0×Entropy (SA1=semi)\\n=2:2464−(2/slash.left10)×0−(5/slash.left10)×1:5219−(3/slash.left3)×0\\n=1:48545\\n3.Computations of Gain (S;aerial animal )and Gain (S;has legs )\\nThese are left as exercises.\\n8.7 Gini indices\\nThe Gini split index of a data set is another feature selection measure in the construction of classiﬁ-\\ncation trees. This measure is used in the CART algorithm.CHAPTER 8. DECISION TREES 94\\n8.7.1 Gini index\\nConsider a data set Shavingrclass labelsc1;:::;cr. Letpibe the proportion of examples having\\nthe class label ci. The Gini index of the data set S, denoted by Gini (S), is deﬁned by\\nGini(S)=1−r\\n/summation.disp\\ni=1p2\\ni:\\nExample\\nLetSbe the data in Table 8.1. There are four class labels ”amphi”, “bird”, ”ﬁsh”, ”mammal” and\\n”reptile”. The numbers of examples having these class labels are as follows:\\nNumber of examples with class label “amphi” = 3\\nNumber of examples with class label “bird” = 2\\nNumber of examples with class label “ﬁsh” = 2\\nNumber of examples with class label “mammal” = 2\\nNumber of examples with class label “reptile” = 1\\nTotal number of examples = 10\\nThe Gini index of Sis given by\\nGini(S)=1−r\\n/summation.disp\\ni=1p2\\ni\\n=1−(3/slash.left10)2−(2/slash.left10)2−(2/slash.left10)2−(2/slash.left10)2−(1/slash.left10)2\\n=0:78\\n8.7.2 Gini split index\\nLetSbe a set of examples, Abe a feature (or, an attribute), Svbe the subset of SwithA=v,\\nand Values (A)be the set of all possible values of A. Then the Gini split index of Arelative toS,\\ndenoted by Gini split(S;A), is deﬁned as\\nGini split(S;A)=/summation.disp\\nv∈Values(A)/divides.alt0Sv/divides.alt0\\n/divides.alt0S/divides.alt0×Gini(Sv):\\nwhere/divides.alt0S/divides.alt0denotes the number of elements in S.\\n8.8 Gain ratio\\nThegain ratio is a third feature selection measure in the construction of classiﬁcation trees.\\nLetSbe a set of examples, Aa feature having cdifferent values and let the set of values of Abe\\ndenoted by Values (A). We deﬁned the information gain of Arelative toS, denoted by Gain (S;A),\\nby\\nGain(S;A)=Entropy (S)−/summation.disp\\nv∈Values(A)/divides.alt0Sv/divides.alt0\\n/divides.alt0S/divides.alt0×Entropy (Sv):\\nWe now deﬁne the split information ofArelative toS, dented by SplitInformation (S;A), by\\nSplitInformation (S;A)=−c\\n/summation.disp\\ni=1/divides.alt0Si/divides.alt0\\n/divides.alt0S/divides.alt0log2/divides.alt0Si/divides.alt0\\n/divides.alt0S/divides.alt0\\nwhereS1;:::Scare thecsubsets of examples resulting from partitioning Sinto thecvalues of the\\nattributeA. The gain ratio ofArelative toS, denoted by GainRatio (S;A), by\\nGainRatio (S;A)=Gain(S,A)\\nSplitInformation (S;A):CHAPTER 8. DECISION TREES 95\\n8.8.1 Example\\nConsider the data Sgiven in Table 8.1. Let Adenote the attribute “gives birth”.We have have already\\nseen that\\n/divides.alt0S/divides.alt0=10\\nEntropy (S)=2:2464\\nGain(S;A)=0:5709\\nNow we have\\nSplitInformation (S;A)=−/divides.alt0Syes/divides.alt0\\n/divides.alt0S/divides.alt0log2/divides.alt0Syes/divides.alt0\\n/divides.alt0S/divides.alt0−/divides.alt0Sno/divides.alt0\\n/divides.alt0S/divides.alt0log2/divides.alt0Sno/divides.alt0\\n/divides.alt0S/divides.alt0\\n=−4\\n10×log24\\n10−6\\n10×log26\\n10\\n=0:9710\\nGainRatio =0:5709\\n0:9710\\n=0:5880\\nIn a similar way we can compute the gain ratios Gain (S;“aquatic” ), Gain(S;“aerial”)and Gain (S;“has legs” ).\\n8.9 Decision tree algorithms\\n8.9.1 Outline\\nDecision tree algorithm: Outline\\n1. Place the “best” feature (or, attribute) of the dataset at the root of the tree.\\n2. Split the training set into subsets. Subsets should be made in such a way that each subset\\ncontains data with the same value for a feature.\\n3. Repeat Step 1 and Step 2 on each subset until we ﬁnd leaf nodes in all the branches of the tree.\\n8.9.2 Some well-known decision tree algorithms\\n1. ID3 (Iterative Dichotomiser 3) developed by Ross Quinlan\\n2. C4.5 developed by Ross Quinlan\\n3. C5.0 developed by Ross Quinlan\\n4. CART (Classiﬁcation And Regression Trees)\\n5. 1R (One Rule) developed by Robert Holte in 1993.\\n6. RIPPER (Repeated Incremental Pruning to Produce Error Reduction) Introduced in 1995 by\\nWilliam W. Cohen.\\nAs an example of decision tree algorithms, we discuss the details of the ID3 algorithm and illustrate\\nit with an example.CHAPTER 8. DECISION TREES 96\\n8.10 The ID3 algorithm\\nRoss Quinlan, while working at University of Sydney, developed the ID3 (Iterative Dichotomiser\\n3)5algorithm and published it in 1975.\\nAssumptions\\n• The algorithm uses information gain to select the most useful attribute for classiﬁcation.\\n• We assume that there are only two class labels, namely, “ +” and “−”. The examples with class\\nlabels “+” are called positive examples and others negative examples.\\n8.10.1 The algorithm\\nNotations\\nThe following notations are used in the algorithm:\\nS The set of examples\\nC The set of class labels\\nF The set of features\\nA An arbitrary feature (attribute)\\nValues(A) The set of values of the feature A\\nv An arbitrary value of A\\nSv The set of examples with A=v\\nRoot The root node of a tree\\nAlgorithm ID3( S,F,C)\\n1.Create a root node for the tree.\\n2.if(all examples in Sare positive) then\\n3. return single node tree Root with label “+”\\n4.end if\\n5.if(all examples are negative) then\\n6. return single node tree Root with label “–”\\n7.end if\\n8.if(number of features is 0) then\\n9. return single node tree Root with label equal to the most common class label.\\n10.else\\n11. LetAbe the feature in Fwith the highest information gain.\\n12. AssignAto the Root node in decision tree.\\n13. for all (valuesvofA)do\\n14. Add a new tree branch below Root corresponding to v.\\n15. if(Svis empty) then\\n16. Below this branch add a leaf node with label equal to the most common class\\nlabel in the set S.\\n17. else\\n18. Below this branch add the subtree formed by applying the same algorithm ID3\\nwith the values ID3 (Sv;C;F−{A}).\\n19. end if\\n20. end for\\n21.end if\\n5dichotomy : A division into two parts or classiﬁcations especially when they are sharply distinguished or opposedCHAPTER 8. DECISION TREES 97\\n8.10.2 Example\\nProblem\\nUse ID3 algorithm to construct a decision tree for the data in Table 8.9.\\nDay outlook temperature humidity wind playtennis\\nD1 sunny hot high weak no\\nD2 sunny hot high strong no\\nD3 overcast hot high weak yes\\nD4 rain mild high weak yes\\nD5 rain cool normal weak yes\\nD6 rain cool normal strong no\\nD7 overcast cool normal strong yes\\nD8 sunny mild high weak no\\nD9 sunny cool normal weak yes\\nD10 rain mild normal weak yes\\nD11 sunny mild normal strong yes\\nD12 overcast mild high strong yes\\nD13 overcast hot normal weak yes\\nD14 rain mild high strong no\\nTable 8.9: Training examples for the target concept “PlayTennis”\\nSolution\\nNote that, in the given data, there are four features but only two class labels (or, target variables),\\nnamely, “yes” and “no”.\\nStep 1\\nWe ﬁrst create a root node for the tree (see Figure 8.7).\\nRoot node\\nTable 8.9\\nFigure 8.7: Root node of the decision tree for data in Table 8.9\\nStep 2\\nNote that not all examples are positive (class label “yes”) and not all examples are negative (class\\nlabel “no”). Also the number of features is not zero.\\nStep 3\\nWe have to decide which feature is to be placed at the root node. For this, we have to calculate the\\ninformation gains corresponding to each of the four features. The computations are shown below.\\n(i) Calculation of Entropy (S)\\nEntropy (S)=−pyeslog2(pyes)−pnolog2(pno)\\n=−(9/slash.left14)×log2/parenleft.alt19/slash.left14/parenright.alt1−(5/slash.left14)×log2/parenleft.alt15/slash.left14/parenright.alt1\\n=0:9405CHAPTER 8. DECISION TREES 98\\n(ii) Calculation of Gain (S;outlook)\\nThe values of the attribute “outlook” are “sunny”, “ overcast” and “rain”. We have to calculate\\nEntropy (Sv)forv=sunny,v=overcast and v=rain.\\nEntropy (Ssunny)=−(3/slash.left5)×log2/parenleft.alt13/slash.left5/parenright.alt1−(2/slash.left5)×log2/parenleft.alt12/slash.left5/parenright.alt1\\n=0:9710\\nEntropy (Sovercast)=−(4/slash.left4)×log2/parenleft.alt14/slash.left4/parenright.alt1\\n=0\\nEntropy (Srain)=−(3/slash.left5)×log2/parenleft.alt13/slash.left5/parenright.alt1−(2/slash.left5)×log2/parenleft.alt12/slash.left5/parenright.alt1\\n=0:9710\\nGain(S;outlook)=Entropy (S)−/divides.alt0Ssunny/divides.alt0\\n/divides.alt0S/divides.alt0×Entropy (Ssunny)\\n−/divides.alt0Sovercast/divides.alt0\\n/divides.alt0S/divides.alt0×Entropy (Sovercast)\\n−/divides.alt0Srain/divides.alt0\\n/divides.alt0S/divides.alt0×Entropy (Srain)\\n=0:9405−(5/slash.left14)×0:9710−(4/slash.left14)×0\\n−(5/slash.left14)×0:9710\\n=0:2469\\n(iii) Calculation of Gain (S;temperature )\\nThe values of the attribute “temperature” are “hot”, “mild” and “cool”. We have to calculate\\nEntropy (Sv)forv=hot,v=mild andv=cool.\\nEntropy (Shot)=−(2/slash.left4)×log2/parenleft.alt12/slash.left4/parenright.alt1−(2/slash.left4)×log2/parenleft.alt12/slash.left4/parenright.alt1\\n=1:0000\\nEntropy (Smild)=−(4/slash.left6)×log2/parenleft.alt14/slash.left6/parenright.alt1−(2/slash.left6)×log2/parenleft.alt12/slash.left6/parenright.alt1\\n=0:9186\\nEntropy (Scool)=−(3/slash.left4)×log2/parenleft.alt13/slash.left4/parenright.alt1−(1/slash.left4)×log2/parenleft.alt11/slash.left4/parenright.alt1\\n=0:8113\\nGain(S;temperature )=Entropy (S)−/divides.alt0Shot/divides.alt0\\n/divides.alt0S/divides.alt0×Entropy (Shot)\\n−/divides.alt0Smild/divides.alt0\\n/divides.alt0S/divides.alt0×Entropy (Smild)\\n−/divides.alt0Scool/divides.alt0\\n/divides.alt0S/divides.alt0×Entropy (Scool)\\n=0:9405−(4/slash.left14)×1:0000−(6/slash.left14)×0:9186\\n−(4/slash.left14)×0:8113\\n=0:0293\\n(iv) Calculation of Gain (S;humidity )and Gain (S;wind)\\nThe following information gains can be calculated in a similar way:\\nGain(S;humidity )=0:151\\nGain(S;wind)=0:048CHAPTER 8. DECISION TREES 99\\nStep 4\\nWe ﬁnd the highest information gain whic is the maximum among Gain (S;outlook), Gain(S;temperature ),\\nGain(S;humidity )and Gain (S;wind). Therefore, we have:\\nhighest information gain =max{0:2469;0:0293;0:151;0:048}\\n=0:2469\\nThis corresponds to the feature “outlook”. Therefore, we place “outlook” at the root node. We now\\nsplit the root node in Figure 8.7 into three branches according to the values of the feature “outlook”\\nas in Figure 8.8.\\nRoot node\\nTable 8.9\\noutlook?\\nNode 1sunny\\nNode 2overcast\\nNode 3rain\\nFigure 8.8: Decision tree for data in Table 8.9, after selecting the branching feature at root node\\nStep 5\\nLetS(1)=Soutlook=sunny. We have /divides.alt2S(1)/divides.alt2=5. The examples in S(1)are shown in Table 8.10.\\nDay outlook temperature humidity wind playtennis\\nD1 sunny hot high weak no\\nD2 sunny hot high strong no\\nD8 sunny mild high weak no\\nD9 sunny cool normal weak yes\\nD11 sunny mild normal strong yes\\nTable 8.10: Training examples with outlook = “sunny”\\nGain(S(1);temp)=Entropy (S(1))−/divides.alt2S(1)\\ntemp = hot/divides.alt2\\n/divides.alt1S(1)/divides.alt1×Entropy (S(1)\\ntemp = hot)\\n−/divides.alt2S(1)\\ntemp = mild/divides.alt2\\n/divides.alt1S(1)/divides.alt1×Entropy (S(1)\\ntemp = mild)\\n−/divides.alt2S(1)\\ntemp = cool/divides.alt2\\n/divides.alt1S(1)/divides.alt1×Entropy (S(1)\\ntemp = cool)\\n=/bracketleft.alt1−(2/slash.left5)log2(2/slash.left5)−(3/slash.left5)log2(3/slash.left5)/bracketright.alt\\n−(2/slash.left5)×/bracketleft.alt1−(2/slash.left2)log(2/slash.left2))/bracketright.alt\\n−(2/slash.left5)×/bracketleft.alt1−(1/slash.left2)log(1/slash.left2)−(1/slash.left2)log2(1/slash.left2)/bracketright.alt\\n−(1/slash.left5)×/bracketleft.alt1−(1/slash.left1)log(1/slash.left1)/bracketright.alt\\n=0:5709CHAPTER 8. DECISION TREES 100\\nGain(S(1);hum)=Entropy (S(1))−/divides.alt2S(1)\\nhum = high/divides.alt2\\n/divides.alt1S(1)/divides.alt1×Entropy (S(1)\\nhum = high)\\n−/divides.alt2S(1)\\nhum = normal/divides.alt2\\n/divides.alt1S(1)/divides.alt1×Entropy (S(1)\\nhum = normal)\\n=/bracketleft.alt1−(2/slash.left5)log2(2/slash.left5)−(3/slash.left5)log2(3/slash.left5)/bracketright.alt\\n−(3/slash.left5)×/bracketleft.alt1−(3/slash.left3)log(3/slash.left3))/bracketright.alt\\n−(2/slash.left5)×/bracketleft.alt1−(2/slash.left2)log(2/slash.left2)/bracketright.alt\\n=0:9709\\nGain(S(1);wind)=Entropy (S(1))−/divides.alt2S(1)\\nwind = weak/divides.alt2\\n/divides.alt1S(1)/divides.alt1×Entropy (S(1)\\nwind = weak)\\n−/divides.alt2S(1)\\nwind = strong/divides.alt2\\n/divides.alt1S(1)/divides.alt1×Entropy (S(1)\\nwind = strong)\\n=/bracketleft.alt1−(2/slash.left5)log2(2/slash.left5)−(3/slash.left5)log2(3/slash.left5)/bracketright.alt\\n−(3/slash.left5)×/bracketleft.alt1−(2/slash.left3)log(2/slash.left3)−(1/slash.left3)log2(1/slash.left3))/bracketright.alt\\n−(2/slash.left5)×/bracketleft.alt1−(1/slash.left2)log(1/slash.left2)−(1/slash.left2)log(1/slash.left2)/bracketright.alt\\n=0:0110\\nThe maximum of Gain (S(1);temp), Gain(S(1);hum)and Gain (S(1);wind)is Gain(S(1);hum).\\nHence we place “humidity” at Node 1 and split this node into two branches according to the values\\nof the feature “humidity” to get the tree in Figure 8.9.\\nRoot node\\nTable 8.9\\noutlook?\\nNode 1:\\nhumidity?\\nNode 4high\\nNode 5normalsunny\\nNode 2overcast\\nNode 3rain\\nFigure 8.9: Decision tree for data in Table 8.9, after selecting the branching feature at Node 1\\nStep 6\\nIt can be seen that all the examples in the the data set corresponding to Node 4 in Figure 8.9 have\\nthe same class label “no” and all the examples corresponding to Node 5 have the same class label\\n“yes”. So we represent Node 4 as a leaf node with value “no” and Node 5 as a leaf node with value\\n“yes”. Similarly, all the examples corresponding to Node 2 have the same class label “yes”. So\\nwe convert Node 2 as a leaf node with value “ yes. Finally, let S(2)=Soutlook = rain . The highest\\ninformation gain for this data set is Gain (S(2);humidity ). The branches resulting from splitting this\\nnode corresponding to the values “high” and “normal” of “humidity” lead to leaf nodes with class\\nlabels “no” and ”yes”. With these changes, we get the tree in Figure 8.10.CHAPTER 8. DECISION TREES 101\\nRoot node\\nTable 8.9\\noutlook?\\nNode 1:\\nhumidity?\\nnohigh\\nyesnormalsunny\\nyesovercast\\nNode 3:\\nhumidity?\\nnohigh\\nyesnormalrain\\nFigure 8.10: Decision tree for data in Table 8.9\\n8.11 Regression trees\\nAregression problem is the problem of determining a relation between one or more independent\\nvariables and an output variable which is a real continuous variable and then using the relation\\nto predict the values of the dependent variables. Regression problems are in general related to\\nprediction of numerical values of variables. Trees can also be used to make such predictions. A tree\\nused for making predictions of numerical variables is called a prediction tree or aregression tree .\\n8.11.1 Example\\nUsing the data in Table 8.11, construct a tree to predict the values of y.\\nx1 1 3 4 6 10 15 2 7 16 0\\nx2 12 23 21 10 27 23 35 12 27 17\\ny 10.1 15.3 11.5 13.9 17.8 23.1 12.7 43.0 17.6 14.9\\nTable 8.11: Data for regression tree\\nSolution\\nWe shall construct a raw decision tree (a tree constructed without using any standard algorithm) to\\npredict the value of ycorresponding to any untabulated values of x1andx2.\\nStep 1. We arbitrarily split the values of x1into two sets: One set deﬁned by x1<6and the other\\nset deﬁned by x1≥6. This splits the data into two parts. This yields the tree in Figure ??.\\nx1 1 3 4 2 0\\nx2 12 23 21 35 17\\ny 10.1 15.3 11.5 12.7 14.9\\nTable 8.12: Data for regression tree\\nStep 2. In Figure 8.12, consider the node speciﬁed by Table 8.12. We arbitrarily split the values\\nofx2into two sets: one speciﬁed by x2<21and one speciﬁed by x2≥21. Similarly, the\\nnode speciﬁed by Table 8.13, we split the values of x2into sets: one speciﬁed by x2<23CHAPTER 8. DECISION TREES 102\\nx1 6 10 15 7 16\\nx2 10 27 23 12 27\\ny 13.9 17.8 23.1 43.0 17.6\\nTable 8.13: Data for regression tree\\nTab 8.11\\nTab 8.12 Tab 8.13x1<6 x1≥6\\nFigure 8.11: Part of a regression tree for Table 8.11\\nand one speciﬁed by x2≥23. The split data are given in Table 8.14(a) - (d). This gives us\\nthe tree in Figure 8.12.\\nTab 8.11\\nTabe 8.12 Tab 8.13x1<6 x1≥6\\nTab 8.14(a) Tab 8.14(b)x2<21 x2≥21\\nTab 8.14(c) Tab 8.14(d)x2<23 x2≥23\\nFigure 8.12: Part of regression tree for Table 8.11\\nStep 3. We next make the nodes speciﬁed by Table 8.14(a), :::, Tab 8.14(d) into leaf nodes. In\\neach of these leaf nodes, we write the average of the values in the corresponding table (this\\nis a standard procedure). For, example, at Table 8.14(a), we write1\\n2(10:1+14:9)=12:5.\\nThen we get Figure 8.13.\\nx1 1 0\\nx2 12 17\\ny 10.1 14.9x1 3 4 2\\nx2 23 21 35\\ny 15.3 11.5 12.7\\n(a) (b)\\nx1 6 7\\nx2 10 12\\ny 13.9 43.0x1 10 15 16\\nx2 27 23 27\\ny 17.8 23.1 17.6\\n(c) (d)\\nTable 8.14: Data for regression treeCHAPTER 8. DECISION TREES 103\\nx1<6 x1≥6\\n12.5 13.17x2<21x2≥21\\n28.45 19.5x2<23x2≥23\\nFigure 8.13: A regression tree for Table 8.11\\nStep 4. Figure 8.13 is the ﬁnal raw regression tree for predicting the values of ybased on the data\\nin Table 8.11.\\n8.11.2 An algorithm for constructing regression trees\\nStarting with a learning sample, three elements are necessary to determine a regression tree:\\n1. A way to select a split at every intermediate node\\n2. A rule for determining when a node is terminal\\n3. A rule for assigning a value for the output variable to every terminal node\\nNotations\\nx1;x2;:::;xn: The input variables\\nN : Number of samples in the data set\\ny1;y2;:::;yN : The values of the output variables\\nT : A tree\\nc : A leaf of T\\nnc : Number of data elements in the leaf c\\nC : The set of indices of data elements which\\nare in the leaf c\\nmc : The mean of the values of ywhich are in\\nthe leafc\\nST : Sum of squares of errors in T\\nWe have\\nmc=1\\nnc/summation.disp\\ni∈Cyi\\nST=/summation.disp\\nc∈leaves(T)/summation.disp\\ni∈C(yi−mc)2\\nAlgorithm\\nStep 1. Start with a single node containing all data points. Calculate mcandST.\\nStep 1. If all the points in the node have the same value for all the independent variables, stop.\\nStep 1. Otherwise, search over all binary splits of all variables for the one which will reduce STas\\nmuch as possible.CHAPTER 8. DECISION TREES 104\\n(a) If the largest decrease in STwould be less than some threshold \\x0e, or one of the\\nresulting nodes would contain less than qpoints, stop and if cis a node where we\\nhave stopped, then assign the value mcto the node.\\n(b) Otherwise, take that split, creating two new nodes.\\nStep 1. In each new node, go back to Step 1.\\nRemarks\\n1. We have seen entropy and information deﬁned for discrete variables. We can deﬁne them for\\ncontinuous variables also. But in the case of regression trees, it is more common to use the\\nsum of squares. The above algorithm is based on sum of squares of errors.\\n2. The CART algorithm mentioned below searches every distinct value of every predictor vari-\\nable to ﬁnd the predictor variable and split value which will reduce STas much as possible.\\n3. In the above algorithm, we have given the simplest criteria for stopping growing of trees.\\nMore sophisticated criteria which produce much less error have been developed.\\n8.11.3 Example\\nConsider the data given in Table 8.11.\\n1. Computation of STfor the entire data set. Initially, there is only one node. So, we have:\\nmc=1\\nnc/summation.disp\\nc∈Cyi\\n=1\\n10(10:1+15:3+/uni22EF+ 14:9)\\n=17:99\\nST=/summation.disp\\nc∈leaves(T)/summation.disp\\ni∈C(yi−mc)2\\n=(10:1−17:99)2+(15:3−17:99)2+/uni22EF+(14:9−17:99)2\\n=817:669\\n2. As suggested in the remarks above, we have to search every distinct value of x1andx2to ﬁnd\\nthe predictor variable and split value which will reduce STas much as possible.\\n3. Let us consider the value 6ofx1. This splits the data set into two parts c1andc2. Letc1be\\nthe part deﬁned by x1<6andc2the part deﬁned by x1≥6.S1is given in Table 8.12 and S2\\nby Table 8.13.Now\\nleaves(T)={c1;c2}:\\nLetT1be the tree corresponding to this partition. Then\\nST1=/summation.disp\\nc∈leaves(T1)/summation.disp\\ni∈C(yi−mc)2\\n=/summation.disp\\ni∈C1(yi−mc1)2+/summation.disp\\ni∈C2(yi−mc2)2\\nmc1=1\\nnc1/summation.disp\\ni∈C1yi\\n=1\\n5(10:1+15:3+11:5+12:7+14:9)\\n=12:9CHAPTER 8. DECISION TREES 105\\nmc2=1\\nnc2/summation.disp\\ni∈C2yi\\n=1\\n5(13:9+17:8+23:1+43:0+17:6)\\n=23:08\\nST1=[(10:1−12:9)2+/uni22EF+(14:9−12:9)2]+\\n[(13:9−23:08)2+/uni22EF+(17:6−23:08)2]\\n=558:588\\nThe reduction in sum of squares of errors is\\nST−ST1=817:669−558:588=259:081:\\n4. In this way, we have compute the reduction in the sum of squares of errors corresponding to\\nall other values of x1and each of the values of x2and choose the one for which the reduction\\nis maximum.\\n5. The process has be continued. (Software package may be required to complete the problem.)\\n8.12 CART algorithm\\nWe have seen how decision trees can be used to create a model that predicts the value of a target (or\\ndependent variable) based on the values of several input or independent variables.\\nThe CART, or Classiﬁcation And Regression Trees methodology, was introduced in 1984 by Leo\\nBreiman, Jerome Friedman, Richard Olshen and Charles Stone as an umbrella term to refer to the\\nfollowing types of decision trees:\\n•Classiﬁcation trees where the target variable is categorical and the tree is used to identify the\\n“class” within which a target variable would likely fall into.\\n•Regression trees where the target variable is continuous and tree is used to predict it’s value.\\nThe main elements of CART are:\\n• Rules for splitting data at a node based on the value of one variable\\n• Stopping rules for deciding when a branch is terminal and can be split no more\\n• A prediction for the target variable in each terminal node\\n8.13 Other decision tree algorithms\\n8.13.1 The C4.5 algorithm\\nThe C4.5 algorithm is an algorithm developed by Ross Quinlan as an improvement of the ID3\\nalgorithm. The following are some of the improvements incorporated in C4.5.\\n• Handling both continuous and discrete attributes\\n• Handling training data with missing attribute values\\n• Handling attributes with differing costs\\n• Pruning trees after creationCHAPTER 8. DECISION TREES 106\\n8.13.2 The C5.0 algorithm\\nThe C5.0 algorithm represents a further improvement on the C4.5 algorithm. This was also devel-\\noped by Ross Quinlan.\\n• Speed - C5.0 is signiﬁcantly faster than C4.5.\\n• Memory usage - C5.0 is more memory efﬁcient than C4.5.\\n• C5.0 gets similar results to C4.5 with considerably smaller decision trees.\\nThe C5.0 algorithm is one of the most well-known implementations of the the decision tree\\nalgorithm. The source code for a single-threaded version of the algorithm is publicly available,\\nand it has been incorporated into programs such as R. The C5.0 algorithm has become the industry\\nstandard to produce decision trees.\\n8.14 Issues in decision tree learning\\nIn thie next feww sections, we discuss some of the practical issues in learning decision trees.\\n8.15 Avoiding overﬁtting of data\\nWhen we construct a decision tree, the various branches are grown (that is, sub-branches are con-\\nstructed) just deeply enough to perfectly classify the training examples. This leads to difﬁculties\\nwhen there is noise in the data or when the number of training examples are too small. In these\\ncases the algorithm can produce trees that overﬁt the training examples.\\nDeﬁnition\\nWe say that a hypothesis overﬁts the training examples if some other hypothesis that ﬁts the train-\\ning examples less well actually performs better over the entire distribution of instances, including\\ninstances beyond the training set.\\nImpact of overﬁtting\\nFigure 8.14 illustrates the impact of overﬁtting in a typical decision tree learning. From the ﬁgure,\\nwe can see that the accuracy of the tree over training examples increases monotonically whereas the\\naccuracy measured over independent test samples ﬁrst increases then decreases.\\n8.15.1 Approaches to avoiding overﬁtting\\nThe main approach to avoid overﬁtting is pruning . Pruning is a technique that reduces the size\\nof decision trees by removing sections of the tree that provide little power to classify instances.\\nPruning reduces the complexity of the ﬁnal classiﬁer, and hence improves predictive accuracy by\\nthe reduction of overﬁtting.\\n• We may apply pruning earlier, that is, before it reaches the point where it perfectly classiﬁes\\nthe training data.\\n• We may allow the tree to overﬁt the data, and then post-prune the true.\\nNow there is the problem of what criterion is to be used to determine the correct ﬁnal tree\\nsize. One commonly used criterion is to use a separate set of examples, distinct from the training\\nexamples, to evaluate the utility of post-pruning nodes from the tree.CHAPTER 8. DECISION TREES 107\\nFigure 8.14: Impact of overﬁtting in decision tree learning\\nCase Temperature Headache Nausea Decision (Flue)\\n1 high ? no yes\\n2 very high yes no yes\\n3 ? no no no\\n4 high yes yes yes\\n5 high ? yes no\\n6 normal yes no no\\n7 normal no yes no\\n8 ? yes ? yes\\nTable 8.15: A dataset with missing attribute values\\n8.15.2 Reduced error pruning\\nInreduced-error pruning , we consider each of the decision tress to be a candidate for pruning. Prun-\\ning a decision node consists of removing the subtree rooted at that node, making it a leaf node, and\\nassigning it the most common classiﬁcation of the training examples afﬁliated to that node. Nodes\\nare removed only if the resulting pruned tree performs no worse than the original over validation set.\\nNodes are pruned iteratively, always choosing the node whose removal most increases the accuracy\\nover the validation set. Pruning of nodes is continued until further pruning decreases the accuracy\\nover the validation set.\\n8.16 Problem of missing attributes\\nTable 8.15 shows a dataset with missing attribute values. the missing values are indicated by “?”s.\\nThe following are some of the methods used to handle the problem of missing attributes.\\n• Deleting cases with missing attribute values\\n• Replacing a missing attribute value by the most common value of that attributeCHAPTER 8. DECISION TREES 108\\n• Assigning all possible values to the missing attribute value\\n• Replacing a missing attribute value by the mean for numerical attributes\\n• Assigning to a missing attribute value the corresponding value taken from the closest tcases,\\nor replacing a missing attribute value by a new value\\n8.17 Sample questions\\n(a) Short answer questions\\n1. Explain the concept of a decision tree with an example.\\n2. What are the different types of decision trees?\\n3. Deﬁne the entropy of a dataset.\\n4. Write a formula to compute the entropy of a two-class dataset.\\n5. Deﬁne information gain and Gini index.\\n6. Give the names of ﬁve different decision-tree algorithms.\\n7. Can decision tree be used for regression? If yes, explain how. If no, explain why.\\n8. What is the difference between classiﬁcation and regression trees?\\n(b) Long answer questions\\n1. Explain classiﬁcation tree using an example.\\n2. Consider the following set of training examples:\\nInstance Classiﬁcation a1a2\\n1 + T T\\n2 + T T\\n3 − T F\\n4 + F F\\n5 − F T\\n6 − F T\\n(a) What is the entropy of this collection of training examples with respect to the target\\nfunction “classiﬁcation”?\\n(b) What is the information gain of a2relative to these training examples?\\n3. Explain the ID3 algorithm for learning decision trees.\\n4. Explain CART algorithm.\\n5. What are issues in decision tree learning? How are they overcome?\\n6. Describe an algorithm to construct regression trees.\\n7. What do you mean by information gain and entropy? How is it used to build the decision\\ntrees? Illustrate using an example.\\n8. Use ID3 algorithm to construct a decision tree for the data in the following table.CHAPTER 8. DECISION TREES 109\\nInstance no. Class label x1x2\\n1 1 T T\\n2 1 T T\\n3 0 T F\\n4 1 F F\\n5 0 F T\\n6 0 F T\\n9. Use ID3 algorithm to construct a decision tree for the data in the following table.\\nGender Car ownership Travel cost Income level Class\\n(mode of transportation)\\nMale 0 Cheap Low Bus\\nMale 1 Cheap Medium Bus\\nFemale 1 Cheap Medium Train\\nFemale 0 Cheap Low Bus\\nMale 1 Cheap Medium Bus\\nMale 0 Standard Medium Train\\nFemale 1 Standard Medium Train\\nFemale 1 Expensive High Car\\nMale 2 Expensive Medium Car\\nFemale 2 Expensive High Car\\n10. Use ID3 algorithm to construct a decision tree for the data in the following table.\\nAge Competition Type Class (proﬁt)\\nOld Yes Software Down\\nOld No Software Down\\nOld No Hardware Down\\nMid Yes Software Down\\nMid Yes Hardware Down\\nMid No Hardware Up\\nMid No Software Up\\nNew Yes Software Up\\nNew No Hardware Up\\nNew No Software Up\\n11. Construct a decision tree for the following data.CHAPTER 8. DECISION TREES 110\\nClass label (risk) Collateral Income Debt Credit history\\nhigh none low high bad\\nhigh none middle high unknown\\nmoderate none middle low unknown\\nhigh none low low unknown\\nlow none upper low unknown\\nlow adequate upper low unknown\\nhigh none low low bad\\nmoderate adequate upper low bad\\nlow none upper low good\\nlow adequate upper high good\\nhigh none low high good\\nmoderate none middle high good\\nlow none upper high good\\nhigh none middle high badChapter 9\\nNeural networks\\n9.1 Introduction\\nAnArtiﬁcial Neural Network (ANN) models the relationship between a set of input signals and an\\noutput signal using a model derived from our understanding of how a biological brain responds to\\nstimuli from sensory inputs. Just as a brain uses a network of interconnected cells called neurons\\nto create a massive parallel processor, ANN uses a network of artiﬁcial neurons or nodes to solve\\nlearning problems.\\n9.2 Biological motivation\\nLet us examine how a biological neuron functions. Figure 9.2 gives a schematic representation of\\nthe functioning of a biological neuron.\\nIn the cell, the incoming signals are received by the cell’s dendrites through a biochemical pro-\\ncess. The process allows the impulse to be weighted according to its relative importance or fre-\\nquency. As the cell body begins accumulating the incoming signals, a threshold is reached at which\\nthe cell ﬁres and the output signal is transmitted via an electrochemical process down the axon . At\\nthe axon’s terminals, the electric signal is again processed as a chemical signal to be passed to the\\nneighboring neurons across a tiny gap known as a synapse .1\\nBiological learning systems are built of very complex webs of interconnected neurons. The hu-\\nman brain has an interconnected network of approximately 1011neurons, each connected, on an\\naverage, to 104other neurons. Even though the neuron switching speeds are much slower than than\\n1Neuron. (2018, February 15). In Wikipedia, The Free Encyclopedia. Retrieved 01:44, February 23, 2018.\\nFigure 9.1: Anatomy of a neuron\\n111CHAPTER 9. NEURAL NETWORKS 112\\nFigure 9.2: Flow of signals in a biological neuron\\ncomputer switching speeds, we are able to take complex decisions relatively quickly. Because of\\nthis, it is believed that the information processing capabilities of biological neural systems is a con-\\nsequence of the ability of such systems to carry out a huge number of parallel processes distributed\\nover many neurons. The developments in ANN systems are motivated by the desire to implement\\nthis kind of highly parallel computation using distributed representations.\\n9.3 Artiﬁcial neurons\\nDeﬁnition\\nAnartiﬁcial neuron is a mathematical function conceived as a model of biological neurons. Artiﬁcial\\nneurons are elementary units in an artiﬁcial neural network. The artiﬁcial neuron receives one or\\nmore inputs (representing excitatory postsynaptic potentials and inhibitory postsynaptic potentials\\nat neural dendrites) and sums them to produce an output. Each input is separately weighted, and the\\nsum is passed through a function known as an activation function ortransfer function .\\nSchematic representation of an artiﬁcial neuron\\nThe diagram shown in Figure ??gives a schematic representation of a model of an artiﬁcial neuron.\\nThe notations in the diagram have the following meanings:\\n∑ f\\n:::x0=1\\nx1 w0\\nw1\\nx2 w2\\nxnwnn\\n/summation.disp\\ni=0wixif/uni239B\\n/uni239Dn\\n/summation.disp\\ni=0wixi/uni239E\\n/uni23A0Output (y)\\ny=f/uni239B\\n/uni239Dn\\n/summation.disp\\ni=0wixi/uni239E\\n/uni23A0\\nFigure 9.3: Schematic representation of an artiﬁcial neuron\\nx1;x2;:::xn∶input signals\\nw1;w2;:::wn∶weights associated with input signalsCHAPTER 9. NEURAL NETWORKS 113\\nx0∶input signal taking the constant value 1\\nw0∶weight associated with x0(called bias)\\n/summation.disp∶indicates summation of input signals\\nf∶function which produces the output\\ny∶output signal\\nThe function fcan be expressed in the following form:\\ny=f/parenleft.alt3n\\n/summation.disp\\ni=0wixi/parenright.alt3 (9.1)\\nRemarks\\nThe small circles in the schematic representation of the artiﬁcial neuron shown in Figure 9.3 are\\ncalled the nodes of the neuron. The circles on the left side which receives the values of x0;x1;:::;xn\\nare called the input nodes and the circle on the right side which outputs the value of yis called\\noutput node . The squares represent the processes that are taking place before the result is outputted.\\nThey need not be explicitly shown in the schematic representation. Figure 9.4 shows a simpliﬁed\\nrepresentation of an artiﬁcial neuron.\\n:::x0=1\\nx1 w0\\nw1\\nx2 w2\\nxnwnOutput (y)\\ny=f/uni239B\\n/uni239Dn\\n/summation.disp\\ni=0wixi/uni239E\\n/uni23A0\\nFigure 9.4: Simpliﬁed representation of an artiﬁcial neuron\\n9.4 Activation function\\n9.4.1 Deﬁnition\\nIn an artiﬁcial neural network, the function which takes the incoming signals as input and produces\\nthe output signal is known as the activation function .\\nRemark\\nEq.(9.1) represents the activation function of the ANN model shown in Figure ??.\\n9.4.2 Some simple activation functions\\nThe following are some of the simple activation functions.CHAPTER 9. NEURAL NETWORKS 114\\n1. Threshold activation function\\nThethreshold activation function is deﬁned by\\nf(x)=/uni23A7/uni23AA/uni23AA/uni23A8/uni23AA/uni23AA/uni23A91ifx>0\\n−1ifx≤0\\nThe graph of this function is shown in Figure 9.5.\\nx1\\n−10\\nFigure 9.5: Threshold activation function\\n2. Unit step functions\\nSometimes, the threshold activation function is also deﬁned as a unit step function in which case it\\nis called a unit-step activation function . This is deﬁned as follows:\\nf(x)=/uni23A7/uni23AA/uni23AA/uni23A8/uni23AA/uni23AA/uni23A91ifx≥0\\n0ifx<0\\nThe graph of this function is shown in Figure 9.6.\\nx1\\n−10\\nFigure 9.6: Unit step activation function\\n3. Sigmoid activation function (logistic function)\\nOne of the must commonly used activation functions is the sigmoid activation function. It is deﬁned\\nas follows:\\nf(x)=1\\n1+e−x\\nThe graph of the function is shown in Figure 9.7.\\nxf(x)\\n1\\n0\\nFigure 9.7: The sigmoid activation functionCHAPTER 9. NEURAL NETWORKS 115\\n4. Linear activation function\\nThe linear activation function is deﬁned by\\nF(x)=mx+c:\\nThis deﬁnes a straight line in the xy-plane.\\nx1\\n−10\\nFigure 9.8: Linear activation function\\n5. Piecewise (or, saturated) linear activation function\\nThis is deﬁned by\\nf(x)=/uni23A7/uni23AA/uni23AA/uni23AA/uni23AA/uni23AA/uni23A8/uni23AA/uni23AA/uni23AA/uni23AA/uni23AA/uni23A90 ifx<xmin\\nmx+cifxmin≤x≤xmax\\n0 ifx>xmax\\nx1\\n−10\\nFigure 9.9: Piecewise linear activation function\\n6. Gaussian activation function\\nThis is deﬁned by\\nf(x)=1\\n\\x1b√\\n2\\x19e−(x−\\x16)2\\n2\\x1b2:\\nx1\\n−10\\nFigure 9.10: Gaussian activation functionCHAPTER 9. NEURAL NETWORKS 116\\n7. Hyperbolic tangential activation function\\nThis is deﬁned by\\nf(x)=ex−e−x\\nex+e−x:\\nx1\\n−10\\nFigure 9.11: Hyperbolic tangent activation function\\n9.5 Perceptron\\nThe perceptron is a special type of artiﬁcial neuron in which thee activation function has a special\\nform.\\n9.5.1 Deﬁnition\\nA perceptron is an artiﬁcial neuron in which the activation function is the threshold function.\\nConsider an artiﬁcial neuron having x1,x2,/uni22EF,xnas the input signals and w1,w2,/uni22EF,wnas the\\nassociated weights. Let w0be some constant. The neuron is called a perceptron if the output of the\\nneuron is given by the following function:\\no(x1;x2;:::;xn)=/uni23A7/uni23AA/uni23AA/uni23A8/uni23AA/uni23AA/uni23A91ifw0+w1x1+/uni22EF+wnxn>0\\n−1ifw0+w1x1+/uni22EF+wnxn≤0\\nFigure 9.12 shows the schematic representation of a perceptron.\\n∑  \\n:::x0=1\\nx1 w0\\nw1\\nx2 w2\\nxnwnn\\n/summation.disp\\ni=0wixiy=/uni23A7/uni23AA/uni23AA/uni23AA/uni23AA/uni23A8/uni23AA/uni23AA/uni23AA/uni23AA/uni23A91ifn\\n/summation.disp\\ni=0wixi>0\\n−1otherwiseOutput (y)\\nFigure 9.12: Schematic representation of a perceptrnCHAPTER 9. NEURAL NETWORKS 117\\nRemarks\\n1. The quantity −w0can be looked upon as a “threshold” that should be crossed by the weighted\\nsumw1x1+/uni22EF+wnxnin order for the neuron to output a “ 1”.\\n9.5.2 Representations of boolean functions by perceptrons\\nIn this section we examine whether simple boolean functions like x1ANDx2can be represented by\\nperceptrons. To be consistent with the conventions in the deﬁnition of a perceptron we assume that\\nthe values−1and1represent the boolean constants “false” and “true” respectively.\\n9.5.3 Representation of x1AND x2\\nLetx1andx2be two boolean variables. Then the boolean function x1ANDx2is represented by\\nTable 9.1. It can be easily veriﬁed that the perceptron shown in Figure 9.13 represents the function\\nx1x2x1ANDx2\\n−1−1−1\\n−1 1−1\\n1−1−1\\n1 1 1\\nTable 9.1: The boolean function x1ANDx2\\nx1ANDx2.\\n∑  x0=1\\nx1\\nx2w0=−0:8\\nw1=0:5\\nw3=0:53\\n/summation.disp\\ni=0wixiy=/uni23A7/uni23AA/uni23AA/uni23AA/uni23AA/uni23AA/uni23A8/uni23AA/uni23AA/uni23AA/uni23AA/uni23AA/uni23A91if3\\n/summation.disp\\ni=0wixi>0\\n−1otherwiseOutput (y)\\nFigure 9.13: Representation of x1ANDx2by a perceptron\\nIn the perceptron shown in Figure 9.13, the output is given by\\ny=/uni23A7/uni23AA/uni23AA/uni23AA/uni23AA/uni23AA/uni23A8/uni23AA/uni23AA/uni23AA/uni23AA/uni23AA/uni23A91if3\\n/summation.disp\\ni=0wixi>0\\n−1otherwise\\n=/uni23A7/uni23AA/uni23AA/uni23A8/uni23AA/uni23AA/uni23A91if−0:8+0:5x1+0:5x2>0\\n−1otherwise\\nRepresentations of OR, NAND and NOR\\nThe functions x1ORx2,x1NANDx2andx1NORx2can also be represented by perceptrons. Table\\n9.2 shows the values to be assigned to the weights w0;w1;w2for getting these boolean functions.CHAPTER 9. NEURAL NETWORKS 118\\nBoolean function w0w1w2\\nx1ANDx2−0:80:5 0:5\\nx1ORx2−0:30:5 0:5\\nx1NANDx2 0:8−0:5−0:5\\nx1NORx2 0:3−0:5−0:5\\nTable 9.2: Representations of boolean functions by perceptrons\\nRemarks\\nNot all boolean functions can be represented by perceptrons. For example, the boolean function\\nx1XORx2cannot be represented by a perceptron. This means that we cannot assign values to\\nw0;w1;w2such that the expression w0+w1x1+w2x2takes the values of x1XORx2, and that this\\nis the case can be easily veriﬁed also.\\n9.5.4 Learning a perceptron\\nBy “learning a perceptron” we mean the process of assigning values to the weights and the thresh-\\nold such that the perceptron produces correct output for each of the given training examples. The\\nfollowing are two algorithms to solve this learning problem:\\n9.5.5 Perceptron learning algorithm\\nDeﬁnitions\\nIn the algorithm, we use the following notations:\\nn : Number of input variables\\ny=f(z) : Output from the perceptron for an input\\nvector z\\nD={(x1;d1);:::;(xs;ds)} : Training set of ssamples\\nxj=(xj0;xj1;:::;xjn) : Then-dimensional input vector\\ndj : Desired output value of the perceptron for\\nthe input xj\\nxji : Value of the i-th feature of the j-th training\\ninput vector\\nxj0 :1\\nwi : Weight of the i-th input variable\\nwi(t) : Weightiat thet-th iteration\\nAlgorithm\\nStep 1. Initialize the weights and the threshold. Weights may be initialized to 0 or to a small\\nrandom value.\\nStep 2. For each example jin the training set D, perform the following steps over the input xj\\nand desired output dj:\\na) Calculate the actual output:\\nyj(t)=f[w0(t)xj0+w1(t)xj1+w2(t)xj2+/uni22EF+wn(t)xjn]CHAPTER 9. NEURAL NETWORKS 119\\nb) Update the weights:\\nwi(t+1)=wi(t)+(dj−yj(t))xji\\nfor all features 0≤i≤n.\\nStep 3. Step 2 is repeated until the iteration error1\\ns∑s\\nj=1/divides.alt0dj−yj(t)/divides.alt0is less than a user-speciﬁed\\nerror threshold \\r, or a predetermined number of iterations have been completed, where s\\nis again the size of the sample set.\\nRemarks\\nThe above algorithm can be applied only if the training examples are linearly separable .\\n9.6 Artiﬁcial neural networks\\nAnartiﬁcial neural network (ANN) is a computing system inspired by the biological neural networks\\nthat constitute animal brains. An ANN is based on a collection of connected units called artiﬁcial\\nneurons. Each connection between artiﬁcial neurons can transmit a signal from one to another. The\\nartiﬁcial neuron that receives the signal can process it and then signal artiﬁcial neurons connected to\\nit.\\neach connection between artiﬁcial neurons has a weight attached to it that get adjusted as learning\\nproceeds. Artiﬁcial neurons may have a threshold such that only if the aggregate signal crosses that\\nthreshold the signal is sent. Artiﬁcial neurons are organized in layers. Different layers may perform\\ndifferent kinds of transformations on their inputs. Signals travel from the input layer to the output\\nlayer, possibly after traversing the layers multiple times.\\n9.7 Characteristics of an ANN\\nAn ANN can be deﬁned and implemented in several different ways. The way the following charac-\\nteristics are deﬁned determines a particular variant of an ANN.\\n•The activation function\\nThis function deﬁnes how a neuron’s combined input signals are transformed into a single\\noutput signal to be broadcasted further in the network.\\n•The network topology (or architecture)\\nThis describes the number of neurons in the model as well as the number of layers and manner\\nin which they are connected.\\n•The training algorithm\\nThis algorithm speciﬁes how connection weights are set in order to inhibit or excite neurons\\nin proportion to the input signal.\\n9.7.1 Activation functions\\nThe activation function is the mechanism by which the artiﬁcial neuron processes incoming informa-\\ntion and passes it throughout the network. Just as the artiﬁcial neuron is modeled after the biological\\nversion, so is the activation function modeled after nature’s design.\\nLetx1,x2,:::,xnbe the input signals, w1,w2,:::,wnbe the associated weights and −w0the\\nthreshold. Let\\nx=w0+w1x1+/uni22EF+wnxn:\\nThe activation function is some function of x. Some of the simplest and commonly used activations\\nare given in Section 9.4.CHAPTER 9. NEURAL NETWORKS 120\\n9.7.2 Network topology\\nBy “network topology” we mean the patterns and structures in the collection of interconnected\\nnodes. The topology determines the complexity of tasks that can be learned by the network. Gener-\\nally, larger and more complex networks are capable of identifying more subtle patterns and complex\\ndecision boundaries. However, the power of a network is not only a function of the network size,\\nbut also the way units are arranged.\\nDifferent forms of forms of network architecture can be differentiated by the following charac-\\nteristics:\\n• The number of layers\\n• Whether information in the network is allowed to travel backward\\n• The number of nodes within each layer of the network\\n1. The number of layers\\nIn an ANN, the input nodes are those nodes which receive unprocessed signals directly from the\\ninput data. The output nodes (there may be more than one) are those nodes which generate the ﬁnal\\npredicted values. A hidden node is a node that processes the signals from the input nodes (or other\\nsuch nodes) prior to reaching the output nodes.\\nThe nodes are arranged in layers . The set of nodes which receive the unprocessed signals from\\nthe input data constitute the ﬁrst layer of nodes. The set of hidden nodes which receive the outputs\\nfrom the nodes in the ﬁrst layer of nodes constitute the second layer of nodes. In a similar way we\\ncan deﬁne the third, fourth, etc. layers. Figure 9.14 shows an ANN with only one layer of nodes.\\nFigure 9.15 shows an ANN with two layers.\\n:::x0\\nx1 w0\\nw1\\nx2 w2\\nxnwnOutput (y)Input layer Output layer\\nFigure 9.14: An ANN with only one layer\\n2. The direction of information travel\\nNetworks in which the input signal is fed continuously in one direction from connection to connec-\\ntion until it reaches the output layer are called feedforward networks . The network shown in Figure\\n9.15 is a feedforward network.\\nNetworks which allows signals to travel in both directions using loops are called recurrent net-\\nworks (or,feedback networks ).\\nIn spite of their potential, recurrent networks are still largely theoretical and are rarely used\\nin practice. On the other hand, feedforward networks have been extensively applied to real-world\\nproblems. In fact, the multilayer feedforward network, sometimes called the Multilayer Perceptron\\n(MLP), is the de facto standard ANN topology. If someone mentions that they are ﬁtting a neural\\nnetwork, they are most likely referring to a MLP.CHAPTER 9. NEURAL NETWORKS 121\\nInput\\nlayerHidden\\nlayerOutput\\nlayer\\nx0\\nx1\\nx2\\n/uni22EF\\nxnOutput\\nFigure 9.15: An ANN with two layers\\n3. The number of nodes in each layer\\nThe number of input nodes is predetermined by the number of features in the input data. Similarly,\\nthe number of output nodes is predetermined by the number of outcomes to be modeled or the\\nnumber of class levels in the outcome. However, the number of hidden nodes is left to the user to\\ndecide prior to training the model. Unfortunately, there is no reliable rule to determine the number\\nof neurons in the hidden layer. The appropriate number depends on the number of input nodes, the\\namount of training data, the amount of noisy data, and the complexity of the learning task, among\\nmany other factors.\\n9.7.3 The training algorithm\\nThere are two commonly used algorithms for learning a single perceptron, namely, the perceptron\\nrule and the delta rule. The former is used when the training data set is linearly separable and the\\nlatter when the training data set is not linearly separable.\\nThe algorithm which is now commonly used to train an ANN is known simply as backpropaga-\\ntion.\\n9.7.4 The cost function\\nDeﬁnition\\nIn a machine learning algorithm, the cost function is a function that measures how well the algorithm\\nmaps the target function that it is trying to guess or a function that determines how well the algorithm\\nperforms in an optimization problem.\\nRemaarks\\nThe cost function is also called the loss function , the objective function , the scoring function , or the\\nerror function .\\nExample\\nLetybe the the output variable. Let y1;:::;ynbe the actual values of yinnexamples and ^y1;:::; ^yn\\nbe the values predicted by an algorithm.CHAPTER 9. NEURAL NETWORKS 122\\nInput\\nlayerHidden\\nlayerOutput\\nlayer\\nx0\\nx1\\nx2\\n/uni22EF\\nxnOutput 1\\nOutput 2\\n(a) Network with one hidden layer and two output nodes\\nInput\\nlayerHidden\\nlayer 1Hidden\\nlayer 2Output\\nlayer\\nx0\\nx1\\nx2\\n/uni22EF\\nxnOutput\\n(b) Network with two hidden layers\\nFigure 9.16: Examples of different topologies of networks\\n1. The sum of squares of the differences between the predicted and actual values of y, denoted\\nby SSE and deﬁned below, can be taken as a cost function for the algorithm.\\nSSE=n\\n/summation.disp\\ni=1(yi−^yi)2:\\n2. The mean of the sum of squares of the differences between the predicted and actual values of\\ny, denoted by MSE and deﬁned below, can be taken as a cost function for the algorithm.\\nMSE=1\\nnn\\n/summation.disp\\ni=1(yi−^yi)2:\\n9.8 Backpropagation\\nThe backpropagation algorithm was discovered in 1985-86. Here is an outline of the algorithm.CHAPTER 9. NEURAL NETWORKS 123\\nFigure 9.17: A simpliﬁed model of the error surface showing the direction of gradient\\n9.8.1 Outline of the algorithm\\n1. Initially the weights are assigned at random.\\n2. Then the algorithm iterates through many cycles of two processes until a stopping criterion is\\nreached. Each cycle is known as an epoch . Each epoch includes:\\n(a) A forward phase in which the neurons are activated in sequence from the input layer to\\nthe output layer, applying each neuron’s weights and activation function along the way.\\nUpon reaching the ﬁnal layer, an output signal is produced.\\n(b) A backward phase in which the network’s output signal resulting from the forward phase\\nis compared to the true target value in the training data. The difference between the\\nnetwork’s output signal and the true value results in an error that is propagated backwards\\nin the network to modify the connection weights between neurons and reduce future\\nerrors.\\n3. The technique used to determine how much a weight should be changed is known as gradient\\ndescent method . At every stage of the computation, the error is a function of the weights. If\\nwe plot the error against the wights, we get a higher dimensional analog of something like a\\ncurve or surface. At any point on this surface, the gradient suggests how steeply the error will\\nbe reduced or increased for a change in the weight. The algorithm will attempt to change the\\nweights that result in the greatest reduction in error (see Figure 9.17).\\n9.8.2 Illustrative example\\nTo illustrate the various steps in the backpropagation algorithm, we consider a small network with\\ntwo inputs, two outputs and one hidden layer as shown in Figure 9.18.2\\nWe assume that there are two observations:\\nSample Input 1 Input 2 Output target 1 Output target 2\\ni1i2 T1 T2\\n1 0.05 0.10 0.01 0.99\\n2 0.25 0.18 0.23 0.79\\nWe are required to estimate the optimal values of the weights w1;:::;w 8;b1;b2. Hereb1andb2are\\nthe biases. For simplicity, we have assigned the same biases to both nodes in the same layer.\\nStep 1. We initialise the connection weights to small random values. These initial weights are\\nshown in Figure 9.19.\\n2Thanks to https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-\\nexample/ for this example.CHAPTER 9. NEURAL NETWORKS 124\\nInput 1\\nInput 2\\n1Output 1\\nOutput 2\\n1w1h1\\nw2w5\\nw6o1\\nw3\\nw4h2w7\\no2w8\\nb1\\nb2b3\\nb4\\nFigure 9.18: ANN for illustrating backpropagation algorithm\\ni1=:05\\ni2=:10\\n1T1=:01\\nT2=:99\\n1w1=:15h1\\nw2=:20w5=:40o1\\nw6=:45w3=:25\\nh2w4=:30w7=:50\\nw8=:55o2\\nb1=:35\\nb2=:35b3=:60\\nb4=:60\\nFigure 9.19: ANN for illustrating backpropagation algorithm with initial values for weights\\nStep 2. Present the ﬁrst sample inputs and the corresponding output targets to the network. This is\\nshown in Figure 9.19.\\nStep 3. Pass the input values to the ﬁrst layer (the layer with nodes h1andh2).\\nStep 4. We calculate the outputs from h1andh2. We use the logistic activation function\\nf(x)=1\\n1+e−x:\\nouth1=f(w1×i1+w2×i2+b1×1)\\n=f(0:15×0:05+0:20×0:10+0:35×1)\\n=f(0:3775)\\n=1\\n1+e−0:3775\\n=0:59327\\nouth2=f(w3×i1+w4×i2+b2×1)\\n=f(0:25×0:05+0:30×0:10+0:35×1)\\n=f(0:3925)\\n=1\\n1+e−0:3925\\n=0:59689CHAPTER 9. NEURAL NETWORKS 125\\nStep 5. We repeat this process for every layer. We get the outputs from the nodes in the output\\nlayer as follows:\\nouto1=f(w5×outh1+w6×outh2+b3×1)\\n=f(0:40×0:59327+0:45×0:59689+0:60×1)\\n=f(1:10591)\\n=1\\n1+e−1:10591\\n=0:75137\\nouto2=f(w7×outh1+w8×outh2+b4×1)\\n=f(0:50×0:59327+0:55×0:59689+0:60×1)\\n=f(1:22492)\\n=1\\n1+e−1:22492\\n=0:77293\\nThe sum of the squares of the output errors is given by\\nE=1\\n2(T1−outo1)2+1\\n2(T2−outo2)2\\n=(0:01−0:75137)2+(0:99−0:77293)2\\n=0:298371\\nStep 6. We begin backward phase. We adjust the weights. We ﬁrst adjust the weights leading to\\nthe nodeso1ando2in the output layer and then the weights leading to the nodes h1andh2\\nin the hidden layer. The adjusted values of the weights w1;:::;w 8;b1;:::;b 4are denoted\\nbyw+\\n1;:::;w+\\n8;b+\\n1;:::;b+\\n4. The computations use a certain constant \\x11called the learning\\nrate. In the following we have taken \\x11=0:5.\\n(a) Computation of adjusted weights leading to o1ando2:\\n\\x0eo1=(T1−outo1)×outo1×(1−outo1)\\n=(0:01−0:75137)×0:75137×(1−0:75137)\\n=−0:13850\\nw+\\n5=w5+\\x11×\\x0eo1×outh1\\n=0:40+0:5×(−0:13850)×0:59327\\n=0:35892\\nw+\\n6=w6+\\x11×\\x0eo1×outh2\\n=0:45+0:5×(−0:13850)×0:59689\\n=0:40867\\nb+\\n3=b3+\\x11×\\x0eo1×1\\n=0:60+0:5×(−0:13850)×1\\n=0:53075\\n\\x0eo2=(T2−outo2)×outo2×(1−outo2)\\n=(0:99−0:77293)×0:77293×(1−0:77293)\\n=0:03810\\nw+\\n7=w7+\\x11×\\x0eo2×outh1\\n=0:50+0:5×0:03810×0:59327CHAPTER 9. NEURAL NETWORKS 126\\n=0:51130\\nw+\\n8=w8+\\x11×\\x0eo2×outh2\\n=0:55+0:5×0:03810×0:59689\\n=0:56137\\nb+\\n4=b4+\\x11×\\x0eo2×1\\n=0:60+0:5×0:03810×1\\n=0:61905\\n(b) Computation of adjusted weights leading to h1andh2:\\n\\x0eh1=(\\x0eo1×w5+\\x0eo2×w7)×outh1×(1−outh1)\\n=(−0:13850×0:40+0:03810×0:50)×0:59327×(1−0:59327)\\n=−0:00877\\nw+\\n1=w1+\\x11×\\x0eh1×i1\\n=0:15+0:5×(−0:00877)×0:05\\n=0:14978\\nw+\\n2=w2+\\x11×\\x0eh1×i2\\n=0:20+0:5×(−0:00877)×0:10\\n=0:19956\\nb+\\n1=b1+\\x11×\\x0eh1×1\\n=0:35+0:5×(−0:00877)×1\\n=0:34562\\n\\x0eh2=(\\x0eo1×w6+\\x0eo2×w8)×outh2×(1−outh2)\\n=((−0:13850)×0:45+0:03810×0:55)×0:59689×(1−0:59689)\\n=−0:00995\\nw+\\n3=w3+\\x11×\\x0eh2×i1\\n=0:25+0:5×(−0:00995)×0:05\\n=0:24975\\nw+\\n4=w4+\\x11×\\x0eh2×i2\\n=0:30+0:5×(−0:00995)×0:10\\n=0:29950\\nb+\\n2=b2+\\x11×\\x0eh2×1\\n=0:35+0:5×(−0:00995)×1\\n=0:34503\\nStep 7. Now we set:\\nw1=w+\\n1; w 2=w+\\n2; w 3=w+\\n3; w 4=w+\\n4\\nw5=w+\\n5; w 6=w+\\n6; w 7=w+\\n7; w 8=w+\\n8\\nb1=b+\\n1; b 2=b+\\n2; b 3=b+\\n3; b 4=b+\\n4\\nWe choose the next sample input and the corresponding output targets to the network and\\nrepeat Steps 2 to 6.\\nStep 8. The process in Step 7 is repeated until the root mean square of output errors is minimised.CHAPTER 9. NEURAL NETWORKS 127\\nRemarks\\n1. The constant1\\n2is included in the expression for Eso that the exponent is cancelled when we\\ndifferentiate it. The result has been multiplied by a learning rate \\x11=0:5and so it doesnâ ˘A´Zt\\nmatter that we introduce the constant1\\n2inE.\\n2. In the above computations, the method used to calculate the adjusted weights is known as the\\ndelta rule .\\n3. The rule for computing the adjusted weights can be succinctly stated as follows. Let wbe a\\nweight andw+its adjusted weight. Let Ebe the the total sum of squares of errors. Then w+\\nis computed by\\nw+=w−\\x11@E\\n@w:\\nHere@E\\n@wis the gradient of Ewith respect to w; that is, the rate at which Eis changing with\\nrespect tow. (The set of all such gradients speciﬁes the direction in which Eis decreasing\\nthe most rapidly, that is, the direction of quickest descent.) For example, it can be shown that\\n@E\\n@w5=−(T1−outo1)×outo1×(1−outo1)×outh1\\n=−\\x0eo1×outh1\\nand so\\nw+\\n5=w5−\\x11@E\\n@w5\\n=w5+\\x11×\\x0eo1×outh1\\n9.8.3 The algorithm\\nThe backpropagation algorithm trains a given feed-forward multilayer neural network for a given set\\nof input patterns with known classiﬁcations. When each entry of the sample set is presented to the\\nnetwork, the network examines its output response to the sample input pattern. The output response\\nis then compared to the known and desired output and the error value is calculated. Based on the\\nerror, the connection weights are adjusted. The adjustments are based on the mean square error of\\nthe output response to the sample input and it is known as the delta learning rule . The set of these\\nsample patterns are repeatedly presented to the network until the error value is minimized.\\nNotations\\nFigures 9.20 and 9.21 show the various notations used in the algorithm.\\nM : Number of layers (excluding the input layer\\nwhich is assigned the layer number 0)\\nNj: Number of neurons (nodes) in j-th layer\\nXp=(Xp1;Xp2;:::;XpN0):p-th training sample\\nTp=(Tp1;Tp2;:::;TpNM): Known output corresponding to\\nthep-th training sample\\nOp=(Op1;Op2;:::;OpNM): Actual output by the network corresponding to\\nthep-th training sample\\nYji: Output from the i-th neuron in layer j\\nWjik : Connection weight from k-th neuron in\\nlayer(j−1)toi-th neuron in layer j\\n\\x0eji: Error value associated with the i-th neuron in layer jCHAPTER 9. NEURAL NETWORKS 128\\n/uni22EF Tp1Op1\\n/uni22EF Tp2Op2\\n/uni22EF/uni22EF /uni22EF\\n/uni22EF TpN0OpN0j(layer #)j=0j=1 j=M\\nNj(# neurons) N0N1 NMXp1\\nXp2\\nXpN0\\nFigure 9.20: Notations of backpropagation algorithm\\nji Yij\\n:::Y(j−1)1\\nY(j−1)2Wji1\\nWji2\\nY(j−1)3Wji3\\nY(j−1)Nj−1WjiNj−1Yij=f/parenleft.alt2∑Nj−1\\nk=1Y(j−1)kWjik/parenright.alt2\\x0eij\\nFigure 9.21: Notations of backpropagation algorithm: The i-th node in layer j\\nThe algorithm\\nStep 1. Initialize connection weights into small random values.\\nStep 2. Present the pth sample input vector of pattern\\nXp=(Xp1;Xp2;:::;XpN0)\\nand the corresponding output target\\nTp=(Tp1;Tp2;:::;TpNM)\\nto the network.\\nStep 3. Pass the input values to the ﬁrst layer, layer 1. For every input node iin layer 0, perform:\\nY0i=Xpi:CHAPTER 9. NEURAL NETWORKS 129\\nStep 4. For every neuron iin every layer j=1;2;:::;M , ﬁnd the output from the neuron:\\nYji=f/parenleft.alt2∑Nj−1\\nk=1Y(j−1)kWjik/parenright.alt2;\\nwhere\\nf(x)=1\\n1+exp(−x):\\nStep 5. Obtain output values. For every output node iin layerM, perform:\\nOpi=YMi:\\nStep 6. Calculate error value \\x0ejifor every neuron iin every layer in backward order j=M;M−\\n1;:::; 2;1, from output to input layer, followed by weight adjustments. For the output\\nlayer, the error value is:\\n\\x0eMi=YMi(1−YMi)(Tpi−YMi);\\nand for hidden layers:\\n\\x0eji=Yji(1−Yji)∑Nj+1\\nk=1\\x0e(j+1)kW(j+1)ki:\\nThe weight adjustment can be done for every connection from neuron kin layer (j−1)to\\nevery neuron jin every layer i:\\nW+\\njik=Wjik+\\x11\\x0ejiYji;\\nwhere\\x11represents weight adjustment factor (called the learning rate ) normalized between\\n0 and 1.\\nStep 7. The actions in steps 2 through 6 will be repeated for every training sample pattern p, and\\nrepeated for these sets until the sum of the squares of output errors is minimized.\\n9.9 Introduction to deep learning\\n9.9.1 Deﬁnition\\nA neural network with multiple hidden layers is called a Deep Neural Network (DNN) and the\\npractice of training such network is referred to as deep learning .\\nRemarks\\nIn the terminology “deep learning”, the term “deep” is a technical term. It refers to the number of\\nlayers in a neural network. A shallow network has one so-called hidden layer, and a deep network\\nhas more than one. Multiple hidden layers allow deep neural networks to learn features of the data\\nin a so-called feature hierarchy, because simple features recombine from one layer to the next, to\\nform more complex features. Networks with many layers pass input data (features) through more\\nmathematical operations than networks with few layers, and are therefore more computationally\\nintensive to train. Computational intensivity is one of the hallmarks of deep learning.\\nFigure 9.22 shows a shallow neural network and Figure 9.23 shows a deep neural network with\\nthree hidden layers.CHAPTER 9. NEURAL NETWORKS 130\\nFigure 9.22: A shallow neural network\\nFigure 9.23: A deep neural network with three hidden layers\\n9.9.2 Some applications\\nDeep learning applications are used in industries from automated driving to medical devices.\\n1.Automated driving :\\nAutomotive researchers are using deep learning to automatically detect objects such as stop\\nsigns and trafﬁc lights. In addition, deep learning is used to detect pedestrians, which helps\\ndecrease accidents.\\n2.Aerospace and defense :\\nDeep learning is used to identify objects from satellites that locate areas of interest, and iden-\\ntify safe or unsafe zones for troops.\\n3.Medical research :\\nCancer researchers are using deep learning to automatically detect cancer cells. Teams at\\nUCLA built an advanced microscope that yields a high-dimensional data set used to train a\\ndeep learning application to accurately identify cancer cells.\\n4.Industrial automation :\\nDeep learning is helping to improve worker safety around heavy machinery by automatically\\ndetecting when people or objects are within an unsafe distance of machines.\\n5.Electronics :CHAPTER 9. NEURAL NETWORKS 131\\nDeep learning is being used in automated hearing and speech translation. For example, home\\nassistance devices that respond to your voice and know your preferences are powered by deep\\nlearning applications.\\n9.10 Sample questions\\n(a) Short answer questions\\n1. Explain the biological motivation for the formulation of the concept of artiﬁcial neural net-\\nworks.\\n2. With the aid of a diagram, explain the concept of an artiﬁcial neuron.\\n3. What is an activation function in an artiﬁcial neuron? Give some examples.\\n4. Deﬁne a perceptron.\\n5. Is neural network supervised or unsupervised learning? Why?\\n6. Is deep learning supervised or unsupervised? Why?\\n7. What is the basic idea of the backpropagation algorithm?\\n8. In the context of ANNs, what is meant by network topology?\\n9. Explain the different types of layers in an ANN.\\n10. What is the gradient descent method? How is used in the backpropagation algorithm?\\n11. A neuron with 4 inputs has the weights 1;2;3;4and bias 0. The activation function is linear,\\nsay the function f(x)=2x. If the inputs are 4;8;5;6, compute the output. Draw a diagram\\nrepresenting the neuron.\\n(b) Long answer questions\\n1. Design a two layer network of perceptrons to implement A XOR B.\\n2. Explain the backpropagation algorithm.\\n3. Describe the perceptron learning algorithm.\\n4. What are the characteristics of an artiﬁcial neural networks.\\n5. Explain the concept of deep learning. Give some real life problems where this concept has\\nbeen successfully applied.\\n6. Compute the output of the following neuron if the activation function is (i) the threshold\\nfunction (ii) the sigmoid function (iii) the hyperbolic tangent function (assume the same bias\\n0.5 for each node).\\nx0=3:5\\nx1=2:9w0=0:89\\nw1=−2:07\\nx2=1:2w2=0:08Output (y)CHAPTER 9. NEURAL NETWORKS 132\\n7. Which of the boolean functions AND, OR, XOR (or none of these) is represented by the\\nfollowing network of perceptrons (with unit step function as the activation function)?\\nx1\\nw1=1\\nx2w2=1w3=−1\\nw4=−1w5=3b1=−0:5\\nb2=−0:5b4=0:5b3==−1:5Output (y)\\n8. Given the following network, compute the outputs from o1ando2(assume that the activation\\nfunction is the sigmoid function).\\nInputi1=:25\\nInputi2=:30\\n1Output 1\\nOutput 2\\n1w1=:17h1\\nw2=:21w5=:52o1\\nw6=:61w3=:18\\nh2w4=:27w7=:55\\nw8=:72o2\\nb1=:12\\nb2=:24b3=:48\\nb4=:36\\n9. (Assignment question) Given the following data, use ANN with one hidden layer, appropriate\\ninitial weights and biases to compute the optimal values of the weights. Perform one iteration\\nof the forward and phases of the backpropagation algorithm for each samples.\\nSample Input 1 Input 2 Output target 1 Output target 2\\n1 1.20 2.30 0.53 0.76\\n2 0.23 0.37 1.17 2.09Chapter 10\\nSupport vector machines\\nWe begin this chapter by illustrating the basic concepts and terminology of the theory of support\\nvector machines by a simple example. We then introduce the necessary mathematical background,\\nwhich is essentially an introduction to ﬁnite dimensional vector spaces, for describing the general\\nconcepts in the theory of support vector machines. The related algorithms without proofs are then\\npresented.\\n10.1 An example\\n10.1.1 Problem statement\\nSuppose we want to develop some criteria for determining the weather conditions under which tennis\\ncan be played. To simplify the matters it has been decided to use the measures of temperature and\\nhumidity as the critical parameters for the investigation. We have some data as given in Table 10.1\\nregarding the values of the parameters and the decisions taken as to whether to play tennis or not.\\nWe are required to develop a criteria to know whether one would be playing tennis on a future date\\nif we know the values of the temperature and humidity of that date in advance.\\n10.1.2 Discussion and solution\\nWe shall now see the various steps that lead to a solution of the problem using the ideas of support\\nvector machines.\\ntemperature humidity play\\n85 85 no\\n60 70 yes\\n80 90 no\\n72 95 no\\n68 80 yes\\n74 73 yes\\n69 70 yes\\n75 85 no\\n83 78 no\\nTable 10.1: Example data with two class labels\\n133CHAPTER 10. SUPPORT VECTOR MACHINES 134\\n1. Two-class data set\\nThis is our ﬁrst observation regarding the data in Table 10.1. In Table 10.1, the data are classiﬁed\\nbased on the values of the variable “play”. This variable has only two values or labels, namely “yes”\\nand ”no”. When there are only two class labels the data is said to be a “two-class data set”. So the\\ndata in Table 10.1 is a two-class data set.\\n2. Scatter plot of the data\\nSince there are only two features or parameters, we may plot the values of one of the parameters, say\\n“temperature”, along the horizontal axis (that is, the x-axis) and the values of the other parameter\\n“humidity”, along the vertical axis (that is, the y-axis). The data can be plotted in a coordinate plane\\nto get a scatter plot of the data. Figure 10.1 shows the scatter plot. In the ﬁgure the points which\\ncorrespond to the decision “yes” on playing tennis has been plotted as ﬁlled squares ( /uni25FE) and which\\ncorrespond to the decision “no” has been marked as hollow circles ( ○).\\nFigure 10.1: Scatter plot of data in Table 10.1 (ﬁlled circles represent “yes” and unﬁlled circles\\n“no”)\\n3. A separating line\\nIf we examine the plot in Figure 10.1, we can see that we can draw a straight line in the plane\\nseparating the two types of points in the sense that all points plotted as ﬁlled squares are on one side\\nof the line and all points marked as hollow circles are on the other side of the line. Such a line is\\ncalled a “separating line” for the data. Figure 10.2 shows a separating line for the data in Table 10.1.\\nThe equation of the separating line shown in Figure 10.2 is\\n5x+2y−535=0: (10.1)\\nIt has the following property:\\n• If the data point with values (x′;y′)has the value “yes” for “play” (ﬁlled square), then\\n5x′+2y′−535<0: (10.2)\\n• If the data point with values (x;y)has the value “no” for “play” (hollow circle), then\\n5x′+2y′−535>0: (10.3)\\nIf such a separating line exists for a given data then the data is said to be “linearly separable”.\\nThus the data in table 10.1 is linearly separable. However note that not all data are linearly separable.CHAPTER 10. SUPPORT VECTOR MACHINES 135\\nFigure 10.2: Scatter plot of data in Table 10.1 with a separating line\\n4. Several separating lines\\nApparently, the conditions given in Eqs. (10.2) and (10.3) may be used as the criteria to know\\nwhether one would be playing tennis on a future date if we know the values of the temperature\\nand humidity of that date in advance. But there are several separating lines and the problem of\\ndetermining which one to choose arises. Figure 10.3 shows two separating lines for the given data.\\nFigure 10.3: Two separating lines for the data in Table 10.1\\n4. Margin of a separating line\\nTo choose the “best” separating line, we introduce the concept of the margin of a separating line.\\nGiven a separating line for the data, we consider the perpendicular distances of the data points\\nfrom the separating line. Th double of the shortest perpendicular distance is called the “margin of the\\nseparating line”. Figure ??shows some of the perpendicular distances and the shortest perpendicular\\ndistance for the data in Table 10.1 and for the separating line given by Eq. (10.1).\\n5. Maximal margin separating line\\nThe “best” separating line is the one with the maximum margin.CHAPTER 10. SUPPORT VECTOR MACHINES 136\\nFigure 10.4: Shortest perpendicular distance of a separating line from data points\\nThe separating line with the maximum margin is called the “maximum margin line” or the “op-\\ntimal separating line”. This line is also called the “support vector machine” for the data in Table\\n10.1.\\nUnfortunately, ﬁnding the equation of the maximum margin line is not a trivial problem. Figure\\n10.5 shows the maximum margin line for the data in Table 10.1. The equation of the maximum\\nmargin line can be shown to be\\n7x+6y−995:5=0: (10.4)\\nFigure 10.5: Maximum margin line for data in Table 10.1\\n6. Support vectors\\nThe data points which are closest to the maximum margin line are called the “support vectors”. The\\nsupport vectors are shown in Figure 10.6.\\n7. The required criterion\\nAs per theory of support vector machines, the equation of the maximum margin line is used to\\ndevise a criterion for taking a decision on whether to play tennis or not. Let x′andy′be the valuesCHAPTER 10. SUPPORT VECTOR MACHINES 137\\nFigure 10.6: Support vectors for data in Table 10.1\\nof temperature and humidity on a given day. Then the decision as to whether play tennis on that day\\nis “yes” if\\n7x+6y−995:5<0\\nand “no” if\\n7x+6y−995:5>0:\\n8. “Street” of maximum width separating “yes” points and “no” points\\nConsidering Figure 10.6, we may draw a line through the support vectors 1and2parallel to the\\nmaximum margin line, and a line through support vector 3 parallel to the maximum margin line.\\nThe two lines are shown as dashed lines in Figure 10.7. The region between these two dashed lines\\ncan be thought of as a “road” or a “street” of maximum width that separates the “yes” data points\\nand the “no” data points.\\nFigure 10.7: Boundaries of “street” of maximum width separating “yes” points and “no” points in\\nTable 10.1CHAPTER 10. SUPPORT VECTOR MACHINES 138\\n9. Final comments\\ni) Any line given an equation of the form\\nax+by+c=0\\nseparates the coordinate plane into two halves. One half consists of all points for which\\nax+by+c>0and the other half consists of all points for which ax+by+c<0. Which half\\nis which depends the signs of the coefﬁcients a;b;c .\\nii) Figure 10.8 shows the plot of the maximum margin line produced using the R programming\\nlanguage.\\nFigure 10.8: Plot of the maximum margin line of data in Table 10.1 produced by the R programming\\nlanguage\\niii) In the sections below, we generalise the concepts introduced above to data sets having more\\nthan two features.\\n10.2 Finite dimensional vector spaces\\nIn Section 10.1 we have geometrically examined in detail the concepts of the theory of support\\nvector machines with an example having only two features. But, obviously, such a geometrical\\napproach is infeasible if there are more than two features. In such cases we have to resort to formal\\nalgebraic/mathematical formalism to investigate the problem. The theory of what are known as\\n“ﬁnite dimensional vector spaces” provides such a formalism. We present below the absolutely\\nessential parts of this theory. Those who are interested in learning about the abstract concept of a\\nvector space may refer to any well written book on linear algebra.\\n10.2.1 Deﬁnition\\nWe give the deﬁnition of a ﬁnite dimensional vector space here. We once again warn the reader\\nthat we are introducing the terms with reference to a very special case of a ﬁnite dimensional vectorCHAPTER 10. SUPPORT VECTOR MACHINES 139\\nspace and that all the terms given below have more general meanings.\\nDeﬁnition\\nLetnbe a positive integer. By a n-dimensional vector we mean an ordered n-tuple of real numbers\\nof the form (x1;x2;:::;xn). We denote vectors by /uni20D7x,/uni20D7y, etc. In the vector /uni20D7x=(x1;x2;:::;xn), the\\nnumbersx1;x2;:::xnare called the coordinates or the components of/uni20D7x. In the following, we call\\nreal numbers as scalars .\\nThe set of all n-dimensional vectors with the operations of addition of vectors andmultiplication\\nof a vector by a scalar and with the deﬁnitions of the zero vector and the negative of a vector as\\ndeﬁned below is a n-dimensional vector space. It is denoted by Rn.\\n1.Addition of vectors\\nLet/uni20D7x=(x1;x2;:::;xn)and/uni20D7y=(y1;y2;:::;yn)be twon-dimensional vectors. The sum of\\n/uni20D7xand/uni20D7y, denoted by /uni20D7x+/uni20D7y, is deﬁned by\\n/uni20D7x+/uni20D7y=(x1+y1;x2+y2;:::;xn+yn):\\n2.Multiplication by scalar\\nLet\\x0bbe a scalar and /uni20D7x=(x1;x2;:::;xn)be an-dimensional vector. The product of /uni20D7xby\\x0b,\\ndenoted by\\x0b/uni20D7x, is deﬁned by\\n\\x0b/uni20D7x=(\\x0bx1;\\x0bx 2;:::;\\x0bxn):\\nWhen we write the product of /uni20D7xby\\x0b, we always write the scalar \\x0bon the left side of the\\nvector/uni20D7xas we have done above.\\n3.The zero vector\\nThen-dimensional vector (0;0;:::; 0), which has all components equal to 0, is called the\\nzero vector. It is also denoted by 0. From the context of the usage we can understand whether\\n0denotes the scalar 0or the zero vector.\\n4.Negative of a vector\\nLet/uni20D7x=(x1;x2;:::;xn)be anyn-dimensional vector. The negative of /uni20D7xis a vector denoted\\nby−/uni20D7xand is deﬁned by\\n−/uni20D7x=(−x1;−x2;:::;−xn):\\nWe write /uni20D7x+(−/uni20D7y)as/uni20D7x−/uni20D7y.\\n10.2.2 Properties\\nLetnbe a positive integer. Let /uni20D7x,/uni20D7y,/uni20D7zbe arbitrary vectors in Rnand let\\x0b;\\x0c;\\r be arbitrary scalars.\\n1. Closure under addition: /uni20D7x+/uni20D7yis also an-dimensional vector.\\n2. Commutativity: /uni20D7x+/uni20D7y=/uni20D7y+/uni20D7x\\n3. Associativity: /uni20D7x+(/uni20D7y+/uni20D7z)=(/uni20D7x+/uni20D7y)+/uni20D7z\\n(Because of this property, we can write the sums /uni20D7x+(/uni20D7y+/uni20D7z)and(/uni20D7x+/uni20D7y)+/uni20D7zin the form\\n/uni20D7x+/uni20D7y+/uni20D7z.)\\n4. Existence of identity for addition: /uni20D7x+0=/uni20D7x\\n5. Existence of inverse for addition: /uni20D7x+(−/uni20D7x)=0\\n6. Closure under scalar multiplication: \\x0b/uni20D7xis also an-dimensional vector.CHAPTER 10. SUPPORT VECTOR MACHINES 140\\n7. Compatibility of multiplication of a vector by a scalar with multiplication of scalars: \\x0b(\\x0c/uni20D7x)=\\n(\\x0b\\x0c)/uni20D7x\\n8. Distributivity of scalar multiplication over vector addition: \\x0b(/uni20D7x+/uni20D7y)=\\x0b/uni20D7x+\\x0b/uni20D7y\\n9. Distributivity of scalar multiplication over addition of scalars: (\\x0b+\\x0c)/uni20D7x=\\x0b/uni20D7x+\\x0c/uni20D7x\\n10. Existence of identity element for scalar multiplication: 1/uni20D7x=/uni20D7x\\nExample of computation\\nLetn=3. Let/uni20D7x=(−1;2;3);/uni20D7y=(2;0;−1);/uni20D7z=(1;1;0),\\x0b=2;\\x0c=−3;\\r=4and\\x15=5. The\\nexpression\\x15(\\x0b/uni20D7x+\\x0c/uni20D7y+\\r/uni20D7z)can be computed in several different ways. One of the methods is shown\\nbelow.\\n\\x15(\\x0b/uni20D7x+\\x0c/uni20D7y+\\r/uni20D7z)=5(2(−1;2;3)+(−3)(2;0;−1)+4(1;1;0))\\n=5((−2;4;6)+(−6;0;3)+(4;4;0))\\n=5((−8;4;9)+(4;4;0))\\n=5(−4;8;9)\\n=(−20;40;45)\\n10.2.3 Norm and inner product\\n1.Norm\\nThe norm of the n-dimensional vector /uni20D7x=(x1;x2;:::;xn), denoted by /divides.alt0/divides.alt0/uni20D7x/divides.alt0/divides.alt0, is deﬁned by\\n/parallel.alt1/uni20D7x/parallel.alt1=/radical.alt2\\nx2\\n1+x2\\n2+/uni22EF+x2n:\\n2.Inner product\\nThe inner product of /uni20D7x=(x1;x2;:::;xn)and/uni20D7y=(y1;y2;:::;yn), denoted by /uni20D7x⋅/uni20D7y, is deﬁned\\nby\\n/uni20D7x⋅/uni20D7y=x1y1+x2y2+/uni22EF+xnyn:\\nNote that we have\\n/parallel.alt1/uni20D7x/parallel.alt1=√\\n/uni20D7x⋅/uni20D7x:\\n3.Angle between two vectors\\nThe angle\\x12between two vectors /uni20D7xand/uni20D7yis deﬁned by\\ncos\\x12=/uni20D7x⋅/uni20D7y\\n/parallel.alt1/uni20D7x/parallel.alt1/parallel.alt1/uni20D7y/parallel.alt1:\\n4.Perpendicularity\\nTwo vectors /uni20D7x=(x1;x2;:::;xn)and/uni20D7y=(y1;y2;:::;yn)are said to be perpendicular (or,\\northogonal) if\\n/uni20D7x⋅/uni20D7y=0:CHAPTER 10. SUPPORT VECTOR MACHINES 141\\nExample\\nLetn=4and let/uni20D7x=(−1;2;0;3)and/uni20D7y=(2;3;1;−4).\\n/parallel.alt1/uni20D7x/parallel.alt1=/radical.alt1\\n(−1)2+22+02+32\\n=√\\n14\\n/parallel.alt1/uni20D7y/parallel.alt1=/radical.alt1\\n22+32+12+(−4)2\\n=√\\n30\\n/uni20D7x⋅/uni20D7y=(−1)×2+2×3+0×1+3×(−4)\\n=−8\\ncos\\x12=−8√\\n14√\\n30\\n=−0:39036\\n\\x12=112:98degrees\\nSince/uni20D7x⋅/uni20D7y≠0the vectors /uni20D7xand/uni20D7yare not orthogonal.\\n10.3 Hyperplanes\\nHyperplanes are certain subsets of ﬁnite dimensional vector spaces which are similar to straight lines\\nin planes and planes in three-dimensional spaces.\\n10.3.1 Deﬁnition\\nConsider the n-dimensional vector space Rn. The set of all vectors\\n/uni20D7x=(x1;x2;:::;xn)\\ninRnwhose components satisfy an equation of the form\\n\\x0b0+\\x0b1x1+\\x0b2x2+/uni22EF+\\x0bnxn=0; (10.5)\\nwhere\\x0b0;\\x0b1;\\x0b2;:::;\\x0bnare scalars, is called a hyperplane in the vector space Rn.\\nRemarks 1\\nLet/uni20D7x=(x1;x2;:::;xn)and/uni20D7\\x0b=(\\x0b1;\\x0b2;:::;\\x0bn), then using the notation of inner product,\\nEq.(10.5) can be written in the following form:\\n\\x0b0+/uni20D7\\x0b⋅/uni20D7x=0:\\nRemarks 2\\nThe hyperplane in Rndeﬁned by Eq.(10.5) divides the space Rninto two disjoint halves. One of\\nthe two halves consists of all vectors /uni20D7xfor which\\n\\x0b0+\\x0b1x1+\\x0b2x2+/uni22EF+\\x0bnxn>0\\nand the other half consists of all vectors /uni20D7xfor which\\n\\x0b0+\\x0b1x1+\\x0b2x2+/uni22EF+\\x0bnxn<0:CHAPTER 10. SUPPORT VECTOR MACHINES 142\\n10.3.2 Special cases\\nHyperplanes in 2-dimensional vector spaces: Straight lines\\nConsider the 2-dimensional vector space R2. Vectors in this space are ordered pairs of the form\\n(x1;x2). Choosing appropriate coordinate axes, such a vector can be represented by a point with\\ncoordinates /uni20D7x=(x1;x2)in the plane. So, the vector space R2can be identiﬁed with the set of points\\nin a plane. In this special case, the norm /parallel.alt1x/parallel.alt1is the distance of the point (x1;x2)in the plane from\\nthe origin. The angle between the vectors /uni20D7x=(x1;x2)and/uni20D7y=(y1;y2)is the angle between the\\nlines joining the origin to the points (x1;x2)and(y1;y2).\\nConsider the set of all vectors /uni20D7x=(x1;x2)inR2which satisfy the following equation:\\n\\x0b0+\\x0b1x1+\\x0b2x2=0\\nwhere\\x0b0+\\x0b1;\\x0b2are scalars. From elementary analytical geometry we can see that the correspond-\\ning set of points in the plane form a straight line in the plane. This straight line divides the plane\\ninto two disjoint halves (see Figure 10.9). It can be proved that one of the two halves consists of all\\npoints for which\\n\\x0b0+\\x0b1x1+\\x0b2x2>0\\nand the other half consists of all points for which\\n\\x0b0+\\x0b1x1+\\x0b2x2<0:\\nx1x2\\nO\\nEquation of line:\\n\\x0b0+\\x0b1x1+\\x0b2x2=0\\n(assume\\x0b0<0)Half plane where\\n\\x0b0+\\x0b1x1+\\x0b2x2<0Half plane where\\n\\x0b0+\\x0b1x1+\\x0b2x2>0\\nFigure 10.9: Half planes deﬁned by a line\\nHyperplanes in 3-dimensional vector spaces: Planes\\nConsider the 3-dimensional vector space R3. Vectors in this space are ordered triples of the form\\n(x1;x2;x3). Choosing appropriate coordinate axes, such a vector can be represented by a point\\nwith coordinates /uni20D7x=(x1;x2;x3)in the ordinary three-dimensional space. So, the vector space R3\\ncan be identiﬁed with the set of points in the three-dimensional space. As in the case of R2, the\\nnorm/parallel.alt1x/parallel.alt1is the distance of the point (x1;x2;x3)from the origin. The angle between the vectors\\n/uni20D7x=(x1;x2;x3)and/uni20D7y=(y1;y2;y3)is the angle between the lines joining the origin to the points\\n(x1;x2;x3)and(y1;y2;y3).\\nConsider the set of all vectors /uni20D7x=(x1;x2;x3)inR3which satisfy the following equation:\\n\\x0b0+\\x0b1x1+\\x0b2x2+\\x0b3x3=0CHAPTER 10. SUPPORT VECTOR MACHINES 143\\nwhere\\x0b0;\\x0b1;\\x0b2;\\x0b3are scalars. From elementary analytical geometry we can see that the corre-\\nsponding set of points in space form a plane. This plane divides the space into two disjoint halves.\\nIt can be proved that one of the two halves consists of all points for which\\n\\x0b0+\\x0b1x1+\\x0b2x2+\\x0b3x3>0\\nand the other half consists of all points for which\\n\\x0b0+\\x0b1x1+\\x0b2x2+\\x0b3x3<0:\\nGeometry of hyperplanes in n-dimensional vector spaces\\nBy analogy with a plane (which is a geometrical object having two dimensions) and the space of\\nour experience (which is a geometrical world having three dimensions) we imagine that there is a\\ngeometrical world or object having ndimensions for any value of n. We also imagine that the points\\nin this world can be represented by ordered ntuples of the form /uni20D7x=(x1;x2;:::;xn). We now\\nidentify the set of n-dimensional vectors with the points in this geometrical world of n-dimensions.\\nBecause of this identiﬁcation, vectors in the n-dimensional vector space Rnare also referred as\\npoints in an-dimensional space . The hyperplanes in Rnare deﬁned by analogy with the geometrical\\nstraight lines and planes.\\n10.3.3 Distance of a hyperplane from a point\\nIn two-dimensional space, that is, in a plane, using elementary analytical geometry, it can be shown\\nthat the perpendicular distance PN of a pointP(x′\\n1;y′\\n1)from a line\\n\\x0b0+\\x0b1x1+\\x0b2x2=0\\nis given by\\nPN=/divides.alt0\\x0b0+\\x0b1x′\\n1+\\x0b2x′\\n2/divides.alt0/radical.alt1\\n\\x0b2\\n1+\\x0b2\\n2:\\nSimilarly, in three-dimensional space, using elementary analytical geometry, it can be shown that\\nthe perpendicular distance PN of a pointP(x′\\n1;x′\\n2;x′\\n3)from a plane\\n\\x0b0+\\x0b1x1+\\x0b2x2+\\x0b3x3=0\\nis given by (see Figure 10.10)\\nPN=/divides.alt0\\x0b0+\\x0b1x′\\n1+\\x0b2x′\\n2+\\x0b3x′\\n3/divides.alt0/radical.alt1\\n\\x0b2\\n1+\\x0b2\\n2+\\x0b2\\n3:\\n\\x0b0+\\x0b1x1+\\x0b2x2+\\x0b3x3=0NP(x′\\n1;x′\\n2;x′\\n3)\\nFigure 10.10: Perpendicular distance of a point from a plane\\nMotivated by these special cases, we introduce the following deﬁnition.CHAPTER 10. SUPPORT VECTOR MACHINES 144\\nDeﬁnition\\nInRn, the perpendicular distance PN of a pointP(x′\\n1;x′\\n2;:::;x′\\nn)from a hyperplane\\n\\x0b0+\\x0b1x1+\\x0b2x2+:::+\\x0bnxn=0\\nis given by\\nPN=/divides.alt0\\x0b0+\\x0b1x′\\n1+\\x0b2x′\\n2+:::+\\x0bnx′\\nn/divides.alt0/radical.alt1\\n\\x0b2\\n1+\\x0b2\\n2+:::+\\x0b2n: (10.6)\\nRemarks\\nLet/uni20D7x′=(x′\\n1;x′\\n2;:::;x′\\nn)and/uni20D7\\x0b=(\\x0b1;\\x0b2;:::;\\x0bn), then using the notations of inner product and\\nnorm, Eq.(10.6) can be written in the following form:\\nPN=/divides.alt0\\x0b0+/uni20D7\\x0b⋅/uni20D7x′/divides.alt0\\n/parallel.alt1/uni20D7x′/parallel.alt1:\\n10.4 Two-class data sets\\nIn a machine learning problem, the variable being predicted is called the output variable , the target\\nvariable , the dependent variable or the response . Atwo-class data set is a data set in which the\\ntarget variable takes only one of two possible values only. If the target variable takes more than two\\npossible values, the data set is called a multi-class dataset .\\nIn a two-class data set, the set of values of the target variable may be {“yes”, “no” }, or{“TRUE”, ”FALSE” },\\nor{0;1}, or{−1;+1}or any such similar set.\\nThe methods of support vector machines were originally developed for classiﬁcation problems\\ninvolving two-class data sets. So in this chapter we consider mainly two-class data sets.\\n10.5 Linearly separable data\\n10.5.1 Deﬁnitions\\nConsider a two-class data set having nnumeric features and two possible class labels −1and+1.\\nLet the vector /uni20D7x=(x1;:::;xn)represent the values of the features in one instance of the data set.\\nWe say that the data set is linearly separable if we can ﬁnd a hyperplane in the n-dimensional vector\\nspaceRn, say\\n\\x0b0+\\x0b1x1+\\x0b2x2+/uni22EF+\\x0bnxn=0 (10.7)\\nhaving the following two properties:\\n1. For each instance /uni20D7xwith class label −1we have\\n\\x0b0+\\x0b1x1+\\x0b2x2+/uni22EF+\\x0bnxn<0:\\n2. For each instance /uni20D7xwith class label +1we have\\n\\x0b0+\\x0b1x1+\\x0b2x2+/uni22EF+\\x0bnxn>0:\\nA hyperplane given by Eq.(10.7) having the two properties given above is called a separating hy-\\nperplane for the data set.\\nRemarks 1\\nIf a data set with two class labels is linearly separable, then, in general, there will be several sepa-\\nrating hyperplanes for the data set. This is illustrated in the example below.CHAPTER 10. SUPPORT VECTOR MACHINES 145\\nRemarks 2\\nGiven a two-class data set, there is no simple method for determining whether the data set is linearly\\nseparable. One of the efﬁcient ways for doing this is to apply the methods of linear programming.\\nWe omit the details.\\n10.5.2 Example\\nExample 1\\nWe have seen in Section 10.1 that the data in Table 10.1 is linearly separable.\\nExample 2\\nShow that the data set given in Table 10.2 is not separable.\\nxyClass label\\n00 0\\n01 1\\n10 1\\n11 0\\nTable 10.2: Example of a two-class data that is not linearly separable\\nSolution\\nThe scatterplot of data in TableTableVXOR shown in Figure 10.11 shows that the data is not linearly\\nseparable.\\nFigure 10.11: Scatterplot of data in Table 10.2\\n10.6 Maximal margin hyperplanes\\n10.6.1 Deﬁnitions\\nConsider a linearly separable data set having two class labels “ −1” and “+1”. Consider a separating\\nhyperplaneHfor the data set.CHAPTER 10. SUPPORT VECTOR MACHINES 146\\n1. Consider the perpendicular distances from the training instances to the separating hyperplane\\nHand consider the smallest such perpendicular distance. The double of this smallest distance\\nis called the margin of the separating hyperplane H.\\n2. The hyperplane for which the margin is the largest is called the maximal margin hyperplane\\n(also called maximum margin hyperplane ) or the optimal separating hyperplane .\\n3. The maximal margin hyperplane is also called the support vector machine for the data set.\\n4. The data points that lie closest to the maximal margin hyperplane are called the support vec-\\ntors.\\nFigure 10.12: Maximal separating hyperplane, margin and support vectors\\n10.6.2 Special cases\\nTo ﬁx ideas, let us consider two special datasets in 2-dimensional space, namely, datasets having 2\\nand 3 examples.\\nDataset with two examples\\nConsider the dataset in Table 10.3.\\nExample no. x1x2Class\\n1 2 1 +1\\n2 4 3 −1\\nTable 10.3: 2-dimensional dataset with 2 examples\\nGeometrically it can be easily seen that the maximum margin hyperplane for this data is the\\nperpendicular bisector of the line segment joining the points (2;1)and(4;3)(see Figure 10.13).\\nThis is true for any two-sample dataset in two-dimensional space.\\nDataset with three examples\\nConsider a dataset with three examples from a two-dimensional space. Let these examples corre-\\nspond to the points A;B;C in the coordinate plane. Two of these examples, say BandC, must have\\nthe same class label say +1and the other point Amust have a different class label, say −1.\\nThe maximal margin hyperplane of the dataset can be obtained as follows. Draw the line joining\\nBandCand draw the line through Aparallel toBC. The line midway between these two lines in\\nthe maximal margin hyperplane of the three-sample datasetCHAPTER 10. SUPPORT VECTOR MACHINES 147\\nx1x2\\nA(2;1)B(4;3)\\n(3;2)Midpoint of AB\\n(0;0)Maximum margin hyperplane:\\nx1+x2−5=0\\nFigure 10.13: Maximal margin hyperplane of a 2-sample set in 2-dimensional space\\nx1x2\\nA(2;2)B(4;5)\\nC(7;4)\\n(0;0)Maximal margin hyperplane\\nx1+3x2−27\\n2=0\\nFigure 10.14: Maximal margin hyperplane of a 3-sample set in 2-dimensional space\\n10.7 Mathematical formulation of the SVM problem\\nThe SVM problem is the problem of ﬁnding the equation of the SVM, that is, the maximal margin\\nhyperplane, given a linearly separable two-class data set. By the very deﬁnition of SVM, this is an\\noptimisation problem. The give below the mathematical formulation of this optimisation problem.\\n10.7.1 Notations and preliminaries\\n• Assume that we are given a two-class training dataset of Npoints of the form\\n(/uni20D7x1;y1);(/uni20D7x2;y2);:::;(/uni20D7xN;yN):\\nwhere theyi’s are either +1or1(the class labels). Each /uni20D7xiis an-dimensional real vector.\\n• We assume that the dataset is linearly separable.\\n• Any hyperplane can be written as the set of points /uni20D7x=(x1;:::;xn)satisfying an equation of\\nthe form\\n/uni20D7w⋅/uni20D7x−b=0:CHAPTER 10. SUPPORT VECTOR MACHINES 148\\n• Since the training data is linearly separable, we can select two parallel hyperplanes that sep-\\narate the two classes of data, so that the distance between them is as large as possible. The\\nmaximum margin hyperplane is the hyperplane that lies halfway between them. It can be\\nshown that these hyperplanes can be described by equations of the following forms:\\n/uni20D7w⋅/uni20D7x−b=+1 (10.8)\\n/uni20D7w⋅/uni20D7x−b=−1 (10.9)\\n• For any point on or “above” the hyperplane Rq.(10.8), the class label is +1. This implies that\\n/uni20D7w⋅/uni20D7xi−b≥+1;ifyi=+1 (10.10)\\nSimilarly, for any point on or “below” the hyperplane Eq.(10.9), the class label is −1. This\\nimplies that\\n/uni20D7w⋅/uni20D7xi−b≤−1;ifyi=−1: (10.11)\\n• The two conditions in Eq.10.10 and Eq.10.11 can be written as a single condition as follows:\\nyi(/uni20D7w⋅/uni20D7xi−b)≥1;for all 1≤i≤N:\\n• Now, the distance between the two hyperplanes in Eq.(10.8) and Eq.(10.9) is\\n2\\n/parallel.alt1/uni20D7w/parallel.alt1:\\nSo, to maximize the distance between the planes we have to minimize /parallel.alt1/uni20D7w/parallel.alt1. Further we also\\nnote that /parallel.alt1/uni20D7w/parallel.alt1is minimum when1\\n2/parallel.alt1/uni20D7w/parallel.alt12is minimum. (The square of the norm is used to avoid\\nsquare-roots and the factor “1\\n2” is introduced to simplify certain expressions.)\\n10.7.2 Formulation of the problem\\nBased on the above discussion, we now formulate the SVM problem as the following optimization\\nproblem.\\nProblem\\nGiven a two-class linearly separable dataset of Npoints of the form\\n(/uni20D7x1;y1);(/uni20D7x2;y2);:::;(/uni20D7xN;yN):\\nwhere theyi’s are either +1or1, ﬁnd a vector /uni20D7wand a number bwhich\\nminimize1\\n2/parallel.alt1/uni20D7w/parallel.alt12\\nsubject to yi(/uni20D7w⋅/uni20D7xi−b)≥1;fori=1;:::N\\n10.7.3 The SVM classiﬁer\\nThe solution of the SYM problem gives us a claasiﬁer for classifying unclassiﬁed data instances.\\nThis is known as the SVM classiﬁer for a given dataset.\\nThe classiﬁer\\nLet/uni20D7w=/uni20D7w∗andb=b∗be a solution of the SVM problem. Let /uni20D7xbe an unclassiﬁed data instance.\\n• Assign the class label +1to/uni20D7xif/uni20D7w∗⋅/uni20D7x−b∗>0.\\n• Assign the class label −1to/uni20D7xif/uni20D7w∗⋅/uni20D7x−b∗<0.CHAPTER 10. SUPPORT VECTOR MACHINES 149\\n10.8 Solution of the SVM problem\\nThe SVM optimization problem as formulated above is an example of a constrained optimization\\nproblem. The general method for solving it is to convert it into a quadratic programming problem\\nand then apply the algorithms for solving quadratic programming problems. These methods yield\\nthe following solution to the SVM problem. The details of these processes are beyond the scope of\\nthese notes.\\n10.8.1 Solution\\nThe vector /uni20D7wand the scalar bare given by\\n/uni20D7w=N\\n/summation.disp\\ni=1\\x0biyi/uni20D7xi (10.12)\\nb=1\\n2/parenleft.alt4min\\ni∶yi=+1(/uni20D7w ⋅/uni20D7xi)+max\\ni∶yi=−1(/uni20D7w ⋅/uni20D7xi)/parenright.alt4 (10.13)\\nwhere/uni20D7\\x0b=(\\x0b1;\\x0b2;:::;\\x0bN)is a vector which maximizes\\nN\\n/summation.disp\\ni=1\\x0bi−1\\n2N\\n/summation.disp\\ni=1;j=1\\x0bi\\x0bjyiyj(/uni20D7xi⋅/uni20D7xj)\\nsubject to\\nN\\n/summation.disp\\ni=1\\x0biyi=0\\n\\x0bi>0fori=1;2;:::;N:\\nRemarks\\nIt can be proved that an \\x0biis nonzero only if /uni20D7xilies on the two margin boundaries, that is, only if /uni20D7xi\\nis a support vector. So, to specify a solution to the SVM problem, we need only specify the support\\nvectors/uni20D7xiand the corresponding coefﬁcients \\x0biyi.\\n10.8.2 An algorithm to ﬁnd the SVM classiﬁer\\nThe solution of the SVM problem given in Section ??can be used to develop an algorithm to ﬁnd a\\nSVM classiﬁer for linearly separable two-class dataset. Here is an outline of such an algorithm.\\nAlgorithm to ﬁnd SVM classiﬁer\\nGiven a two-class linearly separable dataset of Npoints of the form\\n(/uni20D7x1;y1);(/uni20D7x2;y2);:::;(/uni20D7xN;yN);\\nwhere theyi’s are either +1or1:\\nStep 1. Find /uni20D7\\x0b=(\\x0b1;\\x0b2;:::;\\x0bN)which maximizes\\n\\x1e(/uni20D7\\x0b)=N\\n/summation.disp\\ni=1\\x0bi−1\\n2N\\n/summation.disp\\ni=1;j=1\\x0bi\\x0bjyiyj(/uni20D7xi⋅/uni20D7xj)\\nsubject to\\nN\\n/summation.disp\\ni=1\\x0biyi=0\\n\\x0bi>0fori=1;2;:::;N:CHAPTER 10. SUPPORT VECTOR MACHINES 150\\nStep 2. Compute /uni20D7w=∑N\\ni=1\\x0biyi/uni20D7xi.\\nStep 3. Compute b=1\\n2/parenleft.alt1mini∶yi=+1(/uni20D7w ⋅/uni20D7xi)+maxi∶yi=−1(/uni20D7w ⋅/uni20D7xi)/parenright.alt1.\\nStep 4. The SVM classiﬁer function is given by\\nf(/uni20D7x)=/uni20D7w ⋅/uni20D7x−b (10.14)\\nwhere\\x0biis nonzero only if /uni20D7xiis a support vector.\\nRemarks\\nThere are specialised software packages for solving the SVM optimization problem. For example,\\nthere is a special package called svm in the R programming language to solve such problems.\\n10.8.3 Illustrative example\\nProblem 1\\nUsing the SVM algorithm, ﬁnd the SVM classiﬁer for the follwoing data.\\nExample no. x1x2Class\\n1 2 1 +1\\n2 4 3 −1\\nSolution\\nFor this data we have:\\nN=2\\n/uni20D7x1=(2;1); y 1=+1\\n/uni20D7x2=(4;3); y 2=−1\\n/uni20D7\\x0b=(\\x0b1;\\x0b2)\\nStep 1. We have:\\n\\x1e(/uni20D7\\x0b)=N\\n/summation.disp\\ni=1\\x0bi−1\\n2N\\n/summation.disp\\ni=1;j=1\\x0bi\\x0bjyiyj(/uni20D7xi⋅/uni20D7xj)\\n=(\\x0b1+\\x0b2)−1\\n2[\\x0b1\\x0b1y1y1(/uni20D7x1⋅/uni20D7x1)+\\x0b1\\x0b2y1y2(/uni20D7x1⋅/uni20D7x2)+\\n\\x0b2\\x0b1y2y1(/uni20D7x2⋅/uni20D7x1)+\\x0b2\\x0b2y2y2(/uni20D7x2⋅/uni20D7x2)]\\n=(\\x0b1+\\x0b2)−\\n1\\n2[\\x0b2\\n1(+1)(+1)(2×2+1×1)+\\x0b1\\x0b2(+1)(−1)(2×4+1×3)+\\n\\x0b2\\x0b1(−1)(+1)(4×2+3×1)+\\x0b2\\n2(−1)(−1)(4×4+3×3)]\\n=(\\x0b1+\\x0b2)−1\\n2/bracketleft.alt15\\x0b2\\n1−22\\x0b1\\x0b2+25\\x0b2\\n2/bracketright.alt\\nN\\n/summation.disp\\ni=1\\x0biyi=\\x0b1y1+\\x0b2y2\\n=\\x0b1−\\x0b2\\nWe have to solve the following problem.CHAPTER 10. SUPPORT VECTOR MACHINES 151\\nProblem\\nFind values of \\x0b1and\\x0b2which maximizes\\n\\x1e(/uni20D7\\x0b)=(\\x0b1+\\x0b2)−1\\n2/bracketleft.alt15\\x0b2\\n1−22\\x0b1\\x0b2+25\\x0b2\\n2/bracketright.alt\\nsubject to the conditions\\n\\x0b1−\\x0b2=0; \\x0b 1>0;\\x0b2>0:\\nSolution\\nTo ﬁnd the required values of \\x0b1and\\x0b2, we note that from the constraints we have \\x0b2=\\x0b1:\\nUsing this in the expression for \\x1ewe get\\n\\x1e(/uni20D7\\x0b)=2\\x0b1−4\\x0b2\\n1:\\nFor\\x1eto be maximum we must have\\nd\\x1e\\nd\\x0b1=2−8\\x0b1=0\\nthat is\\n\\x0b1=1\\n4\\nand so we also have\\n\\x0b2=1\\n4:\\n(For this value of \\x0b1, clearlyd2f\\nd\\x0b2\\n1<0andfis indeed maximum. Also we have \\x0b1>0and\\n\\x0b2>0.)\\nStep 2. Now we have\\n/uni20D7w=N\\n/summation.disp\\ni=1\\x0biyi/uni20D7xi\\n=\\x0b1y1/uni20D7x1+\\x0b2y2/uni20D7x2\\n=1\\n4(+1)(2;1)+1\\n4(−1)(4;3)\\n=1\\n4(−2;−2)\\n=(−1\\n2;−1\\n2)\\nStep 3. Next we ﬁnd\\nb=1\\n2/parenleft.alt4min\\ni∶yi=+1(/uni20D7w ⋅/uni20D7xi)+max\\ni∶yi=−1(/uni20D7w ⋅/uni20D7xi)/parenright.alt4\\n=1\\n2/parenleft.alt1(/uni20D7w ⋅/uni20D7x1)+(/uni20D7w ⋅/uni20D7x2)/parenright.alt1\\n=1\\n2/parenleft.alt1(−1\\n4×2−1\\n2×1)+(−1\\n2×4−1\\n2×3)/parenright.alt1\\n=1\\n2/parenleft.alt1−10\\n2/parenright.alt1\\n=−5\\n2CHAPTER 10. SUPPORT VECTOR MACHINES 152\\nStep 4. Let /uni20D7x=(x1;x2). The SVM classiﬁer function is given by\\nf(/uni20D7x)=/uni20D7w ⋅/uni20D7x−b\\n=(−1\\n2;−1\\n2)⋅(x1;x2)−(−5\\n2)\\n=−1\\n2x1−1\\n2x2+5\\n2\\n=−1\\n2(x1+x2−5)\\nStep 5. The equation of the maximal margin hyperplane is\\nf(/uni20D7x)=0\\nthat is\\n−1\\n2(x1+x2−5)=0\\nthat is\\nx1+x2−5=0:\\nNote that this the equation of the perpendicular bisector of the line segment joining the\\npoints(2;1)and(4;3)(see Figure 10.13).\\nProblem 2\\nUsing the SVM algorithm, ﬁnd the SVM classiﬁer for the follwoing data.\\nExample no. x1x2Class\\n1 2 2 −1\\n2 4 5 +1\\n3 7 4 +1\\nSolution\\nFor this data we have:\\nN=3\\n/uni20D7x1=(2;2); y 1=−1\\n/uni20D7x2=(4;5); y 2=+1\\n/uni20D7x3=(7;4); y 3=+1\\n/uni20D7\\x0b=(\\x0b1;\\x0b2;\\x0b3)\\n/uni20D7x=(x1;x2)\\nSrep 1. We have\\n\\x1e(/uni20D7\\x0b)=N\\n/summation.disp\\ni=1\\x0b1−1\\n2N\\n/summation.disp\\ni=1;j=1\\x0bi\\x0bjyiyj(/uni20D7xi⋅/uni20D7xj)\\n=3\\n/summation.disp\\ni=1\\x0b1−1\\n23\\n/summation.disp\\ni=1;j=1\\x0bi\\x0bjyiyj(/uni20D7xi⋅/uni20D7xj)\\nWe have\\n(/uni20D7x1⋅/uni20D7x1)=08;(/uni20D7x1⋅/uni20D7x2)=18;(/uni20D7x1⋅/uni20D7x3)=22\\n(/uni20D7x2⋅/uni20D7x1)=18;(/uni20D7x2⋅/uni20D7x2)=41;(/uni20D7x2⋅/uni20D7x3)=48;\\n(/uni20D7x3⋅/uni20D7x1)=22;(/uni20D7x3⋅/uni20D7x2)=48;(/uni20D7x3⋅/uni20D7x3)=65CHAPTER 10. SUPPORT VECTOR MACHINES 153\\nSubstituting these and simplifying we get\\n\\x1e(/uni20D7\\x0b)=(\\x0b1+\\x0b2+\\x0b3)−1\\n2[8\\x0b2\\n1+41\\x0b2\\n2+65\\x0b2\\n3−36\\x0b1\\x0b2−44\\x0b1\\x0b3+96\\x0b2\\x0b3]\\nWe also have\\nN\\n/summation.disp\\ni=1\\x0biyi=−\\x0b1+\\x0b2+\\x0b3\\nNow we have to solve the following problem.\\nProblem\\nFind/uni20D7\\x0b=(\\x0b1;\\x0b2;\\x0b3)which maximizes\\n\\x1e(/uni20D7\\x0b)=(\\x0b1+\\x0b2+\\x0b3)−1\\n2[8\\x0b2\\n1+41\\x0b2\\n2+65\\x0b2\\n3−36\\x0b1\\x0b2−44\\x0b1\\x0b3+96\\x0b2\\x0b3]\\nsubject to the conditions\\n−\\x0b1+\\x0b2+\\x0b3=0; \\x0b 1>0;\\x0b2>0;\\x0b3>0:\\nSolution\\nFrom the constraints we have\\n\\x0b1=\\x0b2+\\x0b3:\\nUsing this in the expression for \\x1e(/uni20D7\\x0b)and simplifying we get\\n\\x1e(/uni20D7\\x0b)=2(\\x0b2+\\x0b3)−1\\n2(13\\x0b2\\n2+32\\x0b2\\x0b3+29\\x0b2\\n3)\\nWhen\\x1e(/uni20D7\\x0b)is maximum we have\\n@\\x1e\\n@\\x0b2=0;@\\x1e\\n@\\x0b3=0 (10.15)\\nthat is\\n2−13\\x0b2−16\\x0b3=0;2−16\\x0b2−29\\x0b3=0:\\nSolving these equations we get\\n\\x0b2=26\\n121; \\x0b 3=−6\\n121\\nHence\\n\\x0b1=26\\n121−6\\n121=20\\n121:\\n(The conditions given in Eq.( ??) are only necessary conditions for getting a maximum\\nvalue for\\x1e(/uni20D7\\x0b). It can be shown that the values for \\x0b2and\\x0b3obtained above do indeed\\nsatisfy the sufﬁcient conditions for yielding a maximum value of \\x1e(/uni20D7\\x0b).)\\nSrep 2. Now we have\\n/uni20D7w=N\\n/summation.disp\\ni=1\\x0biyi/uni20D7xi\\n=20\\n121(−1)(2;2)+26\\n121(+1)(4;5)−6\\n121(+1)(7;4)\\n=(2\\n11;6\\n11)CHAPTER 10. SUPPORT VECTOR MACHINES 154\\nSrep 3. We have\\nb=1\\n2/parenleft.alt4min\\ni∶yi=+1(/uni20D7w ⋅/uni20D7xi)+max\\ni∶yi=−1(/uni20D7w ⋅/uni20D7xi)/parenright.alt4\\n=1\\n2/parenleft.alt1min{(/uni20D7w ⋅/uni20D7x2);(/uni20D7w ⋅/uni20D7x3)}+max{(/uni20D7w ⋅/uni20D7x1)}/parenright.alt1\\n=1\\n2/parenleft.alt1min{38\\n11;38\\n11}+max{16\\n11}/parenright.alt1\\n=1\\n2/parenleft.alt438\\n11+16\\n11/parenright.alt4\\n=27\\n11\\nSrep 4. The SVM classiﬁer function is\\nf(/uni20D7x)=/uni20D7w ⋅/uni20D7x−b\\n=2\\n11x1+6\\n11x2−27\\n11:\\nSrep 5. The equation of the maximal hyperplane is\\nf(/uni20D7x)=0\\nthat is2\\n11x1+6\\n11x2−27\\n11=0\\nthat is\\nx1+3x2−27\\n2=0:\\n(See Figure 10.14.)\\n10.9 Soft margin hyperlanes\\nThe algorithm for ﬁnding the SVM classiﬁer will give give a solution only if the the given two-class\\ndataset is linearly separable. But, in real life problems, two-class datasets are only rarely linearly\\nseparable. In such a case we introduce additional variables, \\x18i, called slack variables which store\\ndeviations from the margin. There are two types of deviation: An instance may lie on the wrong\\nside of the hyperplane and be misclassiﬁed. Or, it may be on the right side but may lie in the margin,\\nnamely, not sufﬁciently away from the hyperplane (see Figure 10.15).\\nIf\\x18i=0, then/uni20D7xiis correctly classiﬁed and there is no problem with /uni20D7xi. If0<\\x18i<1then/uni20D7xiis\\ncorrectly classiﬁed but it is in the margin. If \\x18i>1,/uni20D7xiis misclassiﬁed. Th sum ∑N\\ni=1\\x18iis deﬁned\\nas the soft error and this is added as a penalty to the function to be minimized. We also introduce a\\nfactorCto the soft error.\\nWith these modiﬁcations, we now reformulate the SVM problem as follows (see Section 10.7.2\\nfor the original formulation of the problem):\\nReformulated problem\\nGiven a two-class linearly separable dataset of Npoints of the form\\n(/uni20D7x1;y1);(/uni20D7x2;y2);:::;(/uni20D7xN;yN):\\nwhere theyi’s are either +1or1, ﬁnd vectors /uni20D7wand/uni20D7\\x18and a number bwhich\\nminimize1\\n2/parallel.alt1/uni20D7w/parallel.alt12+CN\\n/summation.disp\\ni=1\\x18iCHAPTER 10. SUPPORT VECTOR MACHINES 155\\nFigure 10.15: Soft margin hyperplanes\\nsubject to yi(/uni20D7w⋅/uni20D7xi−b)≥1−\\x18i;fori=1;:::N\\n\\x18i≥0;fori=1;:::;N\\nRemarks\\n1. There are algorithms for solving the reformulated SVM problem given above. The details of\\nthese algorithms are beyond the scope of these notes.\\n2. The hyperplanes given by the equations\\n/uni20D7w⋅/uni20D7xi−b=+1and/uni20D7w⋅/uni20D7xi−b=−1\\nwith the values of /uni20D7wandbobtained as solutions of the reformulated problem, are called the\\nsoft margin hyperplanes for the SVM problem.\\n10.10 Kernel functions\\nIn the context of SVM’s, a kernel function is a function of the form K(/uni20D7x;/uni20D7y), where /uni20D7xand/uni20D7yare\\nn-dimensional vectors, having a special property. These functions are used to obtain SVM-like\\nclassiﬁers for two-class datasets which are not linearly separable.\\n10.10.1 Deﬁnition\\nLet/uni20D7xand/uni20D7ybe arbitrary vectors in the n-dimensional vector space Rn. Let\\x1ebe a mapping from Rn\\nto some vector space. A function K(/uni20D7x;/uni20D7y)is called a kernel function if there is a function \\x1esuch\\nthatK(/uni20D7x;/uni20D7y)=\\x1e(/uni20D7x)⋅\\x1e(/uni20D7y).\\n10.10.2 Examples\\nExample 1\\nLet\\n/uni20D7x=(x1;x2)∈R2\\n/uni20D7y=(y1;y2)∈R2\\nWe deﬁne\\nK(/uni20D7x;/uni20D7y)=(/uni20D7x⋅/uni20D7y)2:CHAPTER 10. SUPPORT VECTOR MACHINES 156\\nWe show that this is a kernel function. To do this, we note that\\nK(/uni20D7x;/uni20D7y)=(/uni20D7x⋅/uni20D7y)2\\n=(x1y1+x2y2)2\\n=x2\\n1y2\\n1+2x1y1x2y2+x2\\n2y2\\n2\\nNow we deﬁne\\n\\x1e(/uni20D7x)=(x2\\n1;√\\n2x1x2;x2\\n2)∈R3\\n\\x1e(/uni20D7y)=(y2\\n1;√\\n2y1y2;y2\\n2)∈R3\\nThen we have\\n\\x1e(/uni20D7x)⋅\\x1e(/uni20D7y)=x2\\n1y2\\n1+(√\\n2x1x2)(√\\n2y1y2)+x2\\n2y2\\n2\\n=x2\\n1y2\\n1+2x1x2y1y2+x2\\n2y2\\n2\\n=K(/uni20D7x;/uni20D7y)\\nThis shows that K(/uni20D7x;/uni20D7y)is indeed a kernel function.\\nExample 2\\nLet\\n/uni20D7x=(x1;x2)∈R2\\n/uni20D7y=(y1;y2)∈R2\\nWe deﬁne\\nK(/uni20D7x;/uni20D7y)=(/uni20D7x⋅/uni20D7y+\\x12)2:\\nWe show that this is a kernel function. To do this, we note that\\nK(/uni20D7x;/uni20D7y)=(/uni20D7x⋅/uni20D7y+\\x12)2\\n=(x1y1+x2y2+\\x12)2\\n=\\x1e(/uni20D7x)⋅\\x1e(/uni20D7y)\\nwhere\\n\\x1e(/uni20D7x)=(x2\\n1;x2\\n2;√\\n2x1x2;√\\n2\\x12x1;√\\n2\\x12x2;√\\n\\x12)∈R6:\\nThis shows that K(/uni20D7x;/uni20D7y)is indeed a kernel function.\\n10.10.3 Some important kernel functions\\nIn the following we assume that /uni20D7x=(x1;x2;:::;xn)and/uni20D7y=(y1;y2;:::;yn).\\n1.Homogeneous polynomial kernel\\nK(/uni20D7x;/uni20D7y)=(/uni20D7x⋅/uni20D7y)d\\nwheredis some positive integer.\\n2.Non-homogeneous polynomial kernel\\nK(/uni20D7x;/uni20D7y)=(/uni20D7x⋅/uni20D7y+\\x12)d\\nwheredis some positive integer and \\x12is a real constant.CHAPTER 10. SUPPORT VECTOR MACHINES 157\\n3.Radial basis function (RBF) kernel\\nK(/uni20D7x;/uni20D7y)=e−/parallel.alt1/uni20D7x−/uni20D7y/parallel.alt12/slash.left2\\x1b2\\nThis is also called the Gaussian radial function kernel.1\\n4.Laplacian kernel function\\nK(/uni20D7x;/uni20D7y)=e−/parallel.alt1/uni20D7x−/uni20D7y/parallel.alt1/slash.left\\x1b\\n5.Hyperbolic tangent kernel function (Sigmoid kernel function)\\nK(/uni20D7x;/uni20D7y)=tanh(\\x0b(/uni20D7x⋅/uni20D7y)+c)\\n10.11 The kernel method (kernel trick)\\n10.11.1 Outline\\n1. Choose an appropriate kernel function K(/uni20D7x;/uni20D7y).\\n2. Formulate and solve the optimization problem obtained by replacing each inner product /uni20D7x⋅/uni20D7y\\nbyK(/uni20D7x;/uni20D7y)in the SVM optimization problem.\\n3. In the formulation of the classiﬁer function for the SVM problem using the inner products of\\nunclassiﬁed data /uni20D7zand input vectors /uni20D7xi, replace each inner product /uni20D7z⋅/uni20D7xiwithK(/uni20D7z;/uni20D7xi)to\\nobtain the new classiﬁer function.\\n10.11.2 Algorithm\\nAlgorithm of the kernel method\\nGiven a two-class linearly separable dataset of Npoints of the form\\n(/uni20D7x1;y1);(/uni20D7x2;y2);:::;(/uni20D7xN;yN);\\nwhere theyi’s are either +1or1and appropriate kernel function K(/uni20D7x;/uni20D7y):\\nStep 1. Find /uni20D7\\x0b=(\\x0b1;\\x0b2;:::;\\x0bN)which maximizes\\nN\\n/summation.disp\\ni=1\\x0bi−1\\n2N\\n/summation.disp\\ni=1;j=1\\x0bi\\x0bjyiyjK(/uni20D7xi;/uni20D7xj)\\nsubject to\\nN\\n/summation.disp\\ni=1\\x0biyi=0\\n\\x0bi>0fori=1;2;:::;N:\\nStep 2. Compute /uni20D7w=∑N\\ni=1\\x0biyi/uni20D7xi.\\nStep 3. Compute b=1\\n2/parenleft.alt1mini∶yi=+1K(/uni20D7w;/uni20D7xi)+maxi∶yi=−1K(/uni20D7w;/uni20D7xi)/parenright.alt1.\\nStep 4. The SVM classiﬁer function is given by f(/uni20D7z)=∑N\\ni=1\\x0biyiK(/uni20D7xi;/uni20D7z)+b:\\n1To represent this kernel as an inner product, we need map \\x1efromRninto an inﬁnite-dimensional vector space. A\\ndiscussion of these ideas is beyond the scope of these notes.CHAPTER 10. SUPPORT VECTOR MACHINES 158\\n10.12 Multiclass SVM’s\\nIn machine learning, the multiclass classiﬁcation is the problem of classifying instances into one of\\nthree or more classes. Classifying instances into one of the two classes is called binary classiﬁcation.\\nSupport vector machines can be constructed only when the dataset has only two class-labels and\\nis linearly separable. We have already discussed a method to extend the concept of SVM’s to the\\ncase where the dataset is not linearly separable. In this section we consider how the SVM’s can be\\nused to obtain classiﬁers when there are more than two class labels. Two methods are generally used\\nto handle such cases known by the names ”One-against-all\" and “one-against-one”.\\n10.12.1 “One-against-all” method\\nTheOne-Against-All (OAA) SVMs were ﬁrst introduced by Vladimir Vapnik in 1995.\\nFigure 10.16: One-against all\\nLet there be pclass labels, say, c1;c2;:::;cp. We construct the following ptwo-class datasets\\nand obtain the corresponding SVM classiﬁers. First, we assign the class labels +1to all instances\\nhaving class label c1and the class label −1to all the remaining instances in the data set. Let f1(/uni20D7x)\\nbe the SVM classiﬁer function for the resulting two-class dataset. Next, we assign the class labels\\n+1to all instances having class label c2and the class label −1to all the remaining instances in the\\ndata set. Let f2(/uni20D7x)be the SVM classiﬁer function for the resulting two-class dataset. We continue\\nlike this and generate SVM classiﬁer functions f3(/uni20D7x),:::,fp(/uni20D7x)\\nTwo criteria have been developed to assign a class label to a test instance /uni20D7z.\\n1. A data point /uni20D7zwould be classiﬁed under a certain class if and only if that class’s SVM accepted\\nit and all other classes’ SVMs rejected it. Thus /uni20D7zwill be assigned ciiffi(/uni20D7z)>0andfj(/uni20D7z)<0\\nfor allj≠i.\\n2./uni20D7zis the assigned the class label ciiffi(/uni20D7z)has the highest value among f1(/uni20D7z);:::;fp(/uni20D7z),\\nregardless of sign.\\nFigure 10.16 illustrates the one-against-all method with three classes.\\n10.12.2 “One-against-one” method\\nIn the one-against-one (OAO) (also called one-vs-one (OVO)) strategy, a SVM classiﬁer is con-\\nstructed for each pair of classes. If there are pdifferent class labels, a total of p(p−1)/slash.left2classiﬁers\\nare constructed. An unknown instance is classiﬁed with the class getting the most votes. Ties are\\nbroken arbitrarily.CHAPTER 10. SUPPORT VECTOR MACHINES 159\\nFigure 10.17: One-against-one\\nFor example, let there be three classes, A,BandC. In the OVO method we construct 3(3−\\n1)/slash.left2=3SVM binary classiﬁers. Now, if /uni20D7zis to be classiﬁed, we apply each of the three classiﬁers\\nto/uni20D7z. Let the three classiﬁers assign the classes A,B,Brespectively to /uni20D7z. Since a label to /uni20D7zis\\nassigned by the majority voting, in this example, we assign the class label of Bto/uni20D7z.\\nOne-vs-one (OVO) strategy is not a particular feature of SVM. Indeed, OVO can be applied to\\nany binary classiﬁer to solve multi-class classiﬁcation problem.\\n10.13 Sample questions\\n(a) Short answer questions\\n1. Deﬁne an hyperplane in an n-dimensional space. What are the hyperplanes in 2-dimensional\\nand3-dimensional spaces?\\n2. Find the distance of the point (1;−2;3)from the hyperplane\\n3x1−4x2+12x3−1=0:\\n3. What is a linearly separable dataset? Give an example. Give an example for a dataset which\\nis not linearly separable.\\n4. What is meant by maximum margin hyperplane?\\n5. Deﬁne the support vector machine of a two-class dataset.\\n6. Deﬁne the support vectors of a two-class dataset.\\n7. What is a kernel function? Give an example.\\n(b) Long answer questions\\n1. State the mathematical formulation of the SVM problem. Give an outline of the method for\\nsolving the problem.\\n2. Explain the signiﬁcance of soft margin hyperplanes and explain how they are computed.\\n3. Show that the function\\nK(/uni20D7x;/uni20D7y)=(/uni20D7x⋅/uni20D7y)3\\nis a kernel function.\\n4. What is meant by kernel trick in context of support vector machines? How is it used to ﬁnd a\\nSVM classiﬁer.CHAPTER 10. SUPPORT VECTOR MACHINES 160\\n5. Given the following dataset, using elementary geometry ﬁnd the maximum margin hyperplane\\nfor the data. Verify the result by ﬁnding the same using the SVM algorithm.\\nExamplex1x2Class label\\n1 2 1 −1\\n2 4 5 +1\\n3 3 6 +1Chapter 11\\nHidden Markov models\\nThis chapter contains a brief introduction to hidden Markov models (HMM’s). The HMM is one\\nof the most important machine learning models in speech and language processing. To deﬁne it\\nproperly, we need to ﬁrst understand the concept of discrete Markov processes. So, we begin the\\nchapter with a description of Markov processes and then discuss HMM’s. The three basic problems\\nassociated with a HMM are stated, but algorithms for their solutions are not given as they are beyond\\nthe scope of these notes.\\n11.1 Discrete Markov processes: Examples\\n11.1.1 Example 1\\nThrough this example we introduce the various elements that constitute a discrete homogeneous\\nMarkov process.\\n1.System and states\\nLet us consider a highly simpliﬁed model of the different states a stock-market is in, in a given\\nweek. We assume that there are only three possible states:\\nS1: Bull market trend\\nS2: Bear market trend\\nS3: Stagnant market trend\\n2.Transition probabilities\\nWeek after week, the stock-market moves from one state to another state. From previous data,\\nit has been estimated that there are certain probabilities associated with these movements.\\nThese probabilities are called transition probabilities.\\n3.Markov assumption\\nWe assume that the following statement (called Markov assumption or Markov property) re-\\ngarding transition probabilities is true:\\n• Let the weeks be counted as 1;2;:::and let an arbitrary week be the t-th week. Then,\\nthe state in week t+1depends only on the state in week t, regardless of the states in\\nthe previous weeks. This corresponds to saying that, given the present state, the future\\nis independent of the past.\\n4.Homogeneity assumption\\nTo simplify the computations, we assume that the following property, called the homogeneity\\nassumption, is also true.\\n161CHAPTER 11. HIDDEN MARKOV MODELS 162\\n• The probability that the stock market is in a particular state in a particular week t+1\\ngiven that it is in a particular state in week t, is independent of t.\\n5.Representation of transition probabilities Let the probability that a bull week is followed\\nby another bull week be 90%, a bear week be 7.5%, and a stagnant week be 2.5%. Similarly,\\nlet the probability that a bear week is followed by another bull week be 15%, bear week be\\n80% and a stagnant week be 5%. Finally, let the probability that a stagnant week be followed\\nby a bull week is 25%, a bear week be 25% and a stagnant week be 50%. The transition\\nprobabilities can be represented in two ways:\\n(a) The states and the state transition probabilities can be represented diagrammatically as\\nin Figure 11.1.\\nFigure 11.1: A state diagram showing state transition probabilities\\n(b) The state transition probabilities can also be represented by a matrix called the state\\ntransition matrix . Let us label the states as “1 =bull”, “2=bear” and “3 =stagnant” and\\nconsider the matrix\\nP=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A30:90 0:075 0:025\\n0:15 0:80 0:05\\n0:25 0:50 0:25/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6\\nIn this matrix, the element in the i-th row,j-th column represents the probability that the\\nmarket in state iis followed by market in state j.\\nNote that in the state transition matrix P, the sum of the elements in every row is 1.\\n6.Initial probabilities\\nThe initial probabilities are the probabilities that the stock-market is in a particular state ini-\\ntially. These are denoted by \\x191;\\x192;\\x193:\\x191is the probability that the stock-market is in bull\\nstate initially; similarly, \\x192and\\x193. the values of these probabilities can be presented as a\\nvector:\\n\\x05=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A3\\x191\\n\\x192\\n\\x193/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A30:5\\n0:3\\n0:2/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6\\n7.The discrete Markov process\\nThe functioning of the stock-markets with the three states S1;S2;S3with the assumption that\\nthe Markov property is true, the transition probabilities given by the matrix Pand the initialCHAPTER 11. HIDDEN MARKOV MODELS 163\\nprobabilities given by the vector \\x05constitute a discrete Markov process. Since we also assume\\nthe homogeneity property for the transition probabilities is true, it is a homogeneous discrete\\nMarkov process.\\nProbabilities for future states\\nConsider the matrix:\\n\\x05TP=/bracketleft.alt10:5 0:3 0:2/bracketright.alt/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A30:90 0:075 0:025\\n0:15 0:80 0:05\\n0:25 0:50 0:25/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6\\n=/bracketleft.alt10:5450 0:3775 0:0775/bracketright.alt\\nThe elements in this row vector represent the probabilities that the stock-market is in the bull state,\\nthe bear state and the stagnant state respectively in the second week.\\nIn general, the elements of the row vector \\x05TPnrepresent the probabilities that the stock-market\\nis in the bull state, the bear state and the stagnant state respectively in the (n+1)-th week.\\n11.1.2 Example 2\\nConsider a simpliﬁed model of weather. We assume that the weather conditions are observed once\\na day at noon and it is recorded as in one of the following states:\\nS1: Rainy\\nS2: Cloudy\\nS3: Sunny\\nAssuming that the Markov property and the homogeneity property are true, we can write the state\\ntransition probability matrix P. Let the matrix be\\nP=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A30:4 0:3 0:3\\n0:2 0:6 0:2\\n0:1 0:1 0:8/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6\\nLet the initial probabilities be\\n\\x05=/bracketleft.alt10:25 0:25 0:50/bracketright.alt\\nThe changes in weather with the three sates S1;S2;S3satisfying the Markov property and the ho-\\nmogeneity property, the transition probability matrix Pand the initial probabilities given by \\x05con-\\nstitute a discrete homogeneous Markov process.\\n11.2 Discrete Markov processes: General case\\nA Markov process is a random process indexed by time, and with the property that the future is\\nindependent of the past, given the present. The time space may be discrete taking the values 1;2;:::\\nor continuous taking any nonnegative real number as a value. In these notes, we consider only\\ndiscrete time Markov processes.\\n1.System and states\\nConsider a system that at any time is in one of Ndistinct states:\\nS1;S2;:::;SN\\nWe denote the state at time tbyqtfort=1;2;:::. So,qt=Simeans that the system is in\\nstateSiat timet.CHAPTER 11. HIDDEN MARKOV MODELS 164\\n2.Transition probabilities\\nAt regularly spaced discrete times, the system moves to a new state with a given probability,\\ndepending on the values of the previous states. These probabilities are called the transition\\nprobabilities.\\n3.Markov assumptions (Markov property)\\nWe assume the following called the Markov assumption or the Markov property:\\n• The state at time t+1depends only on state at time t, regardless of the states in the\\nprevious times. This corresponds to saying that, given the present state, the future is\\nindependent of the past.\\n4.Homogeneity property\\nWe assume that the following property, called the homogeneity property, is true.\\n• We also assume that these transition probabilities are independent of time, that is, the\\nprobabilities P(qt+1=Sj/divides.alt0qt=Si)are constants and do not depend on t. We denote this\\nprobablity by aij:\\naij=P(qt+1=Sj/divides.alt0qt=Si):\\nWe immediately note that\\naij≥0andN\\n/summation.disp\\nj=1aij=1for alli:\\n5.Representation of transition probabilities\\nThe transition probabilities can be represented in two ways:\\n(a) If the number of states is small, the state transition probabilities can be represented\\ndiagrammatically as in Figure 11.1.\\n(b) The state transition probabilities can also be represented by a matrix called the state\\ntransition matrix .\\nA=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A3a11a12::: a 1N\\na21a22::: a 2N\\n/uni22EF\\naN1aN2::: aNN/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6\\nIn this matrix, the element in the i-th row,j-th column represents the probability that the\\nsystem in state Simoves to state Sj. Note that in the state transition matrix A, the sum\\nof the elements in every row is 1.\\n6.Initial probabilities\\nWe deﬁne the initial probabilities \\x19iwhich is the probability that the ﬁrst state in the sequence\\nisSi:\\n\\x19=P(q1=Si):\\nWe also write\\n\\x05=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A3\\x191\\n\\x192\\n/uni22EF\\n\\x19N/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6\\nWe must have\\nN\\n/summation.disp\\ni=1\\x19i=1:CHAPTER 11. HIDDEN MARKOV MODELS 165\\n7.Discrete Markov process\\nA system with the states S1;S2;:::;SNsatisfying the Markov property is called a discrete\\nMarkov process. If it satisﬁes the homogeneity property, then it is called a homogeneous\\ndiscrete Markov process.\\n11.2.1 Probability for an observation sequence\\nObservable Markov model\\nThe discrete Markov process described in Section 11.2 is also called an observable Markov model or\\nobservable discrete Markov process . It is so called because the state of the system at any time tcan\\nbe directly observed. This is in contrast to models where the state of the system cannot be directly\\nobserved. If the state of the system cannot be directly observed the system is called a hidden Markov\\nmodel. Such systems are considered in Section ??.\\nProbability for an observation sequence\\nIn an observable Markov model, the states are observable. At any time twe knowqt, and as the\\nsystem moves from one state to another, we get an observation sequence that is a sequence of states.\\nThe output of the process is the set of states at each instant of time where each state corresponds to\\na physical observable event.\\nLetObe an arbitrary observation sequence of length T. Let us consider a particular observation\\nsequence\\nQ=(q1;q2;:::;qT):\\nNow, given the transition matrix Aand the initial probabilities \\x05we can calculate the probability\\nP(O=Q)as follows.\\nP(O=Q)=P(q1)P(q2/divides.alt0q1)P(q3/divides.alt0q2):::P(qT/divides.alt0qT−1)\\n=\\x19q1aq1q2aq2q3:::aqT−1qT\\nHere,\\x19q1is the probability that the ﬁrst state is q1,aq1q2is the probability of going from q1toq2,\\nand so on. We multiply these probabilities to get the probability of the whole sequence.\\nExample\\nConsider the discrete Markov process described in Section 11.1.1. Let us compute the probability\\nof having a bull week followed by a stagnant week followed by two bear weeks. In this case the\\nobservation sequence is\\nQ=(bull;stagnant;bear;bear)\\n=(S1;S2;S3;S3)\\nThe required probability is\\nP(O=Q)=P(S1)P(S2/divides.alt0S1)P(S3/divides.alt0S2)P(S3/divides.alt0S3)\\n=\\x191a12a23a33\\n=0:5×0:075×0:05×0:25\\n=0:00046875\\n11.2.2 Learning the parameters\\nConsider a homogeneous discrete Markov process with transition matrix Aand initial probability\\nvector \\x05.Aand\\x05are the parameters of the process. The following procedure may be applied to\\nlearn these parameters.CHAPTER 11. HIDDEN MARKOV MODELS 166\\nStep 1. Obtain Kobservation sequences each of length T. Letqtkbe the observed state at time t\\nin thek-th observation sequence.\\nStep 2. Let ^\\x19ibe the estimate of the initial probability \\x19i. Then\\n^\\x19i=number of sequences starting with Si\\ntotal number of sequences:\\nStep 3. Let ^aijbe the estimate of aij. Then\\n^aij=number of transitions from SitoSj\\nnumber of transitions from Si\\nExample\\nLet there be a discrete Markov process with three states S1,S2andS3. Suppose we have the\\nfollowing 10observation sequences each of length 5:\\nO1∶S1S2S1S1S1\\nO2∶S2S1S1S3S1\\nO3∶S3S1S3S2S2\\nO4∶S1S3S3S1S1\\nO5∶S3S2S1S1S3\\nO6∶S3S1S1S2S1\\nO7∶S1S1S2S3S2\\nO8∶S2S3S1S2S2\\nO9∶S3S2S1S1S2\\nO10∶S1S2S2S1S1\\nWe have:\\n^\\x191=number of sequences starting with S1\\ntotal number of sequences=4\\n10\\n^\\x192=number of sequences starting with S2\\ntotal number of sequences=2\\n10\\n^\\x193=number of sequences starting with S3\\ntotal number of sequences=4\\n10\\nTherefor\\n\\x05=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A34/slash.left10\\n2/slash.left10\\n4/slash.left10/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6\\nWe illustrate the computation of aij’s with an example.\\n^a21=number of transitions from S2toS1\\nnumber of transitions from S2=6\\n11\\n^a22=number of transitions from S2toS2\\nnumber of transitions from S2=3\\n11\\n^a23=number of transitions from S2toS3\\nnumber of transitions from S2=2\\n11\\nThe remaining transition probabilities can be estimated in a similar way.\\n^A=/uni23A1/uni23A2/uni23A2/uni23A2/uni23A2/uni23A2/uni23A39/slash.left19 6/slash.left19 4/slash.left19\\n6/slash.left11 3/slash.left11 2/slash.left11\\n5/slash.left10 4/slash.left10 1/slash.left10/uni23A4/uni23A5/uni23A5/uni23A5/uni23A5/uni23A5/uni23A6:CHAPTER 11. HIDDEN MARKOV MODELS 167\\nFigure 11.2: A two-coin model of an HMM\\n11.3 Hidden Markov models\\n11.3.1 Coin tossing example\\nLet us consider the following scenario:\\nConsider a room which is divided into two parts by a curtain through which we cannot see what\\nis happening on the other half of the room. Person A is sitting in one half and person B is sitting\\nin the other half. Person B is doing some coin tossing experiment, but she will not tell person A\\nanything about what she is doing. Person B will only announce the result of each coin ﬂip. Let a\\ntypical sequence of announcements be\\nO=O1O2:::OT\\n=HHTHHTTT :::H (say)\\nwhere as usual Hstands for heads and Tstands for tails. Person A wants to create a mathematical\\nmodel which explains this sequence of observation. Person A suspects that person B is announcing\\nthe results based on the outcomes of some discrete Markov process. If that is true, then the Markov\\nprocess that is happening behind the curtain is hidden from the rest of the world and we are left with\\nahidden Markov process . To verify whether actually a Markov process is happening is a daunting\\ntask. Based on the observations like Oalone, we have to decide on the following:\\n• A Markov process has different states. What should the states in the process correspond to\\nwhat is happening behind the curtain?\\n• How many states should be there?\\n• What should be the initial probabilities?\\n• What should be the transition probabilities?\\nLet us assume that person B is doing something like the following before announcing the outcomes.\\n1. Let person B be in possession of two biased coins (or, three coins, or any number of coins)\\nand she is ﬂipping these coins in some order. When ﬂipping a particular coin, the system is\\nin the state of that coin. So, each of these coins may be identiﬁed as a state and there are two\\nstates, sayS1andS2.\\n2. The outcomes of the ﬂips of the coins are the observations. These observations are represented\\nby the observation symbols “H” (for “head”) and “T” (for “tail”).CHAPTER 11. HIDDEN MARKOV MODELS 168\\n3. After ﬂipping coin, one of the two coins should be ﬂipped next. There must be some deﬁnite\\nprocedure for doing this. The procedure is some random process with deﬁnite probabilities\\nfor selecting the coins. These are the transition probabilities and they deﬁne the transition\\nprobability matrix A.\\n4. Since the coins are biased, there would be deﬁnite probabilities for getting “H” or “T” each\\ntime the coin is ﬂipped. These probabilities are called the observation probabilities.\\n5. There must be some procedure for selecting the ﬁrst coin. This is speciﬁed by the initial\\nprobabilities vector \\x05.\\n11.3.2 The urn and ball model\\nAgain, consider a room which is divided into two parts by a curtain through which we cannot see\\nwhat is happening on the other half of the room. Person A is sitting in one half and person B is\\nsitting in the other half. Person B is doing some experiment, but she will not tell person A anything\\nabout what she is doing. Person B will only announce the result of each experiment. Let a typical\\nsequence of announcements be\\nO=O1O2:::OT\\n=“red”, “green”, “red”, . . . , “blue”\\nPerson A wants to create a mathematical model which explains this sequence of observations.\\nFigure 11.3: An N-state urn and ball model which illustrates the general case of a discrete symbol\\nHMM\\nPerson A suspects that person B is announcing the results based on the outcomes of some discrete\\nMarkov process. If that is true, then the Markov process that is happening behind the curtain is\\nhidden from the rest of the world and we are left with a hidden Markov process .\\nIn this example, let us assume that person A suspects that something like the following is hap-\\npening behind the curtain.\\nThere areNlarge urns behind the curtain. Within each urn there are large number of coloured\\nballs. There are Mdistinct colours of balls. Person B, according to some random process, chooses\\nan initial urn. From this urn a ball is chosen at random and the colour of the ball is announced.\\nThe ball is then replaced in the urn. A new urn is then selected according to some random selection\\nprocess associated with the current urn and the ball selection process is repeated.\\nThis process is a typical example of a hidden Markov process. Note the following:\\n1. Selection of an urn may be made to correspond to a state of the process. Then, there are N\\nstates in the process.CHAPTER 11. HIDDEN MARKOV MODELS 169\\n2. The colours of the balls selected are the observations. The name of the colour may be referred\\nto as the “observation symbol”. Hence, there are Mobservation symbols in the process.\\n3. The random selection process associated with the current urn speciﬁes the transition probabil-\\nities.\\n4. Each urn contains a mixture of balls of different colours. So, corresponding to each urn, there\\nare deﬁnite probabilities for getting balls of different colours. These probabilities are called\\nthe observation probabilities.\\n5. The procedure for selecting the ﬁrst urn provides the initial probabilities.\\n11.3.3 Hidden Markov model (HMM): The general case\\nA hidden Markov model (HMM) is characterized by the following:\\n1. The number of states in the model, say N. Let the states be S1;S2;:::;SN.\\n2. The number of distinct observation symbols, say M. Let the observation symbols be v1;v2;:::;vM.\\n(The observation symbols correspond to the physical outputs of the system.)\\n3. The state transition probabilities speciﬁed by an N×NmatrixA=[aj]:\\naij=P(qt+1=Sj/divides.alt0qt=Si);fori;j=1;2;:::;N:\\nwhereqtis the state at time t.\\n4. The observation symbol probability distributions bj(k)forj=1;:::;N andk=1;:::;M .\\nbj(k)is the probability that, at time t, the outcome is the symbol vkgiven that the system is\\nin stateSj:\\nbj(k)=P(vkatt/divides.alt0qt=Sj):\\nWe denote by BtheN×Mmatrix whose element in the j-th rowk-column isbj(k).\\n5. The initial probabilities \\x05=[\\x19i]:\\n\\x19=P(q1=Si);fori=1;2;:::;N:\\nThe values of NandMare implicitly deﬁned in A,Band\\x05. So, a HMM is completely deﬁned by\\nthe parameter set\\n\\x15=(A;B; \\x05):\\n11.4 Three basic problems of HMMs\\nGiven the general model of HMM, there are three basic problems that must be solved for the model\\nto be useful for real-world applications. These problems are the following:\\nProblem 1. Evaluation problem\\nGiven the observation sequence\\nO=O1O2:::OT;\\nand a HMM model\\n\\x15=(A;B; \\x05)\\nhow do we efﬁciently compute\\nP(O/divides.alt0\\x15);\\nthe probability of the observation sequence Ogiven the model \\x15?CHAPTER 11. HIDDEN MARKOV MODELS 170\\nProblem 2. Finding state sequence problem\\nGiven the observation sequence\\nO=O1O2:::OT;\\nand a HMM model\\n\\x15=(A;B; \\x05)\\nhow do we ﬁnd the the state sequence\\nQ=q1q2:::;qT\\nwhich has the highest probability of generating O; that is, how do we ﬁnd Q/uni22C6that\\nmaximizes the probability P(Q/divides.alt0O;\\x15)?\\nProblem 3. Learning model parameters problem\\nGiven a training set Xobservation sequences, how do we learn the model\\n\\x15=(A;B; \\x05)\\nthat maximizes the probability of generating X; that is, how do we ﬁnd \\x15/uni22C6that maxi-\\nmizes the probability\\nP(X/divides.alt0\\x15):\\n11.4.1 Solutions of the basic problems\\nThe details of the algorithms for solving these problems are beyond the scope of these notes. Prob-\\nlem 1 is solved using the Forwards-Backwards algorithms. Problem 2 is solved by the Viterbi\\nalgorithm and posterior decoding. Finally, Problem 3 is solved by the Baum-Welch algorithm.1\\n11.5 HMM application: Isolated word recognition\\nMost speech-recognition systems are classiﬁed as isolated or continuous. Isolated word recognition\\nrequires a brief pause between each spoken word, whereas continuous speech recognition does not.\\nSpeech-recognition systems can be further classiﬁed as speaker-dependent or speaker-independent.\\nA speaker-dependent system only recognizes speech from one particular speaker’s voice, whereas a\\nspeaker-independent system can recognize speech from anybody.\\nIn this section, we consider in an outline form how HMMs are used in building an isolated word\\nrecogniser .\\n1. Assume that we have a vocabulary Vof words to be recognised.\\n2. For each word in the vocabulary, there is a training set of Koccurrences of each spoken word\\n(spoken by 1 or more talkers) where each occurrence of the word constitute an observation\\nsequence.\\n3. The observations are some appropriate representation of the characteristics of the word. These\\nrepresentations are obtained via some preprocessing of the speech signal like linear predictive\\ncoding (LPC).\\n4. For each word v∈V, we build an HMM, say\\n\\x15v=(Av;Bv;\\x05v):\\nFor this, we have to apply the algorithms for learning an HMM to estimate the parameters\\n(Av;Bv;\\x05v)that maximise the probability of generating the observations in the training set\\nofKoccurrences of the word v.\\n1For a concise presentation of the algorithms, visit http://www.shokhirev.com/\\nnikolai/abc/alg/hmm/hmm.html .CHAPTER 11. HIDDEN MARKOV MODELS 171\\nFigure 11.4: Block diagram of an isolated word HMM recogniser\\n5. Now consider an unknown word vwhich needs to be recognised. The following procedure is\\nused to recognise the word.\\n(a) The speech signal corresponding to the word wis subjected to preprocessing like LPC\\nand converted to the representation used in building the HMMs and the measurement of\\nthe observation sequence O=O1O2:::OTis obtained.\\n(b) The probabilities P(O/divides.alt0\\x15v), for each word v∈Vare calculated.\\n(c) Choose the word vfor whichP(O/divides.alt0\\x15v)is highest:\\nv/uni22C6=arg max\\nv∈VP(O/divides.alt0\\x15v):\\n(d) The word wis recognised as the word v/uni22C6.\\n11.6 Sample questions\\n(a) Short answer questions\\n1. What is the state transition matrix of a discrete Markov process?\\n2. What is the Markov property of a discrete Markov process?\\n3. Consider a Markov process with two states “Rainy” and “Dry” and the transition probabilities\\nas shown in the following diagram.CHAPTER 11. HIDDEN MARKOV MODELS 172\\nRainy Dry 0.3 0.80.7\\n0.2\\nIfP(Rain)=0:4andP(Dry)=0:6compute the probability for the sequence “Rain, Rain,\\nDry, Dry”.\\n(b) Long answer questions\\n1. Describe a discrete Markov process with an example.\\n2. Describe a hidden Markov model.\\n3. Explain how hidden Markov models are used in speech recognition.\\n4. What are the basic problems associated with a hidden Markov model.\\n5. Describe the urn and ball model of a hidden Markov model.\\n6. Describe the coin tossing model of a hidden Markov model.\\n7. Let there be a discrete Markov process with two states S1andS2. Given the following se-\\nquences of observations of these states, estimate the initial probabilities and the transition\\nprobabilities of the process.\\nS1S2; S 2S2; S 1S2; S 2S1; S 1S1; S 2S1; S 1S2; S 1S1:Chapter 12\\nCombining multiple learners\\nIn general there are several algorithms for learning the same task. Though these are generally suc-\\ncessful, no one single algorithm is always the most accurate. Now, we shall discuss models com-\\nposed of multiple learners that complement each other so that by combining them, we attain higher\\naccuracy.\\n12.1 Why combine many learners\\nThere are several reasons why a single learner may not produce accurate results.\\n• Each learning algorithm carries with it a set of assumptions. This leads to error if the assump-\\ntions do not hold. We cannot be fully sure whether the assumptions are true in a particular\\nsituation.\\n• Learning is an ill-posed problem. With ﬁnite data, each algorithm may converge to a different\\nsolution and may fail in certain circumstances.\\n• The performance of a learner may be ﬁne-tuned to get the highest possible accuracy on a\\nvalidation set. But this ﬁne-tuning is a complex task and still there are instances on which\\neven the best learner is not accurate enough.\\n• It has been proved that there is no single learning algorithm that always produces the most\\naccurate output.\\n12.2 Ways to achieve diversity\\nWhen many learning algorithms are combined, the individual algorithms in the collection are called\\nthebase learners of the collection.\\nWhen we generate multiple base-learners, we want them to be reasonably accurate but do not\\nrequire them to be very accurate individually. The base-learners are not chosen for their accuracy,\\nbut for their simplicity. What we care for is the ﬁnal accuracy when the base- learners are combined,\\nrather than the accuracies of the bas-learners we started from.\\nThere are several different ways for selecting the base learners.\\n1.Use different learning algorithms\\nThere may be several learning algorithms for performing a given task. For example, for\\nclassiﬁcation, one may choose the naive Bayes’ algorithm, or the decision tree algorithm or\\neven the SVM algorithm.\\nDifferent algorithms make different assumptions about the data and lead to different results.\\nWhen we decide on a single algorithm, we give emphasis to a single method and ignore all\\nothers. Combining multiple learners based on multiple algorithms, we get better results.\\n173CHAPTER 12. COMBINING MULTIPLE LEARNERS 174\\n2.Use the same algorithm with different hyperparameters\\nIn machine learning, a hyperparameter is a parameter whose value is set before the learning\\nprocess begins. By contrast, the values of other parameters are derived via training.\\nThe number of layers, the number of nodes in each layer and the initial weights are all hyper-\\nparameters in an artiﬁcial neural network. When we train multiple base-learners with different\\nhyperparameter values, we average over it and reduce variance, and therefore error.\\n3.Use different representations of the input object\\nFor example, in speech recognition, to recognize the uttered words, words may be represented\\nby the acoustic input. Words can also be represented by video images of the speaker’s lips as\\nthe words are spoken.\\nDifferent representations make different characteristics explicit allowing better identiﬁcation.\\nIn many applications, there are multiple sources of information, and it is desirable to use all\\nof these data to extract more information and achieve higher accuracy in prediction. We make\\nseparate predictions based on different sources using separate base-learners, then combine\\ntheir predictions.\\n4.Use different training sets to train different base-learners\\n• This can be done by drawing random training sets from the given sample; this is called bagging .\\n• The learners can be trained serially so that instances on which the preceding base-\\nlearners are not accurate are given more emphasis in training later base-learners; ex-\\namples are boosting andcascading .\\n• The partitioning of the training sample can also be done based on locality in the input\\nspace so that each base-learner is trained on instances in a certain local part of the input\\nspace.\\n5.Multiexpert combination methods\\nThese base learners work in parallel. All of them are trained and then given an instance,\\nthey all give their decisions, and a separate combiner computes the ﬁnal decision using their\\npredictions. Examples include voting and its variants.\\n6.Multistage combination methods\\nThese methods use a serial approach where the next base-learner is trained with or tested on\\nonly the instances where the previous base-learners are not accurate enough.\\n12.3 Model combination schemes\\n12.3.1 Voting\\nThis is the simplest procedure for combining the outcomes of several learning algorithms. Let us\\nexamine some special cases of this scheme\\n1.Binary classiﬁcation problem\\nConsider a binary classiﬁcation problem with class labels −1and+1. Let there be Lbase\\nlearners and let xbe a test instance. Each of the base learners will assign a class label to x. If\\nthe class label assigned is +1, we say that the learner votes for +1and that the label +1gets\\na vote. The number of votes obtained by the class labels when the different base learners are\\napplied is counted. In the voting scheme for combining the learners, the label which gets the\\nmajority votes is assigned to x.CHAPTER 12. COMBINING MULTIPLE LEARNERS 175\\n2.Multi-class classiﬁcation problem\\nLet there be nclass labels C1;C2;:::;Cn. Letxbe a test instance and let there be Lbase\\nlearners. Here also, each of the base learners will assign a class label to xand when a class\\nlabel is assigned a label, the label gets a vote. In the voting scheme, the class label which gets\\nthe maximum number of votes is assigned to x.\\n3.Regression\\nConsiderLbase learners for predicting the value of a variable y. Let ^yibe the output predicted\\nby thei-th base learner. The ﬁnal output is computed as\\ny=wi^y1+w2^y2+/uni22EF+wL^yL\\nwherew1;w2;:::;wLare called the weights attached to the outputs of the various base learn-\\ners and they must satisfy the following conditions:\\nwj≥0forj=1;2;:::;L\\nw1+w2+/uni22EF+wL=1:\\nThis is the weighted voting scheme . Insimple voting , we take\\nwi=1\\nLforj=1;2;:::;L:\\n12.3.2 Bagging\\nBagging is a voting method whereby base-learners are made different by training them over slightly\\ndifferent training sets.\\nGeneratingLslightly different samples from a given sample is done by bootstrap, where given a\\ntraining setXof sizeN, we drawNinstances randomly from Xwith replacement (see Section ??).\\nBecause sampling is done with replacement, it is possible that some instances are drawn more than\\nonce and that certain instances are not drawn at all. When this is done to generate LsamplesXj,\\nj=1;:::;L , these samples are similar because they are all drawn from the same original sample,\\nbut they are also slightly different due to chance.\\nThe base-learners are trained with these LsamplesXj. A learning algorithm is an unstable\\nalgorithm if small changes in the training set causes a large difference in the generated learner.\\nBagging, short for bootstrap aggregating, uses bootstrap to generate Ltraining sets, trains Lbase-\\nlearners using an unstable learning procedure and then during testing, takes an average. Bagging\\ncan be used both for classiﬁcation and regression. In the case of regression, to be more robust, one\\ncan take the median instead of the average when combining predictions.\\nAlgorithms such as decision trees and multilayer perceptrons are unstable.\\n12.3.3 Boosting\\nIn bagging, generating complementary base-learners is left to chance and to the unstability of the\\nlearning method. In boosting, we actively try to generate complementary base-learners by training\\nthe next learner on the mistakes of the previous learners. The original boosting algorithm combines\\nthree weak learners to generate a strong learner. A weak learner has error probability less than\\n1/2, which makes it better than random guessing on a two-class problem, and a strong learner has\\narbitrarily small error probability.\\nThe boosting method\\n1. Letd1;d2;d3be three learning algorithms for a particular task. Let a large training set Xbe\\ngiven.\\n2. We randomly divide Xinto three sets, say X1;X2;X3.CHAPTER 12. COMBINING MULTIPLE LEARNERS 176\\n3. We useX1and traind1.\\n4. We then take X2and feed it to d1.\\n5. We take all instances misclassiﬁed by d1and also as many instances on which d1is correct\\nfromX2, and these together form the training set of d2.\\n6. We then take X3and feed it to d1andd2.\\n7. The instances on which d1andd2disagree form the training set of d3.\\n8. During testing, given an instance, we give it to d1andd2if they agree, that is the response;\\notherwise the response of d3is taken as the output.\\nIt has been shown that this overall system has reduced error rate, and the error rate can arbitrar-\\nily be reduced by using such systems recursively. One disadvantage of the system is thaaaaaat it\\nrequires a very large training sample. An improved algorithm known as AdaBoost (short for “adap-\\ntive boosting”), uses the same training set over and over and thus need not be large. AdaBoost can\\nalso combine an arbitrary number of base-learners, not three.\\n12.4 Ensemble learning/uni22C6\\nThe word “ensemble” literally means “a group of things or people acting or taken together as a\\nwhole, especially a group of musicians who regularly play together.”\\nIn machine learning, an ensemble learning method consists of the following two steps:\\n1. Create different models for solving a particular problem using a given data.\\n2. Combine the models created to produce improved results.\\nThe different models may be chosen in many different ways:\\n• The models may be created using appropriate different algorithms like k-NN algorithm, Naive-\\nBayes algorithm, decision tree algorithm, etc.\\n• The models may be created by using the same algorithm but using different splits of the same\\ndataset into training data and test data.\\n• The models may be created by assigning different initial values to the parameters in the algo-\\nrithm as in ANN algorithms.\\nThe models created in the ensemble learning methods are combined in several ways.\\n• Simple majority voting in classiﬁcation problems: Every model makes a prediction (votes)\\nfor each test instance and the ﬁnal output prediction is the one that receives more than half of\\nthe votes.\\n• Weighted majority voting in classiﬁcation problem: In weighted voting we count the predic-\\ntion of the better models multiple times. Finding a reasonable set of weights is up to us.\\n• Simple averaging in prediction problems: In simple averaging method, for every instance of\\ntest dataset, the average predictions are calculated.\\n• Weighted averaging in prediction problems: In this method, the prediction of each model is\\nmultiplied by the weight and then their average is calculated.\\n12.5 Random forest/uni22C6\\nArandom forest is an ensemble learning method where multiple decision trees are constructed and\\nthen they are merged to get a more accurate prediction.CHAPTER 12. COMBINING MULTIPLE LEARNERS 177\\nFigure 12.1: Example of random forest with majority voting\\n12.5.1 Algorithm\\nHere is an outline of the random forest algorithm.\\n1. The random forests algorithm generates many classiﬁcation trees. Each tree is generated as\\nfollows:\\n(a) If the number of examples in the training set is N, take a sample of Nexamples at\\nrandom - but with replacement, from the original data. This sample will be the training\\nset for generating the tree.\\n(b) If there are Minput variables, a number mis speciﬁed such that at each node, mvari-\\nables are selected at random out of the Mand the best split on these mis used to split\\nthe node. The value of mis held constant during the generation of the various trees in\\nthe forest.\\n(c) Each tree is grown to the largest extent possible.\\n2. To classify a new object from an input vector, put the input vector down each of the trees in\\nthe forest. Each tree gives a classiﬁcation, and we say the tree “votes” for that class. The\\nforest chooses the classiﬁcation\\n12.5.2 Strengths and weaknesses\\nStrengths\\nThe following are some of the important strengths of random forests.\\n• It runs efﬁciently on large data bases.\\n• It can handle thousands of input variables without variable deletion.\\n• It gives estimates of what variables are important in the classiﬁcation.\\n• It has an effective method for estimating missing data and maintains accuracy when a large\\nproportion of the data are missing.\\n• Generated forests can be saved for future use on other data.CHAPTER 12. COMBINING MULTIPLE LEARNERS 178\\n• Prototypes are computed that give information about the relation between the variables and\\nthe classiﬁcation.\\n• The capabilities of the above can be extended to unlabeled data, leading to unsupervised\\nclustering, data views and outlier detection.\\n• It offers an experimental method for detecting variable interactions.\\n• Random forest run times are quite fast, and they are able to deal with unbalanced and missing\\ndata.\\n• They can handle binary features, categorical features, numerical features without any need for\\nscaling.\\n• There are lots of excellent, free, and open-source implementations of the random forest algo-\\nrithm. We can ﬁnd a good implementation in almost all major ML libraries and toolkits.\\nWeaknesses\\n• A weakness of random forest algorithms is that when used for regression they cannot predict\\nbeyond the range in the training data, and that they may over-ﬁt data sets that are particularly\\nnoisy.\\n• The sizes of the models created by random forests may be very large. It may take hundreds of\\nmegabytes of memory and may be slow to evaluate.\\n• Random forest models are black boxes that are very hard to interpret.\\n12.6 Sample questions\\n(a) Short answer questions\\n1. Explain the necessity of combining several algorithms for accomplishing a particular task.\\n2. What is a base learner? How do we select base learners?\\n(b) Long answer questions\\n1. Explain the following: (i) voting (ii) bagging (iii) boosting.\\n2. Explain what is meant by random forests.Chapter 13\\nClustering methods\\n13.1 Clustering\\nClustering orcluster analysis is the task of grouping a set of objects in such a way that objects in the\\nsame group (called a cluster) are more similar (in some sense) to each other than to those in other\\ngroups (clusters).\\nClustering is a main task of exploratory data mining and used in many ﬁelds, including machine\\nlearning, pattern recognition, image analysis, information retrieval, bioinformatics, data compres-\\nsion, and computer graphics. It can be achieved by various algorithms that differ signiﬁcantly in\\ntheir notion of what constitutes a cluster and how to efﬁciently ﬁnd them. Popular notions of clus-\\nters include groups with small distances between cluster members, dense areas of the data space,\\netc.\\n13.1.1 Examples of data with natural clusters\\nIn many applications, there will naturally be several groups or clusters in samples.\\n1. Consider the case of optical character recognition: There are two ways of writing the digit 7;\\nthe American writing is ‘7’, whereas the European writing style has a horizontal bar in the\\nmiddle (something like 7 −). In such a case, when the sample contains examples from both\\ncontinents, the sample will contain two clusters or groups one corresponding to the American\\n7 and the other corresponding to the European 7 −.\\n2. In speech recognition, where the same word can be uttered in different ways, due to different\\npronunciation, accent, gender, age, and so forth, there is not a single, universal prototype. In\\na large sample of utterances of a speciﬁc word, All the different ways should be represented\\nin the sample.\\n13.2 k-means clustering\\n13.2.1 Outline\\nThek-means clustering algorithm is one of the simplest unsupervised learning algorithms for solving\\nthe clustering problem.\\nLet it be required to classify a given data set into a certain number of clusters, say, kclusters.\\nWe start by choosing kpoints arbitrarily as the “centres” of the clusters, one for each cluster. We\\nthen associate each of the given data points with the nearest centre. We now take the averages of\\nthe data points associated with a centre and replace the centre with the average, and this is done for\\neach of the centres. We repeat the process until the centres converge to some ﬁxed points. The data\\npoints nearest to the centres form the various clusters in the dataset. Each cluster is represented by\\nthe associated centre.\\n179CHAPTER 13. CLUSTERING METHODS 180\\n13.2.2 Example\\nWe illustrate the algorithm in the case where there are only two variables so that the data points\\nand cluster centres can be geometrically represented by points in a coordinate plane. The distance\\nbetween the points (x1;x2)and(y1;y2)will be calculated using the familiar distance formula of\\nelementary analytical geometry:\\n/radical.alt1\\n(x1−y1)2+(x2−y2)2:\\nProblem\\nUsek-means clustering algorithm to divide the following data into two clusters and also compute\\nthe the representative data points for the clusters.\\nx11 2 2 3 4 5\\nx21 1 3 2 3 5\\nTable 13.1: Data for k-means algorithm example\\nSolution\\nx1x2\\n0 1 2 3 4 512345\\nFigure 13.1: Scatter diagram of data in Table 13.1\\n1. In the problem, the required number of clusters is 2and we take k=2.\\n2. We choose two points arbitrarily as the initial cluster centres. Let us choose arbitrarily (see\\nFigure 13.2)\\n/uni20D7v1=(2;1);/uni20D7v2=(2;3):\\n3. We compute the distances of the given data points from the cluster centers.CHAPTER 13. CLUSTERING METHODS 181\\nx1x2\\n0 1 2 3 4 512345\\n/uni20D7v1/uni20D7v2\\nFigure 13.2: Initial choice of cluster centres and the resulting clusters\\n/uni20D7xiData point Distance Distance Minimum Assigned\\nfrom/uni20D7v1=(2;1)from/uni20D7v2=(2;3) distance center\\n/uni20D7x1(1;1) 1 2 :24 1 /uni20D7v1\\n/uni20D7x2(2;1) 0 2 0 /uni20D7v1\\n/uni20D7x3(2;3) 2 0 0 /uni20D7v2\\n/uni20D7x4(3;2) 1:41 1 :41 0 /uni20D7v1\\n/uni20D7x5(4;3) 2:82 2 2 /uni20D7v2\\n/uni20D7x6(5;5) 5 3 :61 3 :61 /uni20D7v2\\n(The distances of /uni20D7x4from/uni20D7v1and/uni20D7v2are equal. We have assigned /uni20D7v1to/uni20D7x4arbitrarily.)\\nThis divides the data into two clusters as follows (see Figure 13.2):\\nCluster 1: {/uni20D7x1;/uni20D7x2;/uni20D7x4}represented by /uni20D7v1\\nNumber of data points in Cluster 1: c1=3.\\nCluster 2 : {/uni20D7x3;/uni20D7x5;/uni20D7x6}represented by /uni20D7v2\\nNumber of data points in Cluster 2: c2=3.\\n4. The cluster centres are recalculated as follows:\\n/uni20D7v1=1\\nc1(/uni20D7x1+/uni20D7x2+/uni20D7x4)\\n=1\\n3(/uni20D7x1+/uni20D7x2+/uni20D7x4)\\n=(2:00;1:33)\\n/uni20D7v2=1\\nc2(/uni20D7x3+/uni20D7x5+/uni20D7x6)\\n=1\\n3(/uni20D7x3+/uni20D7x5+/uni20D7x6)\\n=(3:67;3:67)\\n5. We compute the distances of the given data points from the new cluster centers.CHAPTER 13. CLUSTERING METHODS 182\\n/uni20D7xiData point Distance Distance Minimum Assigned\\nfrom/uni20D7v1=(2;1)from/uni20D7v2=(2;3) distance center\\n/uni20D7x1(1;1) 1:05 3 :77 1 :05 /uni20D7v1\\n/uni20D7x2(2;1) 0:33 3 :14 0 :33 /uni20D7v1\\n/uni20D7x3(2;3) 1:67 1 :80 1 :67 /uni20D7v1\\n/uni20D7x4(3;2) 1:20 1 :80 1 :20 /uni20D7v1\\n/uni20D7x5(4;3) 2:60 0 :75 0 :75 /uni20D7v2\\n/uni20D7x6(5;5) 4:74 1 :89 1 :89 /uni20D7v2\\nThis divides the data into two clusters as follows (see Figure 13.4):\\nCluster 1 : {/uni20D7x1;/uni20D7x2;/uni20D7x3;/uni20D7x4}represented by /uni20D7v1\\nNumber of data points in Cluster 1: c1=4.\\nCluster 2 : {/uni20D7x5;/uni20D7x6}represented by /uni20D7v2\\nNumber of data points in Cluster 1: c2=2.\\n6. The cluster centres are recalculated as follows:\\n/uni20D7v1==1\\nc1(/uni20D7x1+/uni20D7x2+/uni20D7x3+/uni20D7x4)\\n=1\\n4(/uni20D7x1+/uni20D7x2+/uni20D7x3+/uni20D7x4)\\n=(2:00;1:33)\\n/uni20D7v2=1\\n2(/uni20D7x5+/uni20D7x6)=(3:67;3:67)\\nx1x2\\n0 1 2 3 4 512345\\n/uni20D7v1/uni20D7v2\\nFigure 13.3: Cluster centres after ﬁrst iteration and the corresponding clusters\\n7. We compute the distances of the given data points from the new cluster centers.\\n4.609772 3.905125 2.692582 2.500000 1.118034 1.118034CHAPTER 13. CLUSTERING METHODS 183\\n/uni20D7xiData point Distance Distance Minimum Assigned\\nfrom/uni20D7v1=(2;1)from/uni20D7v2=(2;3) distance center\\n/uni20D7x1(1;1) 1:25 4 :61 1 :25 /uni20D7v1\\n/uni20D7x2(2;1) 0:75 3 :91 0 :75 /uni20D7v1\\n/uni20D7x3(2;3) 1:25 2 :69 1 :25 /uni20D7v1\\n/uni20D7x4(3;2) 1:03 2 :50 1 :03 /uni20D7v1\\n/uni20D7x5(4;3) 2:36 1 :12 1 :12 /uni20D7v2\\n/uni20D7x6(5;5) 4:42 1 :12 1 :12 /uni20D7v2\\nThis divides the data into two clusters as follows (see Figure ??):\\nCluster 1 : {/uni20D7x1;/uni20D7x2;/uni20D7x3;/uni20D7x4}represented by /uni20D7v1\\nNumber of data points in Cluster 1: c1=4.\\nCluster 2 : {/uni20D7x5;/uni20D7x6}represented by /uni20D7v2\\nNumber of data points in Cluster 1: c1=2.\\n8. The cluster centres are recalculated as follows:\\n/uni20D7v1=1\\nc1(/uni20D7x1+/uni20D7x2+/uni20D7x3+/uni20D7x4)\\n=1\\n4(/uni20D7x1+/uni20D7x2+/uni20D7x3+/uni20D7x4)\\n=(2:00;1:75)\\n/uni20D7v2=1\\nc2(/uni20D7x5+/uni20D7x6)\\n=1\\n2(/uni20D7x5+/uni20D7x6)\\n=(4:00;4:50)\\nx1x2\\n0 1 2 3 4 512345\\n/uni20D7v1/uni20D7v2\\nFigure 13.4: New cluster centres and the corresponding clusters\\n9. This divides the data into two clusters as follows (see Figure ??):\\nCluster 1 : {/uni20D7x1;/uni20D7x2;/uni20D7x3;/uni20D7x4}represented by /uni20D7v1\\nCluster 2 : {/uni20D7x5;/uni20D7x6}represented by /uni20D7v2CHAPTER 13. CLUSTERING METHODS 184\\n10. The cluster centres are recalculated as follows:\\n/uni20D7v1=1\\n4(/uni20D7x1+/uni20D7x2+/uni20D7x3+/uni20D7x4)=(2:00;1:75)\\n/uni20D7v2=1\\n2(/uni20D7x5+/uni20D7x6)=(4:00;4:50)\\nWe note that these are identical to the cluster centres calculated in Step 8. So there will be no\\nreassignment of data points to different clusters and hence the computations are stopped here.\\n11. Conclusion: The kmeans clustering algorithm with k=2applied to the dataset in Table 13.1\\nyields the following clusters and the associated cluster centres:\\nCluster 1 : {/uni20D7x1;/uni20D7x2;/uni20D7x3;/uni20D7x4}represented by /uni20D7v1=(2:00;1:75)\\nCluster 2 : {/uni20D7x5;/uni20D7x6}represented by /uni20D7v2=(2:00;4:75)\\n13.2.3 The algorithm\\nNotations\\nWe assume that each data point is a n-dimensional vector:\\n/uni20D7x=(x1;x2;:::;xn):\\nThe distance between two data points\\n/uni20D7x=(x1;x2;:::;xn)\\nand\\n/uni20D7y=(y1;y2;:::;xn)\\nis deﬁned as\\n/divides.alt0/divides.alt0/uni20D7x−/uni20D7y/divides.alt0/divides.alt0=/radical.alt1\\n(x1−y1)2+/uni22EF(xn−yn)2:\\nLetX={/uni20D7x1;:::;/uni20D7xN}be the set of data points, V={/uni20D7v1;:::;/uni20D7vk}be the set of centres and cifor\\ni=1;:::;k be the number of data points in the i-th cluster\\nBasic idea\\nWhat the algorithm aims to achieve is to ﬁnd a partition the set Xintokmutually disjoint subsets\\nS={S1;S2;:::;Sk}and a set of data points Vwhich minimizes the following within-cluster sum\\nof errors:\\nk\\n/summation.disp\\ni=1/summation.disp\\n/uni20D7x∈Si/divides.alt0/divides.alt0/uni20D7x−/uni20D7vi/divides.alt0/divides.alt02\\nAlgorithm\\nStep 1. Randomly select kcluster centers /uni20D7v1;:::;/uni20D7vk.\\nStep 2. Calculate the distance between each data point /uni20D7xiand each cluster center /uni20D7vj.\\nStep 3. For each j=1;2;:::;N , assign the data point /uni20D7xjto the cluster center /uni20D7vifor which the\\ndistance /divides.alt0/divides.alt0/uni20D7xj−/uni20D7vi/divides.alt0/divides.alt0is minimum. Let /uni20D7xi1,/uni20D7xi2,:::,/uni20D7xicibe the data points assigned to /uni20D7vi.\\nStep 4. Recalculate the cluster centres using\\n/uni20D7vi=1\\nci(/uni20D7xi1+/uni22EF+/uni20D7xici); i=1;2;:::;k:\\nStep 5. Recalculate the distance between each data point and newly obtained cluster centers.\\nStep 6. If no data point was reassigned then stop. Otherwise repeat from Step 3.CHAPTER 13. CLUSTERING METHODS 185\\nSome methods for initialisation\\nThe following are some of the methods for choosing the initial vi’s.\\n• Randomly take some kdata points as the initial vi’s.\\n• Calculate the mean of all data and add small random vectors to the mean to get the kinitial\\nvi’s.\\n• Calculate the principal component, divide its range into kequal intervals, partition the data\\nintokgroups, and then take the means of these groups as the initial centres.\\n13.2.4 Disadvantages\\nEven though the k-means algorithm is fast, robust and easy to understand, there are several disad-\\nvantages to the algorithm.\\n• The learning algorithm requires apriori speciﬁcation of the number of cluster centers.\\n• The ﬁnal cluster centres depend on the initial vi’s.\\n• With different representation of data we get different results (data represented in form of\\ncartesian co-ordinates and polar co-ordinates will give different results).\\n• Euclidean distance measures can unequally weight underlying factors.\\n• The learning algorithm provides the local optima of the squared error function.\\n• Randomly choosing of the initial cluster centres may not lead to a fruitful result.\\n• The algorithm cannot be applied to categorical data.\\n13.2.5 Application: Image segmentation and compression\\nImage segmentation\\nThe goal of segmentation is to partition an image into regions each of which has a reasonably\\nhomogeneous visual appearance or which corresponds to objects or parts of objects. Each pixel in\\nan image is a point in a 3-dimensional space comprising the intensities of the red, blue, and green\\nchannels. A segmentation algorithm simply treats each pixel in the image as a separate data point.\\nFor any value of k, each pixel is replaced by the pixel vector with the (R;G;B )intensity triplet\\ngiven by the centre \\x16kto which that pixel has been assigned. For a given value of k, the algorithm\\nis representing the image using a palette of only kcolours. It should be emphasized that this use of\\nk-means is a very crude approach to image segmentation. The image segmentation problem is in\\ngeneral extremely difﬁcult.\\nData compression\\nWe can also the clustering algorithm to perform data compression. There are two types of data\\ncompression: lossless data compression , in which the goal is to be able to reconstruct the original\\ndata exactly from the compressed representation, and lossy data compression , in which we accept\\nsome errors in the reconstruction in return for higher levels of compression than can be achieved in\\nthe lossless case.\\nWe can apply the k-means algorithm to the problem of lossy data compression as follows. For\\neach of theNdata points, we store only the identity of the cluster to which it is assigned. We also\\nstore the values of the kcluster centres \\x16k, which requires much less data, provided we choose\\nkmuch smaller than N. Each data point is then approximated by its nearest centre \\x16k. New data\\npoints can similarly be compressed by ﬁrst ﬁnding the nearest \\x16kand then storing the label kinstead\\nof the original data vector. This framework is often called vector quantization , and the vectors Îij \\x16k\\nare called code-book vectors .CHAPTER 13. CLUSTERING METHODS 186\\n13.3 Multi-modal distributions\\n13.3.1 Deﬁnitions\\n1. In statistics, a unimodal distribution is a continuous probability distribution with only one\\nmode (or “peak”).\\nA random variable having the normal distribution is a unimodal distribution. Similarly, the\\nt-distribution and the chi-squared distribution are also unimodal distributions.\\nUnimodal Bimodal Multimodal\\nFigure 13.5: Probability distributions\\n2. A bimodal distribution is a continuous probability distribution with two different modes. The\\nmodes appear as distinct peaks in the graph of the probability density function.\\n3. A multimodal distribution is a continuous probability distribution with two or more modes.\\n13.4 Mixture of normal distributions\\n13.4.1 Bimodal mixture\\nConsider the following functions which are probability density functions of normally distributed\\nrandom variables.\\nf1(x)=1\\n\\x1b1√\\n2\\x19e−(x−\\x161)2\\n2\\x1b2\\n1 (13.1)\\nf2(x)=1\\n\\x1b2√\\n2\\x19e−(x−\\x162)2\\n2\\x1b2\\n2 (13.2)\\nNow consider the following function:\\nf(x)=\\x191f1(x)+\\x192f2(x) (13.3)\\nwhere\\x191and\\x192are some constants satisfying the relation\\n\\x191+\\x192=1: (13.4)\\nIt can be shown that the function given in Eq.(13.3) together with Eq.(13.4) deﬁnes a probability\\ndensity function. It can also be shown that the graph of this function has two peaks. Hence this\\nfunction deﬁnes a bimodal distribution. This distribution is called a mixture of the normal distribu-\\ntions deﬁned by Eqs.(13.1) and (13.2). We may mix more than two normal distributions.CHAPTER 13. CLUSTERING METHODS 187\\n13.4.2 Deﬁnition\\nConsider the following kprobability density functions:\\nfi(x)=1\\n\\x1bi√\\n2\\x19e−(x−\\x16i)2\\n2\\x1b2\\ni; i=1;2;:::;k: (13.5)\\nLet\\x191;\\x192;:::;\\x19kbe constants such that\\n\\x19i≥0; i=1;2;:::;k (13.6)\\n\\x191+\\x192+/uni22EF+\\x19k=1: (13.7)\\nThen the random variable Xwhose probability density function is\\nf(x)=f1(x)+f2(x)+/uni22EF+fk(x); (13.8)\\nis said to be a mixture of the knormal distributions having the probability density functions deﬁned\\nin Eq.(13.5).\\nA natural example\\nAs a natural example for such mixtures of normal populations, we consider the probability distribu-\\ntion of heights of people in a region. This is a mixture of two normal distributions: the distribution\\nof heights of males and the distribution of heights of females. Given only the height data and not\\nthe gender assignments for each data point, the distribution of all heights would follow the weighted\\nsum of two normal distributions.\\n13.4.3 Example for mixture of two normal distributions\\nData and histogram\\nConsider the 100 observations of some attribute Xgiven in Table 13.2.\\n[1] 5.39 1.30 2.95 2.16 2.37 2.33 4.76 2.99 1.71 2.41\\n[11] 2.71 2.79 0.54 1.37 5.16 1.22 1.58 4.34 3.83 3.44\\n[21] 3.68 5.03 0.92 2.57 1.97 2.17 5.02 2.73 1.63 3.09\\n[31] 4.05 3.76 3.13 6.50 5.10 3.62 3.14 2.36 2.73 4.08\\n[41] 3.28 2.28 1.52 3.86 2.10 0.86 2.94 2.18 3.39 2.55\\n[51] 3.23 3.30 2.16 3.86 1.92 2.55 4.33 0.86 2.68 2.24\\n[61] 2.82 3.63 2.84 3.82 2.49 3.25 2.39 3.18 6.35 4.16\\n[71] 6.68 5.26 8.00 6.27 7.98 6.50 6.56 8.50 7.48 6.42\\n[81] 5.99 7.44 6.96 7.10 8.48 6.99 7.29 6.87 6.71 7.99\\n[91] 8.19 8.28 6.98 7.43 8.33 5.65 8.96 7.36 5.24 7.30\\nTable 13.2: A set of 100 observations of a numeric attribute X\\nTo make some sense of this set of observations, let us construct the frequency table for the data\\nas in Table 13.3.\\nRange 0-1 1-2 2-3 3-4 4-5 5-6 6-7 7 -8 8-9 9-10\\nFrequency 4 9 26 18 6 9 12 9 7 0\\nRelative\\nfrequency 0.04 0.09 0.26 0.18 0.06 0.09 0.12 0.09 0.07 0.00\\nTable 13.3: Frequency table of data in Table 13.2CHAPTER 13. CLUSTERING METHODS 188\\nFigure 13.6 shows the histogram of the relative frequencies. Notice that the histogram has two\\n“peaks”, one near x=2:5and one near x=6:5. So, the graph of the probability density function of\\nthe attribute Xmust have two peaks. Recall that the graph of the probability density function of a\\nrandom variable having the normal distribution has only one peak.\\nProbability distribution\\nThe data in Table 13.2 was generated using the R programming language. It is a true “mixture” of\\nthe values two normally distributed random variables. 70% of the observations are random values\\nof a normally distributed random variable with \\x161=3and\\x1b1=1:20and 30% of the observations\\nare values of a normally distributed random variable with \\x162=7and\\x1b2=0:87. The weight for the\\nﬁrst normal distribution is \\x191=70%=0:7and that for the second distribution is \\x192=30%=0:3.\\nThe probability density function for the mixed distribution is\\nf(x)=0:7×1\\n1:20√\\n2\\x19e−(x−3)2/slash.left(2×1:202)+0:3×1\\n0:87√\\n2\\x19e−(x−7)2/slash.left(2×0:872): (13.9)\\nFigure 13.6 also shows the curve deﬁned by Eq.(13.9) superimposed on the histogram of the relative\\nfrequency distribution.\\nFigure 13.6: Graph of pdf deﬁned by Eq.(13.9) superimposed on the histogram of the data in Table\\n13.3\\n13.5 Mixtures in terms of latent variables\\nConsider the mixture of knormal distributions deﬁned by Eqs.(13.5) – (13.8).\\nLet us deﬁne a k-dimensional random variable\\n/uni20D7Z=(z1;z2;:::;zk)CHAPTER 13. CLUSTERING METHODS 189\\nwhere eachz1is either 0or1and a 1appears only at one place; that is,\\nzi∈{0;1}andz1+z2+/uni22EF+zk=0:\\nWe also assume that\\nP(zk=1)=\\x19k:\\nThe probability function of /uni20D7Zcan be written in the form\\nP(/uni20D7Z)=\\x19z1\\n1\\x19z2\\n2:::\\x19zk\\nk:\\nNow, suppose we have a set of observations {x1;x2;:::;xN}. Suppose that, in some way, we\\ncan associate a value of the random variable /uni20D7Z, say/uni20D7Zi, with each value xiand think of the given set\\nof observations as a set of ordered pairs\\n{(x1;/uni20D7Z1);(x2;/uni20D7Z2);:::;(xN;/uni20D7ZN)}:\\nHere, only the xi-s are known; the /uni20D7Zi-s are unknown. Let us further assume that the conditional\\nprobability distribution p(x/divides.alt0/uni20D7Z)be given by\\np(x/divides.alt0/uni20D7Z)=[f1(x)]z1×/uni22EF×[fk(x)]zk:\\nThen the marginal distribution of xis given by\\np(x)=/summation.disp\\n/uni20D7Zp(/uni20D7Z)P(x/divides.alt0/uni20D7Z)\\n=\\x191f1(x)+/uni22EF+\\x19kfk(x): (13.10)\\nThe right hand side of Eq.(13.10) is the probability density function of a mixture of knormal distri-\\nbutions with weights \\x191;:::;\\x19k.\\nThus, a mixture of normal distributions is the marginal distribution of a bivariate distribution\\n(x;/uni20D7Z)where/uni20D7Zis an unobserved or latent variable.\\n13.6 Expectation-maximisation algorithm\\nThe maximum likelihood estimation method (MLE) is a method for estimating the parameters of a\\nstatistical model, given observations (see Section 6.5 for details). The method attempts to ﬁnd the\\nparameter values that maximize the likelihood function, or equivalently the log-likelihood function,\\ngiven the observations.\\nTheexpectation-maximisation algorithm (sometimes abbreviated as the EM algorithm ) is used\\nto ﬁnd maximum likelihood estimates of the parameters of a statistical model in cases where the\\nequations cannot be solved directly. These models generally involve latent or unobserved variables\\nin addition to unknown parameters and known data observations. For example, a Gaussian mixture\\nmodel can be described by assuming that each observed data point has a corresponding unobserved\\ndata point, or latent variable, specifying the mixture component to which each data point belongs.\\nThe EM Algorithm is not really an algorithm. Rather it is a general procedure to create algo-\\nrithms for speciﬁc MLE problems. The complete details of this general procedure are beyond the\\nscope of this book. However, we present below a minimal outline of the algorithm\\nOutline of EM algorithm\\nStep 1. Initialise the parameters \\x12to be estimated.\\nStep 2. Expectation step (E-step)\\nTake the expected value of the complete data given the observation and the current param-\\neter estimate, say, ^\\x12j. This is a function of \\x12and^\\x12j, say,Q(\\x12;^\\x12j).\\nStep 3. Maximization step (M-step)\\nFind the values \\x12that maximizes the function Q(\\x12;^\\x12j).\\nStep 4. Repeat Steps 1 and 2 until the parameter values or the likelihood function converge.CHAPTER 13. CLUSTERING METHODS 190\\n13.7 The EM algorithm for Gaussian mixtures\\nIn the case of Gaussian mixture problems, because of the nature of the function, ﬁnding a maximum\\nlikelihood estimate by taking the derivatives of the log-likelihood function with respect to all the\\nparameters and simultaneously solving the resulting equations is nearly impossible. So we apply the\\nEM algorithm to solve the problem.\\nAs already indicated, the EM algorithm is a general procedure for estimating the parameters\\nin a statistical model. This algorithm can be adapted to develop an algorithm for estimating the\\nparameters in a Gaussian mixture model. The adapted EM algorithm has been explained below.\\n(The details of how the EM algorithm can be adapted to estimate the parameters in a Gaussian\\nmixture model are also beyond the scope of this book. For details on these matters, one may refer to\\n[1]).\\nProblem\\nSuppose we are given a set of Nobservations\\n{x1;x2;:::;xN}\\nof a numeric variable X. LetXbe a mix of knormal distributions and let the probability density\\nfunction ofXbe\\nf(x)=\\x191f1(x)+/uni22EF+\\x19kfk(x)\\nwhere\\n\\x19i≥0; i=1;2;:::;k\\n\\x19i+/uni22EF+\\x19k=1\\nfi(x)=1\\n\\x1bi√\\n2\\x19e−(x−\\x16i)2\\n2\\x1b2\\ni; i=1;2;:::;k:\\nEstimate the parameters \\x161;:::;\\x16k,\\x1b1;:::;\\x1bkand\\x191:::;\\x19k.\\nLog-likelihood function\\nLet\\x12denote the set of parameters \\x16i;\\x1bi;\\x19i(i=1;:::;k). The log-likelihood function for the above\\nproblem is given below:\\nlogL(\\x12)=logf(x1)+/uni22EF+ logf(xN)\\n=N\\n/summation.disp\\ni=1log/uni239B\\n/uni239D\\x191\\n\\x1b1√\\n2\\x19e−(xi−\\x161)2\\n2\\x1b2\\n1+/uni22EF+\\x19k\\n\\x1bk√\\n2\\x19e−(xi−\\x16k)2\\n2\\x1b2\\nk/uni239E\\n/uni23A0(13.11)\\nThe algorithm\\nStep 1. Initialise the means \\x16i’s, the variances \\x1b2\\ni’s and the mixing coefﬁcients \\x19i’s.\\nStep 2. Calculate the following for n=1;:::;N andi=1;:::;k :\\n\\rin=\\x19ifi(xn)\\n\\x191f1(xn)+/uni22EF+\\x19kfk(xn)\\nNi=\\ri1+/uni22EF+\\riN\\nStep 3. Recalculate the parameters using the following:\\n\\x16(new)\\ni=1\\nNi(\\ri1x1+/uni22EF\\riNxN)CHAPTER 13. CLUSTERING METHODS 191\\n\\x1b2(new)\\ni=1\\nNi/parenleft.alt2\\ri1(x1−\\x16(new)\\ni)2+/uni22EF+\\riN(x1−\\x16(new)\\ni)2/parenright.alt2\\n\\x19(new)\\ni=Ni\\nN\\nStep 4. Evaluate the log-likelihood function given in Eq.(13.11) and check for convergence of ei-\\nther the parameters or the log-likelihood function. If the convergence criterion is not satis-\\nﬁed, return to Step 2.\\n13.8 Hierarchical clustering\\nHierarchical clustering (also called hierarchical cluster analysis or HCA) is a method of cluster\\nanalysis which seeks to build a hierarchy of clusters (or groups) in a given dataset. The hierarchical\\nclustering produces clusters in which the clusters at each level of the hierarchy are created by merg-\\ning clusters at the next lower level. At the lowest level, each cluster contains a single observation.\\nAt the highest level there is only one cluster containing all of the data.\\nThe decision regarding whether two clusters are to be merged or not is taken based on the mea-\\nsure of dissimilarity between the clusters. The distance between two clusters is usually taken as the\\nmeasure of dissimilarity between the clusters.\\nIn Section ??, we shall see various methods for measuring the distance between two clusters.\\n13.8.1 Dendrograms\\nHierarchical clustering can be represented by a rooted binary tree. The nodes of the trees represent\\ngroups or clusters. The root node represents the entire data set. The terminal nodes each represent\\none of the individual observations (singleton clusters). Each nonterminal node has two daughter\\nnodes.\\nThe distance between merged clusters is monotone increasing with the level of the merger. The\\nheight of each node above the level of the terminal nodes in the tree is proportional to the value of\\nthe distance between its two daughters (see Figure 13.9).\\nAdendrogram is a tree diagram used to illustrate the arrangement of the clusters produced by\\nhierarchical clustering.\\nThe dendrogram may be drawn with the root node at the top and the branches growing vertically\\ndownwards (see Figure 13.8(a)). It may also be drawn with the root node at the left and the branches\\ngrowing horizontally rightwards (see Figure 13.8(b)). In some contexts, the opposite directions may\\nalso be more appropriate.\\nDendrograms are commonly used in computational biology to illustrate the clustering of genes\\nor samples.\\nExample\\nFigure 13.7 is a dendrogram of the dataset {a;b;c;d;e }. Note that the root node represents the en-\\ntire dataset and the terminal nodes represent the individual observations. However, the dendrograms\\nare presented in a simpliﬁed format in which only the terminal nodes (that is, the nodes represent-\\ning the singleton clusters) are explicitly displayed. Figure 13.8 shows the simpliﬁed format of the\\ndendrogram in Figure 13.7.\\nFigure 13.9 shows the distances of the clusters at the various levels. Note that the clusters are at\\n4 levels. The distance between the clusters {a}and{b}is 15, between {c}and{d}is 7.5, between\\n{c;d}and{e}is 15 and between {a;b}and{c;d;e}is 25.\\n13.8.2 Methods for hierarchical clustering\\nThere are two methods for the hierarchical clustering of a dataset. These are known as the agglom-\\nerative method (or the bottom-up method) and the divisive method (or, the top-down method).CHAPTER 13. CLUSTERING METHODS 192\\na bcdea;b\\nc;dc;d;ea;b;c;d;e\\nFigure 13.7: A dendrogram of the dataset {a;b;c;d;e }\\nabcde abcde\\n(a) (b)\\nFigure 13.8: Different ways of drawing dendrogram\\nDistance\\n0510152025\\nabcdeLevel 1Level 2Level 3Level 4\\nFigure 13.9: A dendrogram of the dataset {a;b;c;d;e }showing the distances (heights) of the clus-\\nters at different levels\\nAgglomerative method\\nIn the agglomerative we start at the bottom and at each level recursively merge a selected pair of\\nclusters into a single cluster. This produces a grouping at the next higher level with one less cluster.\\nIf there areNobservations in the dataset, there will be N−1levels in the hierarchy. The pair chosen\\nfor merging consist of the two groups with the smallest “intergroup dissimilarity”.\\nFor example, the hierarchical clustering shown in Figure 13.7 can be constructed by the agglom-\\nerative method as shown in Figure 13.10. Each nonterminal node has two daughter nodes. The\\ndaughters represent the two groups that were merged to form the parent.CHAPTER 13. CLUSTERING METHODS 193\\na bcde\\nStep 1\\na bcdea;b\\nStep 2\\na bcdea;b c;d\\nStep 3\\na bcdea;b\\nc;dc;d;e\\nStep 4\\na bcdea;b\\nc;dc;d;ea;b;c;d;e\\nStep 5\\nFigure 13.10: Hierarchical clustering using agglomerative methodCHAPTER 13. CLUSTERING METHODS 194\\nDivisive method\\nThe divisive method starts at the top and at each level recursively split one of the existing clusters at\\nthat level into two new clusters. If there are Nobservations in the dataset, there the divisive method\\nalso will produce N−1levels in the hierarchy. The split is chosen to produce two new groups with\\nthe largest “between-group dissimilarity”.\\nFor example, the hierarchical clustering shown in Figure 13.7 can be constructed by the divi-\\nsive method as shown in Figure 13.11. Each nonterminal node has two daughter nodes. The two\\ndaughters represent the two groups resulting from the split of the parent.\\n13.9 Measures of dissimilarity\\nIn order to decide which clusters should be combined (for agglomerative), or where a cluster should\\nbe split (for divisive), a measure of dissimilarity between sets of observations is required. In most\\nmethods of hierarchical clustering, the dissimilarity between two groups of observations is measured\\nby using an appropriate measure of distance between the groups of observations. The distance\\nbetween two groups of observations is deﬁned in terms of the distance between two observations.\\nThere are several ways in which the distance between two observations can be deﬁned and also there\\nare also several ways in which the distance between two groups of observations can be deﬁned.\\n13.9.1 Measures of distance between data points\\nNumeric data\\nWe assume that each observation or data point is a n-dimensional vector. Let /uni20D7x=(x1;:::;xn)\\nand/uni20D7y=(y1;:::;yn)be two observations. Then the following are the commonly used measures of\\ndistances in the hierarchical clustering of numeric data.\\nName Formula\\nEuclidean distance /divides.alt0/divides.alt0/uni20D7x−/uni20D7y/divides.alt0/divides.alt02=/radical.alt1\\n(x1−y1)2+/uni22EF+(xn−yn)2\\nSquared Euclidean distance /divides.alt0/divides.alt0/uni20D7x−/uni20D7y/divides.alt0/divides.alt02\\n2=(x1−y1)2+/uni22EF+(xn−yn)2\\nManhattan distance /divides.alt0/divides.alt0/uni20D7x−/uni20D7y/divides.alt0/divides.alt01=/divides.alt0x1−y1/divides.alt0+/uni22EF+/divides.alt0xn−yn/divides.alt0\\nMaximum distance /divides.alt0/divides.alt0/uni20D7x−/uni20D7y/divides.alt0/divides.alt0∞=max{/divides.alt0x1−y1/divides.alt0;:::;/divides.alt0xn−yn/divides.alt0}\\nNon-numeric data\\nFor text or other non-numeric data, metrics such as the Levenshtein distance are often used.\\nTheLevenshtein distance is a measure of the ”distance” between two words. The Levenshtein\\ndistance between two words is the minimum number of single-character edits (insertions, deletions\\nor substitutions) required to change one word into the other.\\nFor example, the Levenshtein distance between “kitten” and “sitting” is 3, since the following\\nthree edits change one into the other, and there is no way to do it with fewer than three edits:\\nkitten→sitten (substitution of “s” for “k”)\\nsitten→sittin (substitution of “i” for “e”)\\nsittin→sitting (insertion of‘g” at the end)\\n13.9.2 Measures of distance between groups of data points\\nLetAandBbe two groups of observations and let xandybe arbitrary data points in AandB\\nrespectively. Suppose we have chosen some formula, say Euclidean distance formula, to measure\\nthe distance between data points. Let d(x;y)denote the distance between xandy. We denote byCHAPTER 13. CLUSTERING METHODS 195\\na;b;c;d;e\\nStep 1\\na;b;c;d;e\\na;b c;d;e\\nStep 2\\na ba;b;c;d;e\\na;b c;d;e\\nStep 3\\na b ea;b;c;d;e\\na;b c;d;e\\nc;d\\nStep 4\\na bcdea;b\\nc;dc;d;ea;b;c;d;e\\nStep 5\\nFigure 13.11: Hierarchical clustering using divisive methodCHAPTER 13. CLUSTERING METHODS 196\\nd(A;B)the distance between the groups AandB. The following are some of the different methods\\nin whichd(A;B)is deﬁned.\\n1.d(A;B)=max{d(x;y)∶x∈A;y∈B}.\\nAgglomerative hierarchical clustering using this measure of dissimilarity is known as complete-\\nlinkage clustering . The method is also known as farthest neighbour clustering .\\na\\nb cd\\ne\\nAB\\nFigure 13.12: Length of the solid line “ ae” ismax{d(x;y)∶x∈A;y∈B}\\n2.d(A;B)=min{d(x;y)∶x∈A;y∈B}.\\nAgglomerative hierarchical clustering using this measure of dissimilarity is known as single-\\nlinkage clustering . The method is also known as nearest neighbour clustering .\\na\\nb cd\\ne\\nAB\\nFigure 13.13: Length of the solid line “ bc” ismin{d(x;y)∶x∈A;y∈B}\\n3.d(A;B)=1\\n/divides.alt0A/divides.alt0/divides.alt0B/divides.alt0/summation.disp\\nx∈A;y∈Bd(x;y)where/divides.alt0A/divides.alt0,/divides.alt0B/divides.alt0are respectively the number of elements in\\nAandB.\\nAgglomerative hierarchical clustering using this measure of dissimilarity is known as mean\\nor average linkage clustering . It is also known as UPGMA (Unweighted Pair Group Method\\nwith Arithmetic Mean).\\n13.10 Algorithm for agglomerative hierarchical clustering\\nGiven a set of Nitems to be clustered and an N×Ndistance matrix, required to construct a\\nhierarchical clustering of the data using the agglomerative method.\\nStep 1. Start by assigning each item to its own cluster, so that we have Nclusters, each containing\\njust one item. Let the distances between the clusters equal the distances between the items\\nthey contain.CHAPTER 13. CLUSTERING METHODS 197\\nStep 2. Find the closest pair of clusters and merge them into a single cluster, so that now we have\\none less cluster.\\nStep 3. Compute distances between the new cluster and each of the old clusters.\\nStep 4. Repeat Steps 2 and 3 until all items are clustered into a single cluster of size N.\\n13.10.1 Example\\nProblem 1\\nGiven the dataset {a;b;c;d;e }and the following distance matrix, construct a dendrogram by complete-\\nlinkage hierarchical clustering using the agglomerative method.\\na b c d e\\na 0 9 3 6 11\\nb 9 0 7 5 10\\nc 3 7 0 9 2\\nd 6 5 9 0 8\\ne11 10 2 8 0\\nTable 13.4: Example for distance matrix\\nSolution\\nThe complete-linkage clustering uses the “maximum formula”, that is, the following formula to\\ncompute the distance between two clusters AandB:\\nd(A;B)=max{d(x;y)∶x∈A;y∈B}\\n1. Dataset : {a;b;c;d;e }.\\nInitial clustering (singleton sets) C1:{a},{b},{c},{d},{e}.\\n2. The following table gives the distances between the various clusters in C1:\\n{a} {b} {c} {d} {e}\\n{a} 0 9 3 6 11\\n{b} 9 0 7 5 10\\n{c} 3 7 0 9 2\\n{d} 6 5 9 0 8\\n{e} 11 10 2 8 0\\nIn the above table, the minimum distance is the distance between the clusters {c}and{e}.\\nAlso\\nd({c};{e})=2:\\nWe merge {c}and{e}to form the cluster {c;e}.\\nThe new set of clusters C2:{a},{b},{d},{c;e}.\\n3. Let us compute the distance of {c;e}from other clusters.\\nd({c;e};{a})=max{d(c;a);d(e;a)}=max{3;11}=11:\\nd({c;e};{b})=max{d(c;b);d(e;b)}=max{7;10}=10:\\nd({c;e};{d})=max{d(c;d);d(e;d)}=max{9;8}=9:\\nThe following table gives the distances between the various clusters in C2.CHAPTER 13. CLUSTERING METHODS 198\\n{a} {b} {d} {c;e}\\n{a} 0 9 6 11\\n{b} 9 0 5 10\\n{d} 6 5 0 9\\n{c;e} 11 10 9 0\\nIn the above table, the minimum distance is the distance between the clusters {b}and{d}.\\nAlso\\nd({b};{d})=5:\\nWe merge {b}and{d}to form the cluster {b;d}.\\nThe new set of clusters C3:{a},{b;d},{c;e}.\\n4. Let us compute the distance of {b;d}from other clusters.\\nd({b;d};{a})=max{d(b;a);d(d;a)}=max{9;6}=9:\\nd({b;d};{c;e})=max{d(b;c);d(b;e);d(d;c);d(d;e)}=max{7;10;9;8}=10:\\nThe following table gives the distances between the various clusters in C3.\\n{a} {b;d} {c;e}\\n{a} 0 9 11\\n{b;d} 9 0 10\\n{c;e} 11 10 0\\nIn the above table, the minimum distance is the distance between the clusters {a}and{b;d}.\\nAlso\\nd({a};{b;d})=9:\\nWe merge {a}and{b;d}to form the cluster {a;b;d}.\\nThe new set of clusters C4:{a;b;d},{c;e}\\n5. Only two clusters are left. We merge them form a single cluster containing all data points. We\\nhave\\nd({a;b;d};{c;e})=max{d(a;c);d(a;e);d(b;c);d(b;e);d(d;c);d(d;e)}\\n=max{3;11;7;10;9;8}\\n=11\\n6. Figure 13.14 shows the dendrogram of the hierarchical clustering.\\nProblem 2\\nGiven the dataset {a;b;c;d;e }and the distance matrix given in Table 13.4, construct a dendrogram\\nby single-linkage hierarchical clustering using the agglomerative method.\\nSolution\\nThe complete-linkage clustering uses the “maximum formula”, that is, the following formula to\\ncompute the distance between two clusters AandB:\\nd(A;B)=min{d(x;y)∶x∈A;y∈B}\\n1. Dataset : {a;b;c;d;e }.\\nInitial clustering (singleton sets) C1:{a},{b},{c},{d},{e}.CHAPTER 13. CLUSTERING METHODS 199\\nDistance\\n0246810\\nabdce\\nFigure 13.14: Dendrogram for the data given in Table 13.4 (complete linkage clustering)\\n2. The following table gives the distances between the various clusters in C1:\\n{a} {b} {c} {d} {e}\\n{a} 0 9 3 6 11\\n{b} 9 0 7 5 10\\n{c} 3 7 0 9 2\\n{d} 6 5 9 0 8\\n{e} 11 10 2 8 0\\nIn the above table, the minimum distance is the distance between the clusters {c}and{e}.\\nAlso\\nd({c};{e})=2:\\nWe merge {c}and{e}to form the cluster {c;e}.\\nThe new set of clusters C2:{a},{b},{d},{c;e}.\\n3. Let us compute the distance of {c;e}from other clusters.\\nd({c;e};{a})=min{d(c;a);d(e;a)}=max{3;11}=3:\\nd({c;e};{b})=min{d(c;b);d(e;b)}=max{7;10}=7:\\nd({c;e};{d})=min{d(c;d);d(e;d)}=max{9;8}=8:\\nThe following table gives the distances between the various clusters in C2.\\n{a} {b} {d} {c;e}\\n{a} 0 9 6 3\\n{b} 9 0 5 7\\n{d} 6 5 0 8\\n{c;e} 3 7 8 0\\nIn the above table, the minimum distance is the distance between the clusters {a}and{c;e}.\\nAlso\\nd({a};{c;e})=3:\\nWe merge {a}and{c;e}to form the cluster {a;c;e}.\\nThe new set of clusters C3:{a;c;e},{b},{d}.CHAPTER 13. CLUSTERING METHODS 200\\n4. Let us compute the distance of {a;c;e}from other clusters.\\nd({a;c;e};{b})=min{d(a;b);d(c;b);d(e;b)}={9;7;10}=7\\nd({a;c;e};{d})=min{d(a;d);d(c;d);d(e;d)}={6;9;8}=6\\nThe following table gives the distances between the various clusters in C3.\\n{a;c;e} {b} {d}\\n{a;c;e} 0 7 6\\n{b} 7 0 5\\n{d} 6 5 0\\nIn the above table, the minimum distance is between {b}and{d}. Also\\nd({b};{d})=5:\\nWe merge {b}and{d}to form the cluster {b;d}.\\nThe new set of clusters C4:{a;c;e},{b;d}\\n5. Only two clusters are left. We merge them form a single cluster containing all data points. We\\nhave\\nd({a;c;e};{b;d})=min{d(a;b);d(a;d);d(c;b);d(c;d);d(e;b);d(e;d)}\\n=min{9;6;7;9;10;8}\\n=6\\n6. Figure 13.15 shows the dendrogram of the hierarchical clustering.\\nDistance\\n0123456\\nacebd\\nFigure 13.15: Dendrogram for the data given in Table 13.4 (single linkage clustering)\\n13.11 Algorithm for divisive hierarchical clustering\\nDivisive clustering algorithms begin with the entire data set as a single cluster, and recursively divide\\none of the existing clusters into two daughter clusters at each iteration in a top-down fashion. To\\napply this procedure, we need a separate algorithm to divide a given dataset into two clusters.\\n• The divisive algorithm may be implemented by using the k-means algorithm with k=2to\\nperform the splits at each iteration. However, it would not necessarily produce a splitting\\nsequence that possesses the monotonicity property required for dendrogram representation.CHAPTER 13. CLUSTERING METHODS 201\\n13.11.1 DIANA (DIvisive ANAlysis)\\nDIANA is a divisive hierarchical clustering technique. Here is an outline of the algorithm.\\nStep 1. Suppose that cluster Clis going to be split into clusters CiandCj.\\nStep 2. LetCi=ClandCj=/uni2205.\\nStep 3. For each object x∈Ci:\\n(a) For the ﬁrst iteration, compute the average distance of xto all other objects.\\n(b) For the remaining iterations, compute\\nDx=average {d(x;y)∶y∈Ci}−average{d(x;y)∶y∈Cj}:\\nx\\nCiCj\\nFigure 13.16: Dx= (average of dashed lines) −(average of solid lines)\\nStep 4. (a) For the ﬁrst iteration, move the object with the maximum average distance to Cj.\\n(b) For the remaining iterations, ﬁnd an object xinCifor whichDxis the largest. If\\nDx>0then movextoCj.\\nStep 5. Repeat Steps 3(b) and 4(b) until all differences Dxare negative. Then Clis split intoCiand\\nCj.\\nStep 6. Select the smaller cluster with the largest diameter. (The diameter of a cluster is the largest\\ndissimilarity between any two of its objects.) Then divide this cluster, following Steps 1-5.\\nStep 7. Repeat Step 6 until all clusters contain only a single object.\\n13.11.2 Example\\nProblem\\nGiven the dataset {a;b;c;d;e }and the distance matrix in Table 13.4, construct a dendrogram by the\\ndivisive analysis algorithm.\\nSolution\\n1. We have, initially\\nCl={a;b;c;d;e }\\n2. We write\\nCi=Cl; Cj=/uni2205:\\n3. Division into clustersCHAPTER 13. CLUSTERING METHODS 202\\n(a) Initial iteration\\nLet us calculate the average dissimilarities of the objects in Ciwith the other objects in\\nCi.\\nAverage dissimilarity of a\\n=1\\n4(d(a;b)+d(a;c)+d(a;e))=1\\n4(9+3+6+11)=7:25\\nSimilarly we have :\\nAverage dissimilarity of b=7:75\\nAverage dissimilarity of c=5:25\\nAverage dissimilarity of d=7:00\\nAverage dissimilarity of e=7:75\\nThe highest average distance is 7:75and there are two corresponding objects. We choose\\none of them, b, arbitrarily. We move btoCj.\\nWe now have\\nCi={a;c;d;e }; Cj=/uni2205∪{b}={b}:\\n(b) Remaining iterations\\n(i) 2-nd iteration.\\nDa=1\\n3(d(a;c)+d(a;d)+d(a;e))−1\\n1(d(a;b))=20\\n3−9=−2:33\\nDc=1\\n3(d(c;a)+d(c;d)+d(c;e))−1\\n1(d(c;b))=14\\n3−7=−2:33\\nDd=1\\n3(d(d;a)+d(d;c)+d(d;e))−1\\n1(d(c;b))=23\\n3−7=0:67\\nDe=1\\n3(d(e;a)+d(e;c)+d(e;d))−1\\n1(d(e;b))=21\\n3−7=0\\nDdis the largest and Dd>0. So we move, dtoCj.\\nWe now have\\nCi={a;c;e}; Cj={b}∪{d}={b;d}:\\n(ii) 3-rd iteration\\nDa=1\\n2(d(a;c)+d(a;e))−1\\n2(d(a;b)+d(a;d))=14\\n2−15\\n2=−0:5\\nDc=1\\n2(d(c;a)+d(c;e))−1\\n2(d(c;b)+d(c;d))=5\\n2−16\\n2=−13:5\\nDe=1\\n2(d(e;a)+d(e;c))−1\\n2(d(e;b)+d(e;d))=13\\n2−18\\n2=−2:5\\nAll are negative. So we stop and form the clusters CiandCj.\\n4. To divide, CiandCj, we compute their diameters.\\ndiameter (Ci)=max{d(a;c);d(a;e);d(c;e)}\\n=max{3;11;2}\\n=11\\ndiameter (Cj)=max{d(b;d)}\\n=5\\nThe cluster with the largest diameter is Ci. So we now split Ci.\\nWe repeat the process by taking Cl={a;c;e}. The remaining computations are left as an\\nexercise to the reader.CHAPTER 13. CLUSTERING METHODS 203\\n13.12 Density-based clustering\\nIn density-based clustering, clusters are deﬁned as areas of higher density than the remainder of the\\ndata set. Objects in these sparse areas - that are required to separate clusters - are usually considered\\nto be noise and border points. The most popular density based clustering method is DBSCAN\\n(Density-Based Spatial Clustering of Applications with Noise).\\nFigure 13.17: Clusters of points and noise points not belonging to any of those clusters\\n13.12.1 Density\\nWe introduce some terminology and notations.\\n• Let\\x0f(epsilon) be some constant distance. Let pbe an arbitrary data point. The \\x0f-neighbourhood\\nofpis the set\\nN\\x0f(p)={q∶d(p;q)<\\x0f}\\n• We choose some number m0to deﬁne points of “high density”: We say that a point pis point\\nofhigh density ifN\\x0f(p)contains at least m0points.\\n• We deﬁne a point pas acore point ifN\\x0f(p)has more than m0points.\\n• We deﬁne a point pas a border point ifN\\x0f(p)has fewer than m0points, but is in the \\x0f-\\nneighbourhood of a core point.\\n• A point which is neither a core point nor a border point is called a noise point .\\np p pq qr\\n(a) (b) (c) (d)\\nFigure 13.18: With m0=4: (a)pa point of high density (b) pa core point (c) pa border point\\n(d)ra noise point\\n• An object qisdirectly density-reachable from object pifpis a core object and qis inN\\x0f(p).\\n• An object qisindirectly density-reachable from an object pif there is a ﬁnite set of objects\\np1;:::;prsuch thatp1is directly density-reachable form p,p2is directly density reachable\\nfromp1, etc.,qis directly density-reachable form pr.CHAPTER 13. CLUSTERING METHODS 204\\nqp pp1p2p3q\\n(a) (b)\\nFigure 13.19: With m0=4: (a)qis directly density-reachable from p(b)qis indirectly\\ndensity-reachable from p\\n13.12.2 DBSCAN algorithm\\nLetX={x1;x2;:::;xn}be the set of data points. DBSCAN requires two parameters: \\x0f(eps) and\\nthe minimum number of points required to form a cluster ( m0).\\nStep 1. Start with an arbitrary starting point pthat has not been visited.\\nStep 2. Extract the \\x0f-neighborhood N\\x0f(p)ofp.\\nStep 3. If the number of points in N\\x0f(p)is not greater than m0then the point pis labeled as noise\\n(later this point can become the part of the cluster).\\nStep 4. If the number of points in N\\x0f(p)is greater than m0then the point pis a core point and is\\nmarked as visited. Select a new cluster-id and mark all objects in N\\x0f(p)with this cluster-id.\\nStep 5. If a point is found to be a part of the cluster then its \\x0f-neighborhood is also the part of the\\ncluster and the above procedure from step 2 is repeated for all \\x0f-neighborhood points. This\\nis repeated until all points in the cluster are determined.\\nStep 6. A new unvisited point is retrieved and processed, leading to the discovery of a further\\ncluster or noise.\\nStep 7. This process continues until all points are marked as visited.\\n13.13 Sample questions\\n(a) Short answer questions\\n1. What is clustering?\\n2. Is clustering supervised learning? Why?\\n3. Explain some applications of the k-means algorithm.\\n4. Explain how clustering technique is used in image segmentation problem.\\n5. Explain how clustering technique used in data compression.\\n6. What is meant by the mixture of two normal distributions?\\n7. Explain hierarchical clustering.\\n8. What is a dendrogram? Give an example.\\n9. Is hierarchical clustering unsupervised learning? Why?\\n10. Describe the two methods for hierarchical clustering.CHAPTER 13. CLUSTERING METHODS 205\\n11. In a clustering problem, what does the measure of dissimilarity measure? Give some examples\\nof measures of dissimilarity.\\n12. Explain the different types of linkages in clustering.\\n13. In the context of density-based clustering, deﬁne high density point, core point, border point\\nand noise point.\\n14. What is agglomerative hierarchical clustering?\\n(b) Long answer questions\\n1. Applyk-means algorithm for given data with k=3. UseC1(2),C2(16)andC3(38)as initial\\ncenters. Data:\\n2;4;6;3;31;12;15;16;38;35;14;21;3;25;30\\n2. Explain K-means algorithm and group the points (1, 0, 1), (1, 1, 0), (0, 0, 1) and (1, 1, 1) using\\nK-means algorithm.\\n3. Applying the k-means algorithm, ﬁnd two clusters in the following data.\\nx185 170 168 179 182 188 180 180 183 180 180 177\\ny 72 56 60 68 72 77 71 70 84 88 67 76\\n4. Usek-means algorithm to ﬁnd 2 clusters in the following data:\\nNo. 1 2 3 4 5 6 7\\nx1 1.0 1.5 3.0 5.0 3.5 4.5 3.5\\nx2 1.0 2.0 4.0 7.0 5.0 5.0 4.5\\n5. Give a general outline of the expectation-maximization algorithm.\\n6. Describe EM algorithm for Gaussian mixtures.\\n7. Describe an algorithm for agglomerative hierarchical clustering.\\n8. Given the following distance matrix, construct the dendrogram using agglomerative clustering\\nwith single linkage, complete linkage and average linkage.\\nA B C D E\\nA 0 1 2 2 3\\nB 1 0 2 4 3\\nC 2 2 0 1 5\\nD 2 4 1 0 3\\nE 3 3 5 3 0\\n9. Describe an algorithm for divisive hierarchical clustering.\\n10. For the data in Question 8, construct a dendrogram using DIANA algorithm.\\n11. Describe the DBSCAN algorithm for clustering.Bibliography\\n[1] Christopher M. Bishop, Pattern Recognition and Machine Learning , Springer, 2006.\\n[2] Ethem Alpaydin, Introduction to Machine Learning , The MIT Press, Cambridge, Mas-\\nsachusetts, 2004.\\n[3] Margaret H. Dunham, Data Mining: Introductory and Advanced Topics , Pearson, 2006.\\n[4] Mitchell T., Machine Learning , McGraw Hill.\\n[5] Ryszard S. Michalski, Jaime G. Carbonell, and Tom M. Mitchell, Machine Learning : An\\nArtiﬁcial Intelligence Approach , Tioga Publishing Company.\\n[6] Michael J. Kearns and Umesh V . Vazirani, An Introduction to Computational Learning Theory ,\\nThe MIT Press, Cambridge, Massachusetts, 1994.\\n[7] D. H. Wolpert, W. G. Macready (1997), “No Free Lunch Theorems for Optimization”, IEEE\\nTransactions on Evolutionary Computation 1, 67.\\n206Index\\n5-by-2 cross-validation, 50\\nabstraction, 3\\naccuracy, 54\\nactivation function, 113\\nGaussian -, 115\\nhyperbolic -, 116\\nlinear -, 115\\nthreshold -, 114\\nunit step -, 114\\nagglomerative method, 192\\nalgorithm\\nbackpropagation -, 123\\nbackward selection -, 37\\nBaum-Welch, 170\\nC4.5 -, 105\\nDBSCAN -, 204\\ndecision tree -, 95\\nDIANA -, 201\\nforward selection -, 36\\nForwards-Backwards, 170\\nID3 -, 96\\nkernel method -, 157\\nnaive Bayes -, 65\\nPCA -, 40\\nperceptron learning -, 118\\nrandom forest -, 177\\nSVM -, 149\\nViterbi -, 170\\nANN, 119\\nArthur Samuel, 1\\nartiﬁcial neural networks, 119\\nassociation rule, 6\\nattribute, 4\\naxis-aligned rectangle, 18\\naxon, 111\\nbackpropagation algorithm, 123\\nbackward phase, 123\\nbackward selection, 37\\nBasic problems of HMM’s, 169\\nBaum-Welch algorithm, 170\\nBayes’ theorem, 62\\nbias, 23\\nbimodal mixture, 186binary classiﬁcation, 15\\nbootstrap, 51\\nbootstrap sampling, 51\\nbootstrapping, 51\\nborder point, 203\\nC4.5 algorithm, 105\\nCART algorithm, 105\\nclassiﬁcation, 7\\nclassiﬁcation tree, 84\\ncluster analysis, 179\\nclustering, 179\\ncomplete-linkage -, 196\\ndensity-based -, 203\\nfarthest neighbour -, 196\\nhierarchical -, 191\\nk-means -, 179\\nnearest neighbour -, 196\\nsingle-linkage -, 196\\ncomplete-linkage clustering, 196\\ncompression, 8\\ncomputational learning theory, 31\\nconcept class, 31\\nconditional probability, 61\\nconfusion matrix, 52\\nconsistent, 16\\nconstruction of tree, 85\\ncore point, 203\\ncost function, 121\\ncovariance matrix, 40\\ncross-validation, 25, 49\\n5-by-2 -, 50\\nhold-out -, 49\\nK-fold -, 49\\nleave-one-out -, 50\\ndata\\ncategorical -, 5\\nnominal -, 5\\nnumeric - , 5\\nordinal -, 5\\ndata compression, 8, 185\\ndata storage, 2\\nDBSCAN algorithm, 204\\ndecision tree, 83\\n207INDEX 208\\ndecision tree algorithm, 95\\ndeep learning, 129\\ndeep neural network, 129\\ndelta learning rule, 127\\ndendrogram, 191\\ndenrite, 111\\ndensity-based clustering, 203\\nDIANA, 201\\ndichotomy, 27\\ndimensionality reduction, 35\\ndirectly-density reachable, 203\\ndiscrete Markov process, 165\\ndiscriminant, 9\\ndissimilarity, 192\\nDIvisive ANAlysis, 201\\ndivisive method, 194\\nE-step, 189\\neigenvalue, 40\\neigenvector, 41\\nEM algorithm, 189\\nensemble learning, 176\\nentropy, 89\\nepoch, 123\\nerror rate, 54\\nevaluation, 3\\nevent\\nindependent -, 61\\nexample, 4\\nexpectation step, 189\\nexpectation-maximization algorithm, 189\\nexperience\\nlearning from -, 1\\nface recognition, 8\\nfalse negative, 51\\nfalse positive, 51\\nfalse positive rate, 55\\nfarthest neighbour clustering, 196\\nfeature, 4\\nfeature extraction, 35\\nfeature selection, 35\\nfeedforward network, 120\\nﬁrst layer, 120\\nﬁrst principal component, 41\\nforward phase, 123\\nforward selection, 36\\nForwards-Backwards algorithms, 170\\nFPR, 55\\nGaussian activation function, 115\\nGaussian mixture, 190\\ngenralisation, 3\\nGini index, 94\\nGini split index, 94gradient descent method, 123\\nhidden Markov model, 169\\nhidden node, 120\\nhierarchical clustering, 191\\nhigh density point, 203\\nHMM, 169\\nbasic problems, 169\\ncoin tossing example, 167\\nEvaluation problem, 169\\nlearning parameter problem, 170\\nstate sequence problem, 170\\nurn and ball model, 168\\nholdout method, 49\\nhomogeneity property, 164\\nhyperplane, 141\\nhypothesis, 15\\nhypothesis space, 16\\nID3 algorithm, 96\\nimage segmentation, 185\\nindependent\\nmutually -, 61\\npairwise -, 61\\nindependent event, 61\\nindirectly density-reachable, 203\\ninductive bias, 23\\ninformation gain, 92\\ninitial probability, 164\\ninner product, 140\\ninput feature, 15\\ninput node, 120\\ninput representation, 15\\ninstance, 4\\ninstance space, 29\\ninternal node, 83\\nisolated word recognition, 170\\nK-fold cross-validation, 49\\nk-means clustering, 179\\nkernel\\nGaussian -, 157\\nhomogeneous polynomial -, 156\\nLaplacian -, 157\\nnon-homogeneous polynomial -, 156\\nradial basis function -, 157\\nkernel function, 155\\nkernel method, 157\\nkernel method algorithm, 157\\nknowledge extraction, 8\\nLaplacian kernel, 157\\nlatent variable, 188\\nlayer in networks, 120\\nleaf node, 83INDEX 209\\nlearner, 2\\nlearning, 1\\nreinforcement -, 13\\nsupervised -, 11\\nunsupervised - , 12\\nlearning associations, 6\\nlearning program, 2\\nlearning theory, 31\\nleave-one-out, 50\\nlength of an instance, 32\\nLevenshtein distance, 194\\nlikelihood, 63\\nlinear activation function, 115\\nlinear regression, 73\\nlinearly separable data, 144\\nlogistic function, 114\\nlogistic regression, 73\\nM-step, 189\\nmachine learning, 1\\ndeﬁnition of -, 1\\nmachine learning program, 2\\nMarkov property, 164\\nmaximal margin hyperplane, 145\\nmaximisation step, 189\\nmaximum margin hyperplane, 145\\nmean squared error, 35\\nmeasure of dissimilarity, 194\\nmisclassiﬁcation rate, 36\\nmixture of distributions, 186\\nmodel, 1\\nmodel selection, 23\\nmore general than, 18\\nmore speciﬁc than, 18\\nmulticlass SVM, 158\\nmultimodal distribution, 186\\nmultiple class, 22\\nmultiple linear regression, 78\\nmultiple regression, 73\\nnaive Bayes algorithm, 65\\nnearest neighbour clustering, 196\\nnegative example, 15\\nneighbourhood, 203\\nnetwork topology, 119\\nneural networks, 119\\nneuron\\nartiﬁcial -, 112\\nbiological -, 111\\nno-free lunch theorem, 48\\nnoise, 22\\nnoise point, 203\\nnorm, 140\\nobservable Markov model, 165Occam’s razor, 24\\nOLS method, 74\\none-against-all, 22\\none-against-all method, 158\\none-against-one, 23\\none-against-one method, 158\\noptical character recognition, 8\\noptimal separating hyperplane, 146\\nordinary least square, 74\\northogonality, 140\\noutput node, 120\\noverﬁtting, 24\\nPAC learnability, 31\\nPAC learning, 31\\nPCA, 38\\nPCA algorithm, 40\\nperceptron, 116\\nperceptron learning algorithm, 118\\nperformance measure, 1\\nperpendicular distance, 144\\nperpendicularity, 140\\npolynomial kernel, 156\\npolynomial regression, 73\\npositive example, 15\\nprecision, 53\\nprincipal component, 41\\nprincipal component analysis, 38\\nprobability\\nconditional -, 61\\nposterior -, 63\\nprior -, 62\\nprobably approximately correct learning, 31\\nradial basis function kernel, 157\\nrandom forest, 176\\nrandom forest algorithm, 177\\nrandom performance, 55\\nRDF kernel, 157\\nrecall, 53\\nReceiver Operating Characteristic, 54\\nrecord, 4\\nrecurrent network, 120\\nregression, 10\\nlogistic -, 73\\nmultiple , 73\\npolynomial -, 73\\nsimple linear -, 73\\nregression function, 10\\nregression problem, 72\\nregression tree, 84, 101\\nreinforcement learning, 13\\nROC, 54\\nROC curve, 56INDEX 210\\nROC space, 55\\nsaturated linear function, 115\\nscalar, 139\\nsensitivity, 54\\nseparating line, 134\\nshallow network, 129\\nshattering, 28\\nsigmoid function, 114\\nsimple linear regression, 73\\nsingle-linkage clustering, 196\\nsize of a concept, 32\\nslack variable, 154\\nsoft margin hyperplane, 154\\nspeciﬁcity, 54\\nspeech recognition, 8\\nstorage, 2\\nstrictly more general than, 18\\nstrictly more speciﬁc than, 18\\nsubset selection, 36\\nsupervised learning, 11\\nsupport vector, 146\\nsupport vector machine, 146\\nSVM, 146\\nSVM algorithm, 149\\nSVM classiﬁer, 148\\nsynapse, 111\\nthreshold function, 114\\nTPR, 55\\ntraining, 3\\ntransition probability, 164\\ntree, 83\\nclassiﬁcation -, 84\\nregression -, 84\\ntrue negative, 51\\ntrue positive, 51\\ntrue positive rate, 55\\ntwo-class data set, 144\\nunderﬁtting, 24\\nunimodal distribution, 186\\nunit of observation, 4\\nunit step function, 114\\nunsupervised learning, 12\\nvalidation set, 25\\nVapnik-Chervonenkis dimension, 29\\nvariable, 4\\nVC dimension, 29\\nvector space, 138\\nﬁnite dimensional -, 138\\nversion space, 19\\nViterbi algorithm, 170weighted least squares, 75\\nword recognition, 170\\nzero vector, 139  \\n \\n \\n  \\n  \\n \\n \\n '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN,database_id=ASTRA_DB_ID)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T8os6kylmwL",
        "outputId": "96c9015c-7ee6-4b3a-a9a6-d2c953313b4d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 1f246906-21d0-46d1-9cb3-1f18538943e1-us-east1.db.astra.datastax.com:29042:33eb8141-aa77-405a-ac6e-c24712cf48b9. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 1f246906-21d0-46d1-9cb3-1f18538943e1-us-east1.db.astra.datastax.com:29042:33eb8141-aa77-405a-ac6e-c24712cf48b9. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(139254290290704) 1f246906-21d0-46d1-9cb3-1f18538943e1-us-east1.db.astra.datastax.com:29042:33eb8141-aa77-405a-ac6e-c24712cf48b9> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 1f246906-21d0-46d1-9cb3-1f18538943e1-us-east1.db.astra.datastax.com:29042:33eb8141-aa77-405a-ac6e-c24712cf48b9. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "import torch\n",
        "from transformers import AutoTokenizer,AutoModelForCausalLM,pipeline,AutoModelForSeq2SeqLM\n",
        "model_id='google/flan-t5-small'\n",
        "tokenizer=AutoTokenizer.from_pretrained(model_id)\n",
        "model=AutoModelForSeq2SeqLM.from_pretrained(model_id,load_in_8bit=True)\n",
        "pipeline=pipeline(\n",
        "    'text2text-generation',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=128\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "kFup-3rV_zpi",
        "outputId": "07c5b29e-f076-4f7c-b4be-87a2ace41949"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Using `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or pip install bitsandbytes` ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-ea844a6bd0e6>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'google/flan-t5-small'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mload_in_8bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m pipeline=pipeline(\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m'text2text-generation'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    567\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload_in_8bit\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mload_in_4bit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_accelerate_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_bitsandbytes_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2714\u001b[0;31m                 raise ImportError(\n\u001b[0m\u001b[1;32m   2715\u001b[0m                     \u001b[0;34m\"Using `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2716\u001b[0m                     \u001b[0;34m\" bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Using `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or pip install bitsandbytes` ",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H47qwJeDBEZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import LlamaCpp\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from huggingface_hub import hf_hub_download\n",
        "from langchain.chains.question_answering import load_qa_chain"
      ],
      "metadata": {
        "id": "TIkr_h_wn7v_"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])"
      ],
      "metadata": {
        "id": "4WF4VBFapjo-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HUGGINGFACEHUB_API_TOKEN']='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'\n",
        "model_name_or_path='TheBloke/Llama-2-138-chat-GGML'\n",
        "model_basename='llama-2-13b.ggmlv3.q5_1.bin'"
      ],
      "metadata": {
        "id": "KFrNN_Abptmu"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path=hf_hub_download(repo_id=model_name_or_path,filename=model_basename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "nfxTLlzlqMAd",
        "outputId": "f3d0307b-7985-4bcf-ad72-23d5bfa8eb12"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RepositoryNotFoundError",
          "evalue": "401 Client Error. (Request ID: Root=1-65b3a639-4976d1435640d1bf5fc2f877;f6fea4f0-30e6-48a9-aa4b-224a94b525d9)\n\nRepository Not Found for url: https://huggingface.co/TheBloke/Llama-2-138-chat-GGML/resolve/main/llama-2-13b.ggmlv3.q5_1.bin.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/TheBloke/Llama-2-138-chat-GGML/resolve/main/llama-2-13b.ggmlv3.q5_1.bin",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-036584afb863>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhf_hub_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_basename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGatedRepoError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0;31m# Repo not found => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m             \u001b[0;31m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1238\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1239\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                     \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1632\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;31m# Recursively follow relative redirects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;31m# Perform request and return if status_code is not in the retry list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;34m\" make sure you are authenticated.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             )\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-65b3a639-4976d1435640d1bf5fc2f877;f6fea4f0-30e6-48a9-aa4b-224a94b525d9)\n\nRepository Not Found for url: https://huggingface.co/TheBloke/Llama-2-138-chat-GGML/resolve/main/llama-2-13b.ggmlv3.q5_1.bin.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers langchain datasets huggingface_hub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sG_oqLHfu4c-",
        "outputId": "76ac3ed4-3f38-44b4-d913-0cb78c7a4e90"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.14 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.16)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.16)\n",
            "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.83)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.14)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.9.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (3.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
        "from langchain.llms import LlamaCpp\n",
        "from langchain.llms.ll\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from huggingface_hub import hf_hub_download\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "gI6BobpTyHAf",
        "outputId": "849d92eb-7b22-4ce6-c31b-ac469adc1703"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain.llms.llm_utils'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-56bed6316c85>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLlamaForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLlamaTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLlamaCpp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_llm_from_hf_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion_answering\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_qa_chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhf_hub_download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.llms.llm_utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tljXUmKvyLoY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}